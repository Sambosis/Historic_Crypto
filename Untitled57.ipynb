{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1egt5X8CJOs0F_L7zP3aLNOoiAUoHN-GO",
      "authorship_tag": "ABX9TyNlCYzZxYsstmgomhMGYd5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sambosis/Historic_Crypto/blob/main/Untitled57.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "# Uncomment the following lines if running in a new environment\n",
        "# !pip install fluidstack -q\n",
        "# !pip install pytorch_lightning tensorflow icecream tensorboardX rich wandb -q\n",
        "\n",
        "# Standard Library Imports\n",
        "import os\n",
        "import glob\n",
        "import io\n",
        "import time\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "import multiprocessing\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "from rich import print as rr\n",
        "# Third-Party Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, RichProgressBar\n",
        "from icecream import ic\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import requests\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.text import Text\n",
        "from rich.box import ROUNDED\n",
        "import wandb\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "import torch.distributed as dist\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "\n",
        "# Initialize Rich Console\n",
        "console = Console()\n",
        "num_cpus = multiprocessing.cpu_count()\n",
        "print(f\"Number of CPU cores available: {num_cpus}\")\n",
        "\n",
        "# Configuration Dataclass\n",
        "@dataclass\n",
        "class Config:\n",
        "    # read the file \"version\" and increment the version number\n",
        "    with open(\"version\", \"r\") as f:\n",
        "        version = int(f.read())\n",
        "        VERSION_N = version + 1\n",
        "        # print(f\"Version number: {VERSION_N}\")\n",
        "        f.close()\n",
        "    with open(\"version\", \"w\") as f:\n",
        "        f.write(str(VERSION_N))\n",
        "        f.close()\n",
        "    # VERSION_N: int = 87\n",
        "    RECORDS_TO_LOAD: int = 1205040\n",
        "    N_PAST: int = 3 * 12 * 3  # 1 week of 10-minute intervals\n",
        "    N_FUTURE: int = 1 * 12 * 2  # 1 day of 10-minute intervals\n",
        "    BATCH_SIZE: int = 5000\n",
        "    HIDDEN_SIZE: int = 256\n",
        "    NUM_LAYERS: int = 2\n",
        "    NUM_EPOCHS: int = 150\n",
        "    HOT_RESTART: bool = True\n",
        "    TRAIN_FIRST: bool = True\n",
        "    EPOCH_TO_RESTART: int = 50\n",
        "    BATCH_FACTOR: int = 81\n",
        "    DEBUG_FREQ: int = 180\n",
        "    num_cpus = multiprocessing.cpu_count()\n",
        "    NUM_WORKERS = (num_cpus // 4 - 4) if num_cpus > 16 else 4\n",
        "    DEBUG_ON: bool = True\n",
        "    DATA_URL: str = 'https://sambo.us-iad-1.linodeobjects.com/fillnan_combined_df.csv'\n",
        "    DATA_FILE: str = './data/fill_nan_df.csv'\n",
        "    MODEL_PATH: str = \"/teamspace/studios/this_studio/models/TransformerModel355/model-355-epoch=40-val_loss=0.62.ckpt\"\n",
        "    MODEL_SAVE_PATH: str = f'./yay'\n",
        "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    EPSILON: float = 1e-4\n",
        "\n",
        "# Initialize Configuration\n",
        "cfg = Config()\n",
        "\n",
        "# Set Random Seed for Reproducibility\n",
        "pl.seed_everything(40, workers=True)\n",
        "\n",
        "# Print Device Information\n",
        "print(f\"Using device: {cfg.DEVICE}\")\n",
        "os.makedirs(cfg.MODEL_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# Initialize IceCream Debugging\n",
        "if cfg.DEBUG_ON:\n",
        "    ic.enable()\n",
        "else:\n",
        "    ic.disable()\n",
        "\n",
        "# Callback to Update Percentile Cutoff\n",
        "class UpdatePercentileCutoffCallback(Callback):\n",
        "    def __init__(self, reduction_threshold=1.9, reduction_factor=0.9):\n",
        "        super().__init__()\n",
        "        self.reduction_threshold = reduction_threshold\n",
        "        self.reduction_factor = reduction_factor\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        # Skip during sanity check to prevent freezing\n",
        "        if trainer.sanity_checking:\n",
        "            return\n",
        "\n",
        "        # Only the main process (rank 0) determines if reduction is needed\n",
        "        if trainer.is_global_zero:\n",
        "            avg_reward = trainer.callback_metrics.get('val/reward', 0)\n",
        "\n",
        "            if avg_reward > self.reduction_threshold:\n",
        "                old_perc_cutoff = pl_module.criterion.get_perc_cutoff()\n",
        "                new_perc_cutoff = old_perc_cutoff * self.reduction_factor\n",
        "                pl_module.criterion.set_perc_cutoff(new_perc_cutoff)\n",
        "                pl_module.criterion.perc_cutoff_buffer.fill_(new_perc_cutoff)\n",
        "                print(f\"PercentileCutoffCallback: Reducing perc_cutoff from {old_perc_cutoff:.5f} to {new_perc_cutoff:.5f}\")\n",
        "\n",
        "                # Log reduction event to WandB\n",
        "                pl_module.logger.experiment.log({\n",
        "                    \"percentile_cutoff_reduction\": new_perc_cutoff,\n",
        "                    \"avg_reward\": avg_reward\n",
        "                })\n",
        "\n",
        "# PositionalEncoding Class\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # (max_len, 1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))  # (d_model/2,)\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)  # Even indices\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)  # Odd indices\n",
        "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        x = x + self.pe[:, :seq_len, :]\n",
        "        return x\n",
        "\n",
        "# Transformer-Based Model\n",
        "class CryptoTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        d_model=256,\n",
        "        nhead=8,\n",
        "        num_encoder_layers=2,\n",
        "        num_decoder_layers=2,\n",
        "        dim_feedforward=2048,\n",
        "        dropout=0.3,\n",
        "        activation=\"gelu\",\n",
        "        n_future=24,\n",
        "        num_outputs=24,\n",
        "        max_seq_length=5000\n",
        "    ):\n",
        "        super(CryptoTransformer, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.d_model = d_model\n",
        "        self.n_future = n_future\n",
        "        self.num_outputs = num_outputs\n",
        "\n",
        "        # Input linear layer\n",
        "        self.input_fc = nn.Linear(input_size, d_model)\n",
        "\n",
        "        # Positional Encoding\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len=max_seq_length)\n",
        "        self.pos_decoder = PositionalEncoding(d_model, max_len=max_seq_length)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "            batch_first=True  # Added for compatibility with batch_first=True\n",
        "        )\n",
        "\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "            batch_first=True  # Added for compatibility with batch_first=True\n",
        "        )\n",
        "\n",
        "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "\n",
        "        # Output linear layer\n",
        "        self.output_fc = nn.Linear(d_model, num_outputs)\n",
        "\n",
        "        # Layer normalization\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask  # (sz, sz)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: (batch_size, n_past, num_features)\n",
        "            tgt: (batch_size, n_future, num_features)\n",
        "        Returns:\n",
        "            out: (batch_size, n_future, num_outputs)\n",
        "        \"\"\"\n",
        "        batch_size = src.size(0)\n",
        "\n",
        "        # Input embedding\n",
        "        src = self.input_fc(src) * np.sqrt(self.d_model)  # (batch_size, n_past, d_model)\n",
        "        tgt = self.input_fc(tgt) * np.sqrt(self.d_model)  # (batch_size, n_future, d_model)\n",
        "\n",
        "        # Add positional encoding\n",
        "        src = self.pos_encoder(src)  # (batch_size, n_past, d_model)\n",
        "        tgt = self.pos_decoder(tgt)  # (batch_size, n_future, d_model)\n",
        "\n",
        "        # Create masks\n",
        "        tgt_mask = self.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)  # (n_future, n_future)\n",
        "\n",
        "        # Transformer forward pass\n",
        "        memory = self.transformer_encoder(src)  # (batch_size, n_past, d_model)\n",
        "        output = self.transformer_decoder(tgt, memory, tgt_mask=tgt_mask)  # (batch_size, n_future, d_model)\n",
        "\n",
        "        # Final linear layer\n",
        "        out = self.output_fc(output)  # (batch_size, n_future, num_outputs)\n",
        "\n",
        "        return out  # (batch_size, n_future, num_outputs)\n",
        "\n",
        "# Custom Balanced Loss Function\n",
        "class BalancedCryptoLoss(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BalancedCryptoLoss, self).__init__()\n",
        "        # Register perc_cutoff as a buffer for automatic synchronization\n",
        "        self.register_buffer('perc_cutoff_buffer', torch.tensor(0.015))\n",
        "        self.config = config\n",
        "        self.mse_weight = 900.0\n",
        "        self.mae_weight = 25.0\n",
        "        self.max_diff_weight = 3.0\n",
        "        self.balance_weight = 3.0\n",
        "        self.direction_weight = 0.001\n",
        "        self.mean_diff_weight = 15.0\n",
        "        self.perc_diff_weight = 15.0\n",
        "        self.within_1pct_reward_weight = 5.0\n",
        "        self.reward_scaling = 5.0\n",
        "        self.epsilon = config.EPSILON\n",
        "        self.debug_freq = config.DEBUG_FREQ\n",
        "        self.epoch = 0\n",
        "        self.mean_mean_diff = 0.0\n",
        "        self.reward = 0.0\n",
        "\n",
        "    def directional_loss(self, preds, target):\n",
        "        direction_pred = (preds[:, 1:] - preds[:, :-1]).sign()\n",
        "        direction_true = (target[:, 1:] - target[:, :-1]).sign()\n",
        "\n",
        "        # Convert signs to 0 and 1\n",
        "        direction_pred = (direction_pred + 1) / 2\n",
        "        direction_true = (direction_true + 1) / 2\n",
        "\n",
        "        # Clamp values to prevent BCE from receiving exact 0 or 1\n",
        "        direction_pred = torch.clamp(direction_pred, 1e-7, 1 - 1e-7)\n",
        "        direction_true = torch.clamp(direction_true, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        return F.binary_cross_entropy(direction_pred, direction_true).mean() * self.direction_weight\n",
        "\n",
        "    def mse_loss_component(self, y_pred, y_true):\n",
        "        return F.mse_loss(y_pred, y_true) * self.mse_weight\n",
        "\n",
        "    def mae_loss_component(self, y_pred, y_true):\n",
        "        return F.l1_loss(y_pred, y_true) * self.mae_weight\n",
        "\n",
        "    def percentage_diff_component(self, y_pred, y_true):\n",
        "        perc_diff = torch.abs((y_pred - y_true) / (self.epsilon + y_true))\n",
        "        self.mean_mean_diff = torch.mean(perc_diff).item()\n",
        "        return (torch.mean(perc_diff) * self.perc_diff_weight) ** 2\n",
        "\n",
        "    def max_diff_component(self, perc_diff):\n",
        "        max_diffs, _ = torch.max(perc_diff, dim=1)\n",
        "        return torch.mean(max_diffs) * self.max_diff_weight\n",
        "\n",
        "    def imbalance_component(self, perc_diff):\n",
        "        overpredict = torch.relu(perc_diff)\n",
        "        underpredict = torch.relu(-perc_diff)\n",
        "        imbalance = torch.abs(torch.mean(overpredict, dim=1) - torch.mean(underpredict, dim=1))\n",
        "        return torch.mean(imbalance) * self.balance_weight\n",
        "\n",
        "    def reward_component(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Calculates the reward component based on the predicted and true values.\n",
        "\n",
        "        Args:\n",
        "            y_pred (torch.Tensor): The predicted values.\n",
        "            y_true (torch.Tensor): The true values.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The reward component calculated based on the percentage difference between\n",
        "                          the predicted and true values.\n",
        "        \"\"\"\n",
        "        percentage_diff = torch.abs((y_pred - y_true) / (self.epsilon + y_true))\n",
        "\n",
        "        within_1pct = (percentage_diff <= self.perc_cutoff_buffer).float()\n",
        "        within_1pct_ratio = torch.mean(within_1pct)\n",
        "        return within_1pct_ratio * self.within_1pct_reward_weight\n",
        "\n",
        "    def compute_all_losses(self, y_pred, y_true):\n",
        "        mse_loss = self.mse_loss_component(y_pred, y_true)\n",
        "        mae_loss = self.mae_loss_component(y_pred, y_true)\n",
        "        perc_diff_loss = self.percentage_diff_component(y_pred, y_true)\n",
        "        max_diff_loss = self.max_diff_component(torch.abs((y_pred - y_true) / (self.epsilon + y_true)))\n",
        "        imbalance_loss = self.imbalance_component(torch.abs((y_pred - y_true) / (self.epsilon + y_true)))\n",
        "        direction_loss = self.directional_loss(y_pred, y_true)\n",
        "        reward = self.reward_component(y_pred, y_true)\n",
        "        return mse_loss, mae_loss, perc_diff_loss, max_diff_loss, imbalance_loss, direction_loss, reward\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        self.epoch += 1\n",
        "\n",
        "        # Compute Loss Components\n",
        "        mse_loss, mae_loss, perc_diff_loss, max_diff_loss, imbalance_loss, direction_loss, reward = self.compute_all_losses(y_pred, y_true)\n",
        "        self.reward = reward\n",
        "        # Combine Loss Components\n",
        "        final_loss = (mse_loss + mae_loss + perc_diff_loss + max_diff_loss +\n",
        "                      imbalance_loss + direction_loss - (reward * self.reward_scaling))\n",
        "\n",
        "        # Clamp Final Loss to prevent negative values\n",
        "        final_loss = torch.clamp(final_loss, min=0.00001)\n",
        "        perc_cutoff = self.get_perc_cutoff()\n",
        "        return final_loss, mse_loss, mae_loss, perc_diff_loss, max_diff_loss, imbalance_loss, direction_loss, reward, perc_cutoff\n",
        "\n",
        "    def get_reward(self):\n",
        "        # Returns a float that is converted from a tensor\n",
        "        return self.reward.item()\n",
        "\n",
        "    def set_perc_cutoff(self, perc_cutoff):\n",
        "        # Update the buffer in-place\n",
        "        self.perc_cutoff_buffer.fill_(perc_cutoff)\n",
        "\n",
        "    def get_last_mean_diff(self):\n",
        "        return self.mean_mean_diff\n",
        "\n",
        "    def get_perc_cutoff(self):\n",
        "        return self.perc_cutoff_buffer.item()\n",
        "\n",
        "# Custom Dataset\n",
        "class CryptoDataset(Dataset):\n",
        "    def __init__(self, data: pd.DataFrame, n_past: int, n_future: int):\n",
        "        self.data = data\n",
        "        self.n_past = n_past\n",
        "        self.n_future = n_future\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.n_past - self.n_future + 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data.iloc[idx:idx + self.n_past].values  # (n_past, num_features)\n",
        "        y = self.data.iloc[idx + self.n_past:idx + self.n_past + self.n_future].values  # (n_future, num_features)\n",
        "        return torch.FloatTensor(x), torch.FloatTensor(y)\n",
        "\n",
        "# Utility Functions\n",
        "def get_random_sample(dataframe: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Retrieve a random sample from the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): DataFrame to sample from.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (input_data, target_data)\n",
        "    \"\"\"\n",
        "    random_index = random.randint(0, len(dataframe) - cfg.N_PAST - cfg.N_FUTURE)\n",
        "    input_data = dataframe.iloc[random_index:random_index + cfg.N_PAST].values\n",
        "    target_data = dataframe.iloc[random_index + cfg.N_PAST:random_index + cfg.N_PAST + cfg.N_FUTURE].values\n",
        "    return torch.FloatTensor(input_data), torch.FloatTensor(target_data)\n",
        "\n",
        "def prepare_input(input_data, device):\n",
        "    \"\"\"\n",
        "    Prepare input tensor for the model.\n",
        "\n",
        "    Args:\n",
        "        input_data (torch.FloatTensor): Input data.\n",
        "\n",
        "    Returns:\n",
        "        torch.FloatTensor: Prepared input tensor.\n",
        "    \"\"\"\n",
        "    return input_data.unsqueeze(0).to(device)\n",
        "\n",
        "def convert_to_numpy(input_data, target, prediction):\n",
        "    \"\"\"\n",
        "    Convert tensors to NumPy arrays.\n",
        "\n",
        "    Args:\n",
        "        input_data (torch.FloatTensor): Input data.\n",
        "        target (torch.FloatTensor): Target data.\n",
        "        prediction (torch.FloatTensor): Prediction data.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (input_np, target_np, prediction_np)\n",
        "    \"\"\"\n",
        "    return input_data.detach().cpu().numpy(), target.detach().cpu().numpy(), prediction.detach().cpu().numpy()\n",
        "\n",
        "def gaussian_smoothing(data, window_size, sigma):\n",
        "    \"\"\"\n",
        "    Compute the Gaussian smoothing of the data.\n",
        "\n",
        "    Args:\n",
        "        data (np.ndarray): Input data.\n",
        "        window_size (int): Window size for Gaussian smoothing.\n",
        "        sigma (float): Standard deviation of the Gaussian kernel.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Gaussian smoothed data.\n",
        "    \"\"\"\n",
        "    # Generate Gaussian kernel\n",
        "    x = np.linspace(-window_size // 2, window_size // 2, window_size)\n",
        "    kernel = np.exp(-(x ** 2) / (2 * sigma ** 2))\n",
        "    kernel /= kernel.sum()\n",
        "\n",
        "    # Convolve data with Gaussian kernel\n",
        "    return np.convolve(data, kernel, 'valid')\n",
        "\n",
        "# def gaussian_smoothing(data, window_size, sigma):\n",
        "#     \"\"\"\n",
        "#     Compute the Gaussian smoothing of the data.\n",
        "\n",
        "#     Args:\n",
        "#         data (np.ndarray): Input data.\n",
        "#         window_size (int): Window size for Gaussian smoothing.\n",
        "#         sigma (float): Standard deviation of the Gaussian kernel.\n",
        "\n",
        "#     Returns:\n",
        "#         np.ndarray: Gaussian smoothed data.\n",
        "#     \"\"\"\n",
        "#     return gaussian_filter1d(data, sigma=sigma)\n",
        "\n",
        "# Inverse Transformation Function\n",
        "def inverse_transform_predictions(scaled_value, scaler, log_transform=True):\n",
        "    \"\"\"\n",
        "    Inverse transform a scaled value back to its original scale.\n",
        "\n",
        "    Args:\n",
        "        scaled_value (np.ndarray or float): Scaled value(s).\n",
        "        scaler (MinMaxScaler): Fitted scaler used during preprocessing.\n",
        "        log_transform (bool): Indicates whether a log transform was applied.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray or float: Original scale value(s).\n",
        "    \"\"\"\n",
        "    # Ensure scaled_value is a 2D array for inverse_transform\n",
        "    scaled_array = np.array(scaled_value).reshape(-1, 1)\n",
        "    inverse_scaled = scaler.inverse_transform(scaled_array).flatten()\n",
        "\n",
        "    if log_transform:\n",
        "        original = np.exp(inverse_scaled)\n",
        "    else:\n",
        "        original = inverse_scaled\n",
        "\n",
        "    return original\n",
        "\n",
        "# Visualization Function\n",
        "def visualize_predictions(target_np, prediction_np, n_future, scalers, filtered_df, model_save_path):\n",
        "    num_features = filtered_df.shape[1]\n",
        "    max_cols = 4\n",
        "    num_rows = (num_features - 1) // max_cols + 1\n",
        "    num_cols = min(num_features, max_cols)\n",
        "\n",
        "    plt.figure(figsize=(18 * num_cols / max_cols, 6 * num_rows))\n",
        "\n",
        "    window_size = 7  # Adjust this value for smoothing\n",
        "\n",
        "    for j in range(num_features):\n",
        "        plt.subplot(num_rows, num_cols, j + 1)\n",
        "        col_name = filtered_df.columns[j]\n",
        "\n",
        "        # Extract past data from filtered_df\n",
        "        past_scaled = filtered_df[col_name].values  # Shape: (n_past,)\n",
        "        past_scaled = past_scaled[:-(n_future-1)]  # Only consider past data\n",
        "        past_inverted = inverse_transform_predictions(past_scaled, scalers[col_name])\n",
        "\n",
        "        # Directly extract the known future target data from filtered_df\n",
        "        target_scaled = filtered_df[col_name].values # Shape: (n_future,)\n",
        "        target_scaled = target_scaled[-(n_future+1):]  # Only consider future data\n",
        "        target_inverted = inverse_transform_predictions(target_scaled, scalers[col_name])\n",
        "\n",
        "        # Extract the predicted future data\n",
        "        prediction_scaled = prediction_np[0, :, j]  # Shape: (n_future,)\n",
        "        prediction_inverted = inverse_transform_predictions(prediction_scaled, scalers[col_name])\n",
        "\n",
        "        last_xbtusd_price_scaled = filtered_df['XBTUSD_price'].iloc[-1]\n",
        "        last_xbtusd_price = inverse_transform_predictions(last_xbtusd_price_scaled, scalers['XBTUSD_price'])\n",
        "\n",
        "        # Adjust if column ends with 'XBT_price'\n",
        "        if col_name.endswith('XBT_price'):\n",
        "            past_inverted *= last_xbtusd_price\n",
        "            target_inverted *= last_xbtusd_price\n",
        "            prediction_inverted *= last_xbtusd_price\n",
        "\n",
        "        # Combine past and future data\n",
        "        # total_inverted = np.concatenate((past_inverted, target_inverted))\n",
        "        total_predicted = np.concatenate((past_inverted, prediction_inverted))\n",
        "\n",
        "        # Create time indices\n",
        "        n_past = len(past_inverted)\n",
        "        total_timesteps = n_past + n_future\n",
        "        time_indices = range(total_timesteps)\n",
        "\n",
        "        # Plot past data\n",
        "        # print the lenth of the x and y axis\n",
        "        # print(len(time_indices[-(len(past_inverted)):]), len(past_inverted[n_past-n_future:]))\n",
        "\n",
        "        plt.plot(time_indices[n_past-n_future:(n_past+1)], past_inverted[-(n_future+1):], 'b', label='Past Data' if j == 0 else \"\")\n",
        "        # plt.plot(time_indices[-(len(past_inverted))+n_future:], past_inverted[:], 'b', label='Past Data' if j == 0 else \"\")\n",
        "\n",
        "        # Plot known target data\n",
        "        plt.plot(time_indices[n_past-1:], target_inverted, 'g', alpha=0.7, label='Target Data' if j == 0 else \"\")\n",
        "\n",
        "        # Plot prediction data\n",
        "        plt.plot(time_indices[n_past:], prediction_inverted, 'r', alpha=0.7, label='Prediction Data' if j == 0 else \"\")\n",
        "\n",
        "        # Optionally apply smoothing\n",
        "        total_inverted_smooth = gaussian_smoothing(past_inverted, window_size, sigma=10)\n",
        "        total_predicted_smooth = gaussian_smoothing(total_predicted, window_size, sigma=10)\n",
        "\n",
        "        # Plot smoothed data\n",
        "        # print the lenth of the x and y axis\n",
        "        # plt.plot(time_indices[n_past:], total_inverted_smooth[-n_future:], 'g', linewidth=2, label='Target Smoothed' if j == 0 else \"\")\n",
        "\n",
        "        # plt.plot(time_indices[n_past:], total_predicted_smooth[-n_future:], 'r', linewidth=2, label='Prediction Smoothed' if j == 0 else \"\")\n",
        "\n",
        "        # plt.fill_between(range(-n_future), total_predicted_smooth[:-n_future], total_inverted_smooth[:-n_future], color='blue', alpha=0.1)\n",
        "        # Ensure that both arrays have the same length for the fill_between operation\n",
        "        min_length = min(len(total_predicted_smooth), len(total_inverted_smooth))\n",
        "\n",
        "        # Adjust the indices to ensure matching lengths\n",
        "        start_index = n_past - min_length\n",
        "        end_index = n_past\n",
        "\n",
        "        # Plot smoothed data\n",
        "        # plt.plot(time_indices[n_past:], total_inverted_smooth[-n_future:], 'g', linewidth=2, label='Target Smoothed' if j == 0 else \"\")\n",
        "        plt.plot(time_indices[n_past+window_size:], total_predicted_smooth[n_past+1:], 'r', linewidth=2, label='Prediction Smoothed' if j == 0 else \"\")\n",
        "\n",
        "        # Fill between the smoothed prediction and smoothed total\n",
        "        plt.fill_between(time_indices[-n_future:], total_predicted_smooth[-n_future:], target_inverted[-n_future:], color='blue', alpha=0.1)\n",
        "        # Adjust plot settings\n",
        "        plt.title(col_name)\n",
        "        if j == 0:\n",
        "            plt.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    time_date = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    image_path = os.path.join(model_save_path, f\"{time_date}_predictions.png\")\n",
        "    plt.savefig(image_path)\n",
        "    plt.close()\n",
        "\n",
        "    return image_path\n",
        "\n",
        "# Checkpoint Saving Function\n",
        "def save_checkpoint(state, filename):\n",
        "    \"\"\"\n",
        "    Save a training checkpoint.\n",
        "\n",
        "    Args:\n",
        "        state (dict): State dictionary containing model, optimizer, scheduler states, etc.\n",
        "        filename (str): Path to save the checkpoint.\n",
        "    \"\"\"\n",
        "    torch.save(state, filename)\n",
        "\n",
        "# Checkpoint Loading Function\n",
        "def load_checkpoint(model, optimizer, scheduler, model_path, device):\n",
        "    print(f\"Loading checkpoint from {model_path}\")\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    print(\"Checkpoint keys:\", checkpoint.keys())\n",
        "\n",
        "    # Adjust the state_dict\n",
        "    if 'model_state_dict' in checkpoint:\n",
        "        state_dict = checkpoint['model_state_dict']\n",
        "    elif 'state_dict' in checkpoint:\n",
        "        state_dict = checkpoint['state_dict']\n",
        "    else:\n",
        "        # If the checkpoint is the model's state_dict itself\n",
        "        state_dict = checkpoint\n",
        "\n",
        "    # Remove 'model.' prefix from the keys\n",
        "    from collections import OrderedDict\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        if k.startswith('model.'):\n",
        "            name = k[6:]  # remove 'model.' prefix\n",
        "        else:\n",
        "            name = k\n",
        "        new_state_dict[name] = v\n",
        "\n",
        "    # Load the adjusted state_dict into the model\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(new_state_dict, strict=False)\n",
        "\n",
        "    if missing_keys:\n",
        "        print(f\"Missing keys: {missing_keys}\")\n",
        "    if unexpected_keys:\n",
        "        print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "    # Load optimizer and scheduler state dicts if available\n",
        "    if optimizer is not None and 'optimizer_state_dict' in checkpoint:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    if scheduler is not None and 'scheduler_state_dict' in checkpoint:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    print(\"Checkpoint loaded successfully.\")\n",
        "    return checkpoint\n",
        "# Data Loading and Preprocessing\n",
        "def load_and_preprocess_data(file_path: str, download_url: str = None):\n",
        "    \"\"\"\n",
        "    Load and preprocess data from a CSV file. If the file does not exist, download it.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file.\n",
        "        download_url (str, optional): URL to download the CSV file. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Preprocessed DataFrame.\n",
        "        dict: Dictionary of scalers used for each column.\n",
        "    \"\"\"\n",
        "    ic(\"Starting data loading and preprocessing...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        ic(f\"File {file_path} does not exist.\")\n",
        "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "        if download_url:\n",
        "            ic(f\"Downloading file from {download_url}...\")\n",
        "            try:\n",
        "                response = requests.get(download_url, stream=True)\n",
        "                response.raise_for_status()\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    for chunk in response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "                ic(f\"File downloaded and saved to {file_path}\")\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                ic(f\"Failed to download the file: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            ic(\"Download URL not provided. Cannot download the file.\")\n",
        "            raise FileNotFoundError(f\"The file {file_path} does not exist and no download URL was provided.\")\n",
        "\n",
        "    # Load the DataFrame\n",
        "    df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "    df = df.tail(cfg.RECORDS_TO_LOAD)\n",
        "    scalers = {}\n",
        "    start_time_preprocess = time.time()\n",
        "\n",
        "    for col in df.columns:\n",
        "        # Ensure no non-positive values before log transform\n",
        "        if (df[col] <= 0).any():\n",
        "            raise ValueError(f\"Column {col} contains non-positive values, cannot apply log transform.\")\n",
        "\n",
        "        # Apply natural logarithm transformation\n",
        "        df[col] = np.log(df[col])\n",
        "\n",
        "        # Initialize and fit MinMaxScaler\n",
        "        scaler = MinMaxScaler()\n",
        "        df[col] = scaler.fit_transform(df[[col]])\n",
        "\n",
        "        # Save the scaler\n",
        "        scalers[col] = scaler\n",
        "\n",
        "    ic(f\"Data preprocessing completed in {time.time() - start_time_preprocess:.2f} seconds\")\n",
        "    ic(f\"DataFrame shape: {df.shape}\")\n",
        "\n",
        "    return df, scalers\n",
        "\n",
        "# Lightning Wrapper\n",
        "class LightningWrapper(pl.LightningModule):\n",
        "    def __init__(self, model, criterion, optimizer, scheduler, num_epochs: int, scaler_dict: dict, val_data: pd.DataFrame):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.num_epochs = num_epochs\n",
        "        self.scaler_dict = scaler_dict\n",
        "        self.val_data = val_data  # For making predictions during logging\n",
        "        self.validation_rewards = []  # Initialize validation rewards list\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        return self.model(src, tgt)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        batch_X, batch_y = batch\n",
        "        # Shift target sequence to the right and prepend zeros\n",
        "        tgt_input = torch.zeros_like(batch_y)\n",
        "        tgt_input[:, 1:, :] = batch_y[:, :-1, :]\n",
        "        y_pred = self.model(batch_X, tgt_input)\n",
        "        final_loss, mse_loss, mae_loss, perc_diff_loss, max_diff_loss, imbalance_loss, direction_loss, reward, perc_cutoff = self.criterion(y_pred, batch_y)\n",
        "\n",
        "        # Log all loss components\n",
        "        self.log('train/final_loss', final_loss, on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
        "        self.log('train/mse_loss', mse_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.log('train/mae_loss', mae_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.log('train/perc_diff_loss', perc_diff_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.log('train/max_diff_loss', max_diff_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.log('train/imbalance_loss', imbalance_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.log('train/direction_loss', direction_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.log('train/reward', reward, on_step=False, on_epoch=True, sync_dist=True)\n",
        "\n",
        "        return final_loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        batch_X, batch_y = batch\n",
        "        # Shift target sequence to the right and prepend zeros\n",
        "        tgt_input = torch.zeros_like(batch_y)\n",
        "        tgt_input[:, 1:, :] = batch_y[:, :-1, :]\n",
        "        y_pred = self.model(batch_X, tgt_input)\n",
        "        final_loss, mse_loss, mae_loss, perc_diff_loss, max_diff_loss, imbalance_loss, direction_loss, reward, percentile_cutoff = self.criterion(y_pred, batch_y)\n",
        "\n",
        "        # Log all loss components\n",
        "        self.log('val_loss', final_loss, on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
        "        self.log('val/mse_loss', mse_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.log('val/mae_loss', mae_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.log('val/perc_diff_loss', perc_diff_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.log('val/max_diff_loss', max_diff_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.log('val/imbalance_loss', imbalance_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.log('val/direction_loss', direction_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.log('val/reward', reward, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.log('val/perc_cutoff', percentile_cutoff, on_step=False, on_epoch=True, sync_dist=True)\n",
        "        self.validation_rewards.append(reward.item())\n",
        "\n",
        "        return final_loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return {\n",
        "            'optimizer': self.optimizer,\n",
        "            'lr_scheduler': {\n",
        "                'scheduler': self.scheduler,\n",
        "                'monitor': 'val_loss'\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        # Skip ALL logic during sanity check\n",
        "        if hasattr(self.trainer, 'running_sanity_check') and self.trainer.running_sanity_check:\n",
        "            self.print(\"Skipping ALL on_validation_epoch_end logic during sanity check.\")\n",
        "            return  # Exit the method early\n",
        "\n",
        "        if self.global_rank == 0:\n",
        "            try:\n",
        "                plot_path = self.generate_and_log_plots()\n",
        "                if plot_path:\n",
        "                    img = Image.open(plot_path)\n",
        "                    self.logger.experiment.log({\n",
        "                        \"Validation/Prediction_vs_Target\": wandb.Image(img),\n",
        "                        \"global_step\": self.global_step\n",
        "                    })\n",
        "                    # os.remove(plot_path)\n",
        "            except Exception as e:\n",
        "                self.print(f\"Error in generate_and_log_plots: {e}\")\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        # Only the main process should perform logging\n",
        "        if self.global_rank == 0:\n",
        "            # Log learning rate\n",
        "            optimizer = self.optimizers()\n",
        "            lr = optimizer.param_groups[0]['lr']\n",
        "            self.logger.experiment.log({'learning_rate': lr, 'epoch': self.current_epoch})\n",
        "\n",
        "    # def on_after_backward(self):\n",
        "    #     # Only the main process should perform logging\n",
        "    #     if self.global_rank == 0:\n",
        "    #         total_norm = 0.0\n",
        "    #         for p in self.model.parameters():\n",
        "    #             if p.grad is not None:\n",
        "    #                 param_norm = p.grad.detach().data.norm(2)\n",
        "    #                 total_norm += param_norm.item() ** 2\n",
        "    #         total_norm = total_norm ** 0.5\n",
        "    #         self.logger.experiment.log({'Gradients/grad_total_norm': total_norm, 'step': self.global_step})\n",
        "    def on_after_backward(self):\n",
        "        # Only the main process should perform logging\n",
        "        if self.global_rank == 0:\n",
        "            total_norm = 0.0\n",
        "            clip_value = 50.0  # Your gradient clipping value\n",
        "\n",
        "            for p in self.model.parameters():\n",
        "                if p.grad is not None:\n",
        "                    param_norm = p.grad.detach().data.norm(2)\n",
        "                    total_norm += param_norm.item() ** 2\n",
        "            total_norm = total_norm ** 0.5\n",
        "\n",
        "            # Log total gradient norm\n",
        "            self.logger.experiment.log({'Gradients/grad_total_norm': total_norm, 'step': self.global_step})\n",
        "\n",
        "            # Log whether the gradients were clipped\n",
        "            clipped = total_norm > clip_value\n",
        "            # convert to float to plot in wandb\n",
        "            clipped = float(clipped)\n",
        "            self.logger.experiment.log({'Gradients/clipped': clipped, 'step': self.global_step})\n",
        "\n",
        "    def generate_and_log_plots(self):\n",
        "        \"\"\"\n",
        "        Generate prediction vs target plots and save them to a temporary file.\n",
        "        Returns the path to the saved image.\n",
        "        \"\"\"\n",
        "        # Make predictions on a random sample from validation data\n",
        "        sample = get_random_sample(self.val_data)\n",
        "        input_data, target = sample\n",
        "        input_tensor = prepare_input(input_data, self.device)\n",
        "        tgt_input = torch.zeros_like(target).unsqueeze(0).to(self.device)\n",
        "        prediction = self.model(input_tensor, tgt_input)\n",
        "        _, target_np, prediction_np = convert_to_numpy(input_tensor, target, prediction)\n",
        "\n",
        "        # Prepare DataFrame for plotting\n",
        "        start_idx = random.randint(0, len(self.val_data) - cfg.N_PAST - cfg.N_FUTURE)\n",
        "        past_df = self.val_data.iloc[start_idx:start_idx + cfg.N_PAST]\n",
        "\n",
        "        # Get future data to form the target data\n",
        "        future_df = self.val_data.iloc[start_idx + cfg.N_PAST: start_idx + cfg.N_PAST + cfg.N_FUTURE]\n",
        "\n",
        "        # Ensure past_df and future_df have correct lengths\n",
        "        if len(past_df) < cfg.N_PAST or len(future_df) < cfg.N_FUTURE:\n",
        "            print(\"Not enough data for plotting.\")\n",
        "            return None\n",
        "\n",
        "        # Create filtered_df for plotting: combining past and future data\n",
        "        filtered_df = pd.concat([past_df, future_df])\n",
        "\n",
        "        # Generate and save plot\n",
        "        image_path = visualize_predictions(target_np, prediction_np, cfg.N_FUTURE, self.scaler_dict, filtered_df, cfg.MODEL_SAVE_PATH)\n",
        "\n",
        "        return image_path\n",
        "\n",
        "    def set_perc_cutoff(self, perc_cutoff):\n",
        "        self.criterion.set_perc_cutoff(perc_cutoff)\n",
        "\n",
        "    def get_perc_cutoff(self):\n",
        "        return self.criterion.get_perc_cutoff()\n",
        "\n",
        "# Main Execution Block\n",
        "def train_main(cfg):\n",
        "    torch.set_float32_matmul_precision(\"medium\")\n",
        "    # Load and preprocess data\n",
        "    df, scalers = load_and_preprocess_data(cfg.DATA_FILE, cfg.DATA_URL)\n",
        "    NUM_FEATURES = df.shape[1]\n",
        "\n",
        "    # Initialize the Wandb logger and name your Wandb project\n",
        "    logger = WandbLogger(project='my-awesome-project', log_model=True)  # Set log_model to True\n",
        "\n",
        "    # Log hyperparameters to Wandb\n",
        "    logger.log_hyperparams({\n",
        "        \"batch_size\": cfg.BATCH_SIZE,\n",
        "        \"hidden_size\": cfg.HIDDEN_SIZE,\n",
        "        \"num_layers\": cfg.NUM_LAYERS,\n",
        "        \"num_epochs\": cfg.NUM_EPOCHS,\n",
        "        \"learning_rate\": 4e-5,\n",
        "        \"weight_decay\": 5e-5\n",
        "    })\n",
        "\n",
        "    # Split data into training and validation\n",
        "    train_size = int(0.8 * len(df))\n",
        "    train_data = df.iloc[:train_size]\n",
        "    val_data = df.iloc[train_size:]\n",
        "\n",
        "    # Create Datasets\n",
        "    train_dataset = CryptoDataset(train_data, cfg.N_PAST, cfg.N_FUTURE)\n",
        "    val_dataset = CryptoDataset(val_data, cfg.N_PAST, cfg.N_FUTURE)\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=cfg.BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=cfg.NUM_WORKERS,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=cfg.BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=cfg.NUM_WORKERS,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    # Initialize Transformer Model\n",
        "    model = CryptoTransformer(\n",
        "        input_size=NUM_FEATURES,\n",
        "        d_model=cfg.HIDDEN_SIZE,\n",
        "        nhead=8,\n",
        "        num_encoder_layers=cfg.NUM_LAYERS,\n",
        "        num_decoder_layers=cfg.NUM_LAYERS,\n",
        "        dim_feedforward=2048,\n",
        "        dropout=0.2,\n",
        "        activation=\"gelu\",\n",
        "        n_future=cfg.N_FUTURE,\n",
        "        num_outputs=NUM_FEATURES,\n",
        "        max_seq_length=cfg.N_PAST + cfg.N_FUTURE\n",
        "    ).to(cfg.DEVICE)\n",
        "\n",
        "    # Initialize Loss Function\n",
        "    criterion = BalancedCryptoLoss(cfg)\n",
        "\n",
        "    # Initialize Optimizer and Scheduler\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=4e-5, weight_decay=1e-4)\n",
        "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=4, min_lr=4e-6)\n",
        "\n",
        "        # Handle Hot Restart# Create the CosineAnnealingLR scheduler\n",
        "    # Create the CosineAnnealingWarmRestarts scheduler\n",
        "    scheduler = CosineAnnealingWarmRestarts(\n",
        "        optimizer,\n",
        "        T_0=12,           # First restart after 50 epochs\n",
        "        T_mult=2,         # Double the cycle length after each restart\n",
        "        eta_min=1e-6,     # Minimum learning rate\n",
        "        last_epoch=-1,    # Start from the beginning1\n",
        "    )    # ... (rest of your code)\n",
        "\n",
        "    # Handle Hot Restart\n",
        "    if cfg.HOT_RESTART:\n",
        "        try:\n",
        "            # Load the checkpoint into LightningWrapper\n",
        "            wrapped_model = LightningWrapper.load_from_checkpoint(\n",
        "                checkpoint_path=cfg.MODEL_PATH,\n",
        "                model=model,  # Pass your model instance\n",
        "                criterion=criterion,  # Pass your criterion instance\n",
        "                optimizer=optimizer,  # Pass your optimizer instance\n",
        "                scheduler=scheduler,  # Pass your scheduler instance\n",
        "                num_epochs=cfg.NUM_EPOCHS,\n",
        "                scaler_dict=scalers,\n",
        "                val_data=val_data\n",
        "            )\n",
        "\n",
        "            # Access the underlying CryptoTransformer model if needed\n",
        "            model = wrapped_model.model\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"No checkpoint found at {cfg.MODEL_PATH}. Starting fresh.\")\n",
        "            wrapped_model = LightningWrapper(\n",
        "                model=model,\n",
        "                criterion=criterion,\n",
        "                optimizer=optimizer,\n",
        "                scheduler=scheduler,\n",
        "                num_epochs=cfg.NUM_EPOCHS,\n",
        "                scaler_dict=scalers,\n",
        "                val_data=val_data\n",
        "            )\n",
        "    # ... (rest of your code)\n",
        "    if cfg.TRAIN_FIRST:\n",
        "        # Initialize Lightning Wrapper\n",
        "        wrapped_model = LightningWrapper(\n",
        "            model=model,\n",
        "            criterion=criterion,  # Pass the initialized criterion\n",
        "            optimizer=optimizer,\n",
        "            scheduler=scheduler,\n",
        "            num_epochs=cfg.NUM_EPOCHS,\n",
        "            scaler_dict=scalers,\n",
        "            val_data=val_data\n",
        "        )\n",
        "\n",
        "        # Initialize Callbacks\n",
        "        early_stopping_callback = EarlyStopping(\n",
        "            monitor='val_loss',  # Ensure this matches the logged metric\n",
        "            patience=75,\n",
        "            mode='min'\n",
        "        )\n",
        "\n",
        "        checkpoint_callback = ModelCheckpoint(\n",
        "            monitor='val_loss',  # Ensure this matches the logged metric\n",
        "            dirpath=cfg.MODEL_SAVE_PATH,\n",
        "            filename=f'model-{cfg.VERSION_N}-{{epoch:02d}}-{{val_loss:.2f}}',\n",
        "            save_top_k=9,\n",
        "            mode='min',\n",
        "            save_weights_only=False\n",
        "        )\n",
        "\n",
        "        # Initialize Progress Bar Callback\n",
        "        progress_bar = RichProgressBar(refresh_rate=2)  # Set your desired refresh rate\n",
        "\n",
        "        # Initialize Percentile Cutoff Callback\n",
        "        perc_cutoff_callback = UpdatePercentileCutoffCallback(\n",
        "            reduction_threshold=0.8, # Set your desired reduction threshold of the reward\n",
        "            reduction_factor=0.95\n",
        "        )\n",
        "\n",
        "        # Initialize Trainer with Wandb logger and all callbacks\n",
        "        trainer = pl.Trainer(\n",
        "            max_epochs=cfg.NUM_EPOCHS,\n",
        "            logger=logger,  # Use Wandb logger here\n",
        "            accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
        "            devices=torch.cuda.device_count() if torch.cuda.is_available() else 1,\n",
        "            strategy='ddp_find_unused_parameters_true' if torch.cuda.device_count() > 1 else \"ddp_notebook\",  # Distributed Data Parallel\n",
        "            callbacks=[progress_bar, checkpoint_callback, early_stopping_callback, perc_cutoff_callback],\n",
        "            enable_progress_bar=True,\n",
        "            log_every_n_steps=10,\n",
        "            # precision=16,  # Optional: Use mixed precision for faster training\n",
        "            gradient_clip_val=50.0,  # Optional: Gradient clipping\n",
        "        )\n",
        "\n",
        "        # Start Training\n",
        "        trainer.fit(wrapped_model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
        "    else:\n",
        "        print(\"Skipping training as TRAIN_FIRST is set to False.\")\n",
        "\n",
        "    # Finalizing WandB\n",
        "    wandb.finish()\n",
        "\n",
        "    # Clean up CUDA cache\n",
        "    try:\n",
        "        torch.cuda.empty_cache()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to empty CUDA cache: {e}\")\n",
        "        pass\n",
        "\n",
        "    # Terminate the script\n",
        "    raise Exception(\"Training completed and script terminated.\")"
      ],
      "metadata": {
        "id": "7AKThxQgXDsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKqLVptwVKql"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "import multiprocessing\n",
        "import glob\n",
        "import numpy as np\n",
        "from rich.table import Table\n",
        "from rich.console import Console\n",
        "import os\n",
        "\n",
        "# Initialize Rich Console\n",
        "console = Console()\n",
        "\n",
        "# Define your CryptoTransformer class as per your implementation\n",
        "class CryptoTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_size, d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
        "                 dim_feedforward, dropout, activation, n_future, num_outputs, max_seq_length):\n",
        "        super(CryptoTransformer, self).__init__()\n",
        "        # Transformer implementation as per your code\n",
        "        self.transformer = torch.nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "        )\n",
        "        self.input_fc = torch.nn.Linear(input_size, d_model)\n",
        "        self.output_fc = torch.nn.Linear(d_model, num_outputs)\n",
        "        self.n_future = n_future\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.input_fc(src)\n",
        "        tgt = self.input_fc(tgt)\n",
        "        output = self.transformer(src, tgt)\n",
        "        output = self.output_fc(output)\n",
        "        return output\n",
        "\n",
        "# Define your CryptoLSTM class as per your implementation\n",
        "class CryptoLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size):\n",
        "        super(CryptoLSTM, self).__init__()\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                                  dropout=dropout, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
        "        # Optionally include LayerNorm if your models use it\n",
        "        if 'ln' in output_size:\n",
        "            self.ln = torch.nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        if hasattr(self, 'ln'):\n",
        "            out = self.ln(out)\n",
        "        # If the model outputs a sequence\n",
        "        if out.dim() == 3:\n",
        "            out = self.fc(out)\n",
        "        else:\n",
        "            out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Function to inverse transform data, adjusted to handle varying number of features\n",
        "def get_original_values(df_columns, input_df, target_df, prediction_df, scalers):\n",
        "    inv_pred = pd.DataFrame()\n",
        "    inv_target = pd.DataFrame()\n",
        "    inv_input = pd.DataFrame()\n",
        "    for col in prediction_df.columns:\n",
        "        scaler = scalers.get(col)\n",
        "        if scaler:\n",
        "            inv_pred[col] = np.exp(scaler.inverse_transform(prediction_df[[col]]).flatten())\n",
        "    for col in target_df.columns:\n",
        "        scaler = scalers.get(col)\n",
        "        if scaler:\n",
        "            inv_target[col] = np.exp(scaler.inverse_transform(target_df[[col]]).flatten())\n",
        "    for col in input_df.columns:\n",
        "        scaler = scalers.get(col)\n",
        "        if scaler:\n",
        "            inv_input[col] = np.exp(scaler.inverse_transform(input_df[[col]]).flatten())\n",
        "    return inv_input, inv_target, inv_pred\n",
        "\n",
        "# Function to calculate the score\n",
        "def calculate_score(inv_target, inv_pred):\n",
        "    scores = {}\n",
        "    for col in inv_target.columns:\n",
        "        # Ensure lengths match\n",
        "        min_len = min(len(inv_target[col]), len(inv_pred[col]))\n",
        "        target_col = inv_target[col][:min_len]\n",
        "        pred_col = inv_pred[col][:min_len]\n",
        "        # Calculate the absolute percentage error\n",
        "        ape = np.abs((target_col - pred_col) / target_col)\n",
        "        # Handle division by zero\n",
        "        ape = ape.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "        # Calculate the mean absolute percentage error\n",
        "        mape = ape.mean()\n",
        "        scores[col] = mape\n",
        "    # Calculate the overall score (average of individual scores)\n",
        "    overall_score = np.mean(list(scores.values()))\n",
        "    print(f\"Overall Score: {overall_score:.2%}\")\n",
        "    return overall_score\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import traceback\n",
        "def load_model(model_file, cfg, device='cpu'):\n",
        "    try:\n",
        "        if not os.path.exists(model_file):\n",
        "            print(f\"File not found: {model_file}\")\n",
        "            return None\n",
        "\n",
        "        # Load the state dict\n",
        "        state_dict = torch.load(model_file, map_location=device)\n",
        "\n",
        "        # Determine the model type\n",
        "        if any(key.startswith('transformer') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoTransformer\")\n",
        "            # Infer Transformer parameters\n",
        "            hidden_size = state_dict['transformer.encoder.layers.0.self_attn.in_proj_weight'].shape[0]\n",
        "            num_heads = state_dict['transformer.encoder.layers.0.self_attn.in_proj_weight'].shape[1] // hidden_size\n",
        "            num_layers = len([key for key in state_dict.keys() if key.startswith('transformer.encoder.layers')])\n",
        "            input_size = state_dict['transformer.encoder.layers.0.self_attn.in_proj_weight'].shape[1]\n",
        "            output_size = state_dict['transformer.decoder.layers.0.self_attn.in_proj_weight'].shape[1]\n",
        "            print(f\"Inferred Transformer parameters: hidden_size={hidden_size}, num_heads={num_heads}, num_layers={num_layers}, input_size={input_size}, output_size={output_size}\")\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoTransformer(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hidden_size,\n",
        "                num_heads=num_heads,\n",
        "                num_layers=num_layers,\n",
        "                output_size=output_size,\n",
        "                dropout=0.2\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            model.load_state_dict(state_dict, strict = False)\n",
        "\n",
        "            return model, {'input_size': input_size, 'output_size': output_size, 'n_past': cfg.N_PAST, 'n_future': cfg.N_FUTURE}\n",
        "\n",
        "        elif any(key.startswith('lstm') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoLSTM\")\n",
        "            # Infer LSTM parameters\n",
        "            hidden_size = state_dict['lstm.weight_ih_l0'].shape[0] // 4\n",
        "            num_layers = len([key for key in state_dict.keys() if key.startswith('lstm.weight_ih_l')])\n",
        "\n",
        "            input_size = state_dict['lstm.weight_ih_l0'].shape[1]\n",
        "            output_size = state_dict['fc.weight'].shape[0]\n",
        "            print(f\"Inferred LSTM parameters: hidden_size={hidden_size}, num_layers={num_layers}, input_size={input_size}, output_size={output_size}\")\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoLSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hidden_size,\n",
        "                num_layers=num_layers,\n",
        "                output_size=output_size,\n",
        "                dropout=0.2\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            model.load_state_dict(state_dict,strict=False)\n",
        "\n",
        "            return model, {'input_size': input_size, 'output_size': output_size, 'n_past': cfg.N_PAST, 'n_future': cfg.N_FUTURE}\n",
        "\n",
        "        else:\n",
        "            print(f\"Unrecognized model format for {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load model {model_file}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=10):\n",
        "    top_models = []\n",
        "    for model_file in model_files:\n",
        "        cfg.MODEL_PATH = model_file\n",
        "        print(f\"\\nLoading model from {cfg.MODEL_PATH}\")\n",
        "\n",
        "        result = load_model(cfg.MODEL_PATH, cfg, cfg.DEVICE)\n",
        "        if result is None:\n",
        "            print(f\"Skipping model {cfg.MODEL_PATH} due to loading error\")\n",
        "            continue\n",
        "\n",
        "        model, params = result\n",
        "        input_size = params['input_size']\n",
        "        output_size = params['output_size']\n",
        "        n_past = params['n_past']\n",
        "        n_future = params['n_future']\n",
        "\n",
        "        # Get the input and target columns\n",
        "        input_cols = df.columns[:input_size]\n",
        "        target_cols = df.columns[:output_size]\n",
        "\n",
        "        try:\n",
        "            input_data, target_data = get_random_sample(df, n_past, n_future, input_cols, target_cols)\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting random sample: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Prepare the tensors\n",
        "        try:\n",
        "            input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "            target_tensor = torch.tensor(target_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing tensors: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if isinstance(model, CryptoTransformer):\n",
        "                    tgt_input = torch.zeros((1, n_future, input_size), device=cfg.DEVICE)\n",
        "                    prediction = model(input_tensor, tgt_input)\n",
        "                elif isinstance(model, CryptoLSTM):\n",
        "                    prediction = model(input_tensor)\n",
        "                else:\n",
        "                    print(f\"Unknown model type for file: {model_file}\")\n",
        "                    continue\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to make predictions: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Evaluate the model\n",
        "        try:\n",
        "            loss = calculate_loss(prediction, target_tensor)\n",
        "            top_models.append((model_file, loss))\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating loss: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Sort the models by loss\n",
        "    top_models.sort(key=lambda x: x[1])\n",
        "\n",
        "    # Return the top models\n",
        "    return top_models[:top_n]\n",
        "\n",
        "\n",
        "# Function to prepare input data\n",
        "def prepare_input(input_data, device):\n",
        "    input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    return input_tensor\n",
        "\n",
        "# Function to get a random sample from the DataFrame\n",
        "def get_random_sample(df, n_past, n_future, input_cols, target_cols):\n",
        "    max_start = len(df) - n_past - n_future\n",
        "    start_idx = np.random.randint(0, max_start)\n",
        "    input_data = df[input_cols].iloc[start_idx:start_idx + n_past].values\n",
        "    target_data = df[target_cols].iloc[start_idx + n_past:start_idx + n_past + n_future].values\n",
        "    return input_data, target_data\n",
        "\n",
        "# Function to convert tensors to numpy arrays\n",
        "def convert_to_numpy(input_tensor, target, prediction):\n",
        "    input_np = input_tensor.cpu().numpy()\n",
        "    target_np = target.cpu().numpy()\n",
        "    prediction_np = prediction.cpu().numpy()\n",
        "    return input_np, target_np, prediction_np\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    VERSION_N: int = 1\n",
        "    RECORDS_TO_LOAD: int = 1205040\n",
        "    N_PAST: int = 3 * 12 * 3  # 1 week of 10-minute intervals\n",
        "    N_FUTURE: int = 1 * 12 * 2  # 1 day of 10-minute intervals\n",
        "    BATCH_SIZE: int = 5000\n",
        "    HIDDEN_SIZE: int = 256\n",
        "    NUM_LAYERS: int = 2\n",
        "    DROPOUT: float = 0.2\n",
        "    NUM_EPOCHS: int = 150\n",
        "    HOT_RESTART: bool = True\n",
        "    TRAIN_FIRST: bool = True\n",
        "    EPOCH_TO_RESTART: int = 50\n",
        "    BATCH_FACTOR: int = 81\n",
        "    DEBUG_FREQ: int = 180\n",
        "    num_cpus = multiprocessing.cpu_count()\n",
        "    NUM_WORKERS = max((num_cpus // 4 - 4), 4) if num_cpus > 16 else 4\n",
        "    DEBUG_ON: bool = False\n",
        "    DATA_URL: str = 'https://sambo.us-iad-1.linodeobjects.com/fillnan_combined_df.csv'\n",
        "    DATA_FILE: str = './data/fill_nan_df.csv'\n",
        "    MODEL_PATH: str = \"/teamspace/studios/this_studio/models/TransformerModel355/model-355-epoch=40-val_loss=0.62.ckpt\"\n",
        "    MODEL_SAVE_PATH: str = f'./yay'\n",
        "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    EPSILON: float = 1e-4\n",
        "    PATH_TO_SEARCH: str = \"/content/drive/MyDrive/Kraken\"\n",
        "    # Additional parameters\n",
        "    NUM_FEATURES: int = None  # To be set after loading data\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_and_preprocess_data(file_path: str, download_url: str = None):\n",
        "    \"\"\"\n",
        "    Load and preprocess data from a CSV file. If the file does not exist, download it.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file.\n",
        "        download_url (str, optional): URL to download the CSV file. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Preprocessed DataFrame.\n",
        "        dict: Dictionary of scalers used for each column.\n",
        "    \"\"\"\n",
        "    ic(\"Starting data loading and preprocessing...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        ic(f\"File {file_path} does not exist.\")\n",
        "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "        if download_url:\n",
        "            ic(f\"Downloading file from {download_url}...\")\n",
        "            try:\n",
        "                response = requests.get(download_url, stream=True)\n",
        "                response.raise_for_status()\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    for chunk in response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "                ic(f\"File downloaded and saved to {file_path}\")\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                ic(f\"Failed to download the file: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            ic(\"Download URL not provided. Cannot download the file.\")\n",
        "            raise FileNotFoundError(f\"The file {file_path} does not exist and no download URL was provided.\")\n",
        "\n",
        "    # Load the DataFrame\n",
        "    df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "    df = df.tail(cfg.RECORDS_TO_LOAD)\n",
        "    scalers = {}\n",
        "    start_time_preprocess = time.time()\n",
        "\n",
        "    for col in df.columns:\n",
        "        # Ensure no non-positive values before log transform\n",
        "        if (df[col] <= 0).any():\n",
        "            raise ValueError(f\"Column {col} contains non-positive values, cannot apply log transform.\")\n",
        "\n",
        "        # Apply natural logarithm transformation\n",
        "        df[col] = np.log(df[col])\n",
        "\n",
        "        # Initialize and fit MinMaxScaler\n",
        "        scaler = MinMaxScaler()\n",
        "        df[col] = scaler.fit_transform(df[[col]])\n",
        "\n",
        "        # Save the scaler\n",
        "        scalers[col] = scaler\n",
        "\n",
        "    ic(f\"Data preprocessing completed in {time.time() - start_time_preprocess:.2f} seconds\")\n",
        "    ic(f\"DataFrame shape: {df.shape}\")\n",
        "\n",
        "    return df, scalers\n",
        "\n",
        "df, scalers = load_and_preprocess_data(cfg.DATA_FILE, cfg.DATA_URL)\n",
        "cfg.NUM_FEATURES = df.shape[1]\n",
        "# def evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=10):\n",
        "#     top_models = []\n",
        "#     for model_file in model_files:\n",
        "#         cfg.MODEL_PATH = model_file\n",
        "#         print(f\"\\nLoading model from {cfg.MODEL_PATH}\")\n",
        "\n",
        "#         result = load_model(cfg.MODEL_PATH, cfg, cfg.DEVICE)\n",
        "#         if result is None:\n",
        "#             print(f\"Skipping model {cfg.MODEL_PATH} due to loading error\")\n",
        "#             continue\n",
        "\n",
        "#         model, params = result\n",
        "#         input_size = params['input_size']\n",
        "#         output_size = params['output_size']\n",
        "#         n_past = params['n_past']\n",
        "#         n_future = params['n_future']\n",
        "\n",
        "#         # Get the input and target columns\n",
        "#         input_cols = df.columns[:input_size]\n",
        "#         target_cols = df.columns[:output_size]\n",
        "\n",
        "#         try:\n",
        "#             input_data, target_data = get_random_sample(df, n_past, n_future, input_cols, target_cols)\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error getting random sample: {str(e)}\")\n",
        "#             continue\n",
        "\n",
        "#         # Prepare the tensors\n",
        "#         try:\n",
        "#             input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "#             target_tensor = torch.tensor(target_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error preparing tensors: {str(e)}\")\n",
        "#             continue\n",
        "\n",
        "#         try:\n",
        "#             model.eval()\n",
        "#             with torch.no_grad():\n",
        "#                 if isinstance(model, CryptoTransformer):\n",
        "#                     tgt_input = torch.zeros((1, n_future, input_size), device=cfg.DEVICE)\n",
        "#                     prediction = model(input_tensor, tgt_input)\n",
        "#                 elif isinstance(model, CryptoLSTM):\n",
        "#                     prediction = model(input_tensor)\n",
        "#                 else:\n",
        "#                     print(f\"Unknown model type for file: {model_file}\")\n",
        "#                     continue\n",
        "#         except Exception as e:\n",
        "#             print(f\"Failed to make predictions: {e}\")\n",
        "#             continue\n",
        "\n",
        "#         # Convert tensors to numpy\n",
        "#         input_np = input_tensor.squeeze(0).cpu().numpy()\n",
        "#         target_np = target_tensor.squeeze(0).cpu().numpy()\n",
        "#         prediction_np = prediction.squeeze(0).cpu().numpy()\n",
        "\n",
        "#         # Convert to DataFrames\n",
        "#         input_df = pd.DataFrame(input_np, columns=input_cols)\n",
        "#         target_df = pd.DataFrame(target_np, columns=target_cols)\n",
        "#         if prediction_np.ndim == 1:\n",
        "#             prediction_df = pd.DataFrame(prediction_np.reshape(-1, 1), columns=target_cols)\n",
        "#         else:\n",
        "#             prediction_df = pd.DataFrame(prediction_np, columns=target_cols)\n",
        "\n",
        "#         # Inverse transform\n",
        "#         inv_input, inv_target, inv_pred = get_original_values(df.columns, input_df, target_df, prediction_df, scalers)\n",
        "\n",
        "#         print(\"Calculating scores...\")\n",
        "#         model_score = calculate_score(inv_target, inv_pred)\n",
        "\n",
        "#         # Append and maintain top N\n",
        "#         top_models.append((model_file, model_score))\n",
        "#         top_models = sorted(top_models, key=lambda x: x[1])\n",
        "#         top_models = top_models[:top_n]\n",
        "\n",
        "#         print(f\"Current top {len(top_models)} models:\")\n",
        "#         for m, s in top_models:\n",
        "#             print(f\"  Model: {m}, Score: {s:.2%}\")\n",
        "\n",
        "#     return top_models\n",
        "\n",
        "\n",
        "# Create a list of model files\n",
        "model_files = glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.ckpt\"), recursive=True) + \\\n",
        "              glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.pth\"), recursive=True)\n",
        "print(f\"Total model files found: {len(model_files)}\")\n",
        "\n",
        "# Optionally, truncate the list for testing\n",
        "model_files = model_files[:20]  # Adjust as needed\n",
        "\n",
        "# Evaluate models and get top N\n",
        "top_n = 10\n",
        "top_models = evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=top_n)\n",
        "\n",
        "# Display Top N models\n",
        "print(f\"\\nTop {len(top_models)} models:\")\n",
        "for model_file, score in top_models:\n",
        "    print(f\"Model: {model_file}, Score: {score:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "import multiprocessing\n",
        "import glob\n",
        "import numpy as np\n",
        "from rich.table import Table\n",
        "from rich.console import Console\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from icecream import ic  # Ensure icecream is installed (`pip install icecream`)\n",
        "import traceback\n",
        "\n",
        "# Initialize Rich Console\n",
        "console = Console()\n",
        "\n",
        "# Define your CryptoTransformer class as per your implementation\n",
        "class CryptoTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_size, d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
        "                 dim_feedforward, dropout, activation, n_future, num_outputs, max_seq_length):\n",
        "        super(CryptoTransformer, self).__init__()\n",
        "        # Transformer implementation as per your code\n",
        "        self.transformer = torch.nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "        )\n",
        "        self.input_fc = torch.nn.Linear(inwarnput_size, d_model)\n",
        "        self.output_fc = torch.nn.Linear(d_model, num_outputs)\n",
        "        self.n_future = n_future\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.input_fc(src)\n",
        "        tgt = self.input_fc(tgt)\n",
        "        output = self.transformer(src, tgt)\n",
        "        output = self.output_fc(output)\n",
        "        return output\n",
        "\n",
        "# Define your CryptoLSTM class as per your implementation\n",
        "class CryptoLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size, has_ln=False):\n",
        "        super(CryptoLSTM, self).__init__()\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                                  dropout=dropout, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
        "        # Optionally include LayerNorm if your models use it\n",
        "        if has_ln:\n",
        "            self.ln = torch.nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        if hasattr(self, 'ln'):\n",
        "            out = self.ln(out)\n",
        "        # If the model outputs a sequence\n",
        "        if out.dim() == 3:\n",
        "            out = self.fc(out)\n",
        "        else:\n",
        "            out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Function to inverse transform data, adjusted to handle varying number of features\n",
        "def get_original_values(df_columns, input_df, target_df, prediction_df, scalers):\n",
        "    inv_pred = pd.DataFrame()\n",
        "    inv_target = pd.DataFrame()\n",
        "    inv_input = pd.DataFrame()\n",
        "    for col in prediction_df.columns:\n",
        "        scaler = scalers.get(col)\n",
        "        if scaler:\n",
        "            inv_pred[col] = np.exp(scaler.inverse_transform(prediction_df[[col]]).flatten())\n",
        "    for col in target_df.columns:\n",
        "        scaler = scalers.get(col)\n",
        "        if scaler:\n",
        "            inv_target[col] = np.exp(scaler.inverse_transform(target_df[[col]]).flatten())\n",
        "    for col in input_df.columns:\n",
        "        scaler = scalers.get(col)\n",
        "        if scaler:\n",
        "            inv_input[col] = np.exp(scaler.inverse_transform(input_df[[col]]).flatten())\n",
        "    return inv_input, inv_target, inv_pred\n",
        "\n",
        "# Function to calculate the score\n",
        "def calculate_score(inv_target, inv_pred):\n",
        "    scores = {}\n",
        "    for col in inv_target.columns:\n",
        "        # Ensure lengths match\n",
        "        min_len = min(len(inv_target[col]), len(inv_pred[col]))\n",
        "        target_col = inv_target[col][:min_len]\n",
        "        pred_col = inv_pred[col][:min_len]\n",
        "        # Calculate the absolute percentage error\n",
        "        ape = np.abs((target_col - pred_col) / target_col)\n",
        "        # Handle division by zero\n",
        "        ape = ape.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "        # Calculate the mean absolute percentage error\n",
        "        mape = ape.mean()\n",
        "        scores[col] = mape\n",
        "    # Calculate the overall score (average of individual scores)\n",
        "    overall_score = np.mean(list(scores.values()))\n",
        "    print(f\"Overall Score: {overall_score:.2%}\")\n",
        "    return overall_score\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*does not have many workers.*\")\n",
        "\n",
        "def load_model(model_file, cfg, device='cpu'):\n",
        "    try:\n",
        "        if not os.path.exists(model_file):\n",
        "            print(f\"File not found: {model_file}\")\n",
        "            return None\n",
        "\n",
        "        # Load the state dict\n",
        "        state_dict = torch.load(model_file, map_location=device)\n",
        "\n",
        "        # Check if it's a Lightning checkpoint\n",
        "        if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n",
        "            state_dict = state_dict['state_dict']\n",
        "\n",
        "        # Determine the model type based on key prefixes\n",
        "        if any(key.startswith('model.lstm') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoLSTM\")\n",
        "\n",
        "            # Infer LSTM parameters\n",
        "            lstm_weight_ih_keys = [k for k in state_dict.keys() if k.startswith('model.lstm.weight_ih_l')]\n",
        "            num_layers = len(lstm_weight_ih_keys)\n",
        "            if num_layers == 0:\n",
        "                print(f\"No LSTM layers found in {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "                return None\n",
        "\n",
        "            sample_weight_ih = state_dict[lstm_weight_ih_keys[0]]\n",
        "            hidden_size = sample_weight_ih.shape[0] // 4  # LSTM gates\n",
        "            input_size = sample_weight_ih.shape[1]\n",
        "\n",
        "            if 'model.fc.weight' in state_dict:\n",
        "                output_size = state_dict['model.fc.weight'].shape[0]\n",
        "            elif 'model.fc.bias' in state_dict:\n",
        "                output_size = state_dict['model.fc.bias'].shape[0]\n",
        "            else:\n",
        "                print(f\"Could not infer output_size for LSTM in {model_file}. Using default: {cfg.NUM_FEATURES}\")\n",
        "                output_size = cfg.NUM_FEATURES\n",
        "\n",
        "            # Infer if LayerNorm is present\n",
        "            has_ln = any('model.layer_norm' in key or 'model.ln' in key for key in state_dict.keys())\n",
        "            print(f\"Inferred LSTM parameters: hidden_size={hidden_size}, num_layers={num_layers}, \"\n",
        "                  f\"input_size={input_size}, output_size={output_size}, LayerNorm={has_ln}\")\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoLSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hidden_size,\n",
        "                num_layers=num_layers,\n",
        "                dropout=cfg.DROPOUT,\n",
        "                output_size=output_size,\n",
        "                has_ln=has_ln\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {'input_size': input_size, 'output_size': output_size,\n",
        "                          'n_past': cfg.N_PAST, 'n_future': cfg.N_FUTURE}\n",
        "\n",
        "        elif any(key.startswith('model.transformer') for key in state_dict.keys()):\n",
        "            # It's a Transformer model\n",
        "            print(f\"Loading {model_file} as CryptoTransformer\")\n",
        "            # Attempt to infer Transformer parameters from state_dict\n",
        "            # This is heuristic and may need adjustments based on actual model architecture\n",
        "\n",
        "            # Infer d_model from in_proj_weight of the first transformer encoder layer\n",
        "            d_model = cfg.HIDDEN_SIZE  # Default value\n",
        "            for key in state_dict.keys():\n",
        "                if 'transformer_encoder.layers.0.self_attn.in_proj_weight' in key:\n",
        "                    weight = state_dict[key]\n",
        "                    d_model = weight.shape[1] // 3  # Assuming in_proj_weight has shape (3*d_model, d_model)\n",
        "                    break\n",
        "\n",
        "            # Infer number of encoder and decoder layers\n",
        "            transformer_encoder_keys = [k for k in state_dict.keys() if 'transformer_encoder.layers.' in k]\n",
        "            num_encoder_layers = len(set(k.split('.')[3] for k in transformer_encoder_keys))\n",
        "            transformer_decoder_keys = [k for k in state_dict.keys() if 'transformer_decoder.layers.' in k]\n",
        "            num_decoder_layers = len(set(k.split('.')[3] for k in transformer_decoder_keys))\n",
        "\n",
        "            # Infer nhead from the shape of out_proj.weight\n",
        "            nhead = cfg.NHEAD if hasattr(cfg, 'NHEAD') else 8\n",
        "            if transformer_encoder_keys:\n",
        "                first_layer_key = transformer_encoder_keys[0]\n",
        "                out_proj_weight = state_dict.get(first_layer_key.replace('in_proj_weight', 'out_proj.weight'))\n",
        "                if out_proj_weight is not None:\n",
        "                    nhead = out_proj_weight.shape[1] // (d_model // nhead)\n",
        "\n",
        "            dim_feedforward = cfg.DIM_FEEDFORWARD if hasattr(cfg, 'DIM_FEEDFORWARD') else 2048\n",
        "            dropout = cfg.DROPOUT\n",
        "            activation = 'gelu'  # Defaulting to 'gelu'\n",
        "\n",
        "            print(f\"Inferred Transformer parameters: d_model={d_model}, nhead={nhead}, \"\n",
        "                  f\"num_encoder_layers={num_encoder_layers}, num_decoder_layers={num_decoder_layers}, \"\n",
        "                  f\"dim_feedforward={dim_feedforward}, dropout={dropout}, activation={activation}\")\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoTransformer(\n",
        "                input_size=cfg.NUM_FEATURES,\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                num_encoder_layers=num_encoder_layers,\n",
        "                num_decoder_layers=num_decoder_layers,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                activation=activation,\n",
        "                n_future=cfg.N_FUTURE,\n",
        "                num_outputs=cfg.NUM_FEATURES,\n",
        "                max_seq_length=cfg.N_PAST + cfg.N_FUTURE\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            # Return model and inferred parameters\n",
        "            return model, {\n",
        "                'input_size': cfg.NUM_FEATURES,\n",
        "                'output_size': cfg.NUM_FEATURES,\n",
        "                'n_past': cfg.N_PAST,\n",
        "                'n_future': cfg.N_FUTURE\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"Unrecognized model format for {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load model {model_file}: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# Function to prepare input data\n",
        "def prepare_input(input_data, device):\n",
        "    input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    return input_tensor\n",
        "\n",
        "# Function to get a random sample from the DataFrame\n",
        "def get_random_sample(df, n_past, n_future, input_cols, target_cols):\n",
        "    max_start = len(df) - n_past - n_future\n",
        "    if max_start <= 0:\n",
        "        raise ValueError(\"DataFrame is too short for the given n_past and n_future\")\n",
        "    start_idx = np.random.randint(0, max_start)\n",
        "    input_data = df[input_cols].iloc[start_idx:start_idx + n_past].values\n",
        "    target_data = df[target_cols].iloc[start_idx + n_past:start_idx + n_past + n_future].values\n",
        "    return input_data, target_data\n",
        "\n",
        "# Function to convert tensors to numpy arrays\n",
        "def convert_to_numpy(input_tensor, target, prediction):\n",
        "    input_np = input_tensor.cpu().numpy()\n",
        "    target_np = target.cpu().numpy()\n",
        "    prediction_np = prediction.cpu().numpy()\n",
        "    return input_np, target_np, prediction_np\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    VERSION_N: int = 1\n",
        "    RECORDS_TO_LOAD: int = 1205040\n",
        "    N_PAST: int = 3 * 12 * 3  # 1 week of 10-minute intervals\n",
        "    N_FUTURE: int = 1 * 12 * 2  # 1 day of 10-minute intervals\n",
        "    BATCH_SIZE: int = 5000\n",
        "    HIDDEN_SIZE: int = 256\n",
        "    NUM_LAYERS: int = 2\n",
        "    DROPOUT: float = 0.2\n",
        "    NUM_EPOCHS: int = 150\n",
        "    HOT_RESTART: bool = True\n",
        "    TRAIN_FIRST: bool = True\n",
        "    EPOCH_TO_RESTART: int = 50\n",
        "    BATCH_FACTOR: int = 81\n",
        "    DEBUG_FREQ: int = 180\n",
        "    num_cpus = multiprocessing.cpu_count()\n",
        "    NUM_WORKERS = max((num_cpus // 4 - 4), 4) if num_cpus > 16 else 4\n",
        "    DEBUG_ON: bool = False\n",
        "    DATA_URL: str = 'https://sambo.us-iad-1.linodeobjects.com/fillnan_combined_df.csv'\n",
        "    DATA_FILE: str = './data/fill_nan_df.csv'\n",
        "    MODEL_PATH: str = \"/teamspace/studios/this_studio/models/TransformerModel355/model-355-epoch=40-val_loss=0.62.ckpt\"\n",
        "    MODEL_SAVE_PATH: str = f'./yay'\n",
        "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    EPSILON: float = 1e-4\n",
        "    PATH_TO_SEARCH: str = \"/content/drive/MyDrive/Kraken\"\n",
        "    # Additional parameters\n",
        "    NUM_FEATURES: int = None  # To be set after loading data\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_and_preprocess_data(file_path: str, download_url: str = None):\n",
        "    \"\"\"\n",
        "    Load and preprocess data from a CSV file. If the file does not exist, download it.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file.\n",
        "        download_url (str, optional): URL to download the CSV file. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Preprocessed DataFrame.\n",
        "        dict: Dictionary of scalers used for each column.\n",
        "    \"\"\"\n",
        "    ic(\"Starting data loading and preprocessing...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        ic(f\"File {file_path} does not exist.\")\n",
        "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "        if download_url:\n",
        "            ic(f\"Downloading file from {download_url}...\")\n",
        "            try:\n",
        "                response = requests.get(download_url, stream=True)\n",
        "                response.raise_for_status()\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    for chunk in response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "                ic(f\"File downloaded and saved to {file_path}\")\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                ic(f\"Failed to download the file: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            ic(\"Download URL not provided. Cannot download the file.\")\n",
        "            raise FileNotFoundError(f\"The file {file_path} does not exist and no download URL was provided.\")\n",
        "\n",
        "    # Load the DataFrame\n",
        "    df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "    df = df.tail(cfg.RECORDS_TO_LOAD)\n",
        "    scalers = {}\n",
        "    start_time_preprocess = time.time()\n",
        "\n",
        "    for col in df.columns:\n",
        "        # Ensure no non-positive values before log transform\n",
        "        if (df[col] <= 0).any():\n",
        "            raise ValueError(f\"Column {col} contains non-positive values, cannot apply log transform.\")\n",
        "\n",
        "        # Apply natural logarithm transformation\n",
        "        df[col] = np.log(df[col])\n",
        "\n",
        "        # Initialize and fit MinMaxScaler\n",
        "        scaler = MinMaxScaler()\n",
        "        df[col] = scaler.fit_transform(df[[col]])\n",
        "\n",
        "        # Save the scaler\n",
        "        scalers[col] = scaler\n",
        "\n",
        "    ic(f\"Data preprocessing completed in {time.time() - start_time_preprocess:.2f} seconds\")\n",
        "    ic(f\"DataFrame shape: {df.shape}\")\n",
        "\n",
        "    return df, scalers\n",
        "\n",
        "df, scalers = load_and_preprocess_data(cfg.DATA_FILE, cfg.DATA_URL)\n",
        "cfg.NUM_FEATURES = df.shape[1]\n",
        "\n",
        "def evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=10):\n",
        "    top_models = []\n",
        "    for model_file in model_files:\n",
        "        cfg.MODEL_PATH = model_file\n",
        "        print(f\"\\nLoading model from {cfg.MODEL_PATH}\")\n",
        "\n",
        "        result = load_model(cfg.MODEL_PATH, cfg, cfg.DEVICE)\n",
        "        if result is None:\n",
        "            print(f\"Skipping model {cfg.MODEL_PATH} due to loading error\")\n",
        "            continue\n",
        "\n",
        "        model, params = result\n",
        "        input_size = params['input_size']\n",
        "        output_size = params['output_size']\n",
        "        n_past = params['n_past']\n",
        "        n_future = params['n_future']\n",
        "\n",
        "        # Get the input and target columns\n",
        "        input_cols = df.columns[:input_size]\n",
        "        target_cols = df.columns[:output_size]\n",
        "\n",
        "        try:\n",
        "            input_data, target_data = get_random_sample(df, n_past, n_future, input_cols, target_cols)\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting random sample: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Prepare the tensors\n",
        "        try:\n",
        "            input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "            target_tensor = torch.tensor(target_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing tensors: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if isinstance(model, CryptoTransformer):\n",
        "                    tgt_input = torch.zeros((1, n_future, input_size), device=cfg.DEVICE)\n",
        "                    prediction = model(input_tensor, tgt_input)\n",
        "                elif isinstance(model, CryptoLSTM):\n",
        "                    prediction = model(input_tensor)\n",
        "                else:\n",
        "                    print(f\"Unknown model type for file: {model_file}\")\n",
        "                    continue\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to make predictions: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Convert tensors to numpy\n",
        "        input_np = input_tensor.squeeze(0).cpu().numpy()\n",
        "        target_np = target_tensor.squeeze(0).cpu().numpy()\n",
        "        prediction_np = prediction.squeeze(0).cpu().numpy()\n",
        "\n",
        "        # Convert to DataFrames\n",
        "        input_df = pd.DataFrame(input_np, columns=input_cols)\n",
        "        target_df = pd.DataFrame(target_np, columns=target_cols)\n",
        "        if prediction_np.ndim == 1:\n",
        "            prediction_df = pd.DataFrame(prediction_np.reshape(-1, 1), columns=target_cols)\n",
        "        else:\n",
        "            prediction_df = pd.DataFrame(prediction_np, columns=target_cols)\n",
        "\n",
        "        # Inverse transform\n",
        "        inv_input, inv_target, inv_pred = get_original_values(df.columns, input_df, target_df, prediction_df, scalers)\n",
        "\n",
        "        print(\"Calculating scores...\")\n",
        "        model_score = calculate_score(inv_target, inv_pred)\n",
        "\n",
        "        # Append and maintain top N\n",
        "        top_models.append((model_file, model_score))\n",
        "        top_models = sorted(top_models, key=lambda x: x[1])\n",
        "        top_models = top_models[:top_n]\n",
        "\n",
        "        print(f\"Current top {len(top_models)} models:\")\n",
        "        for m, s in top_models:\n",
        "            print(f\"  Model: {m}, Score: {s:.2%}\")\n",
        "\n",
        "    return top_models\n",
        "\n",
        "# Create a list of model files\n",
        "model_files = glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.ckpt\"), recursive=True) + \\\n",
        "              glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.pth\"), recursive=True)\n",
        "print(f\"Total model files found: {len(model_files)}\")\n",
        "\n",
        "# Optionally, truncate the list for testing\n",
        "model_files = model_files[:20]  # Adjust as needed\n",
        "\n",
        "# Evaluate models and get top N\n",
        "top_n = 10\n",
        "top_models = evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=top_n)\n",
        "\n",
        "# Display Top N models\n",
        "print(f\"\\nTop {len(top_models)} models:\")\n",
        "for model_file, score in top_models:\n",
        "    print(f\"Model: {model_file}, Score: {score:.2%}\")\n"
      ],
      "metadata": {
        "id": "2QZG_1KJVL4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "import multiprocessing\n",
        "import glob\n",
        "import numpy as np\n",
        "from rich.table import Table\n",
        "from rich.console import Console\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from icecream import ic  # Ensure icecream is installed (`pip install icecream`)\n",
        "import traceback\n",
        "import warnings\n",
        "\n",
        "# Initialize Rich Console\n",
        "console = Console()\n",
        "\n",
        "# Define your CryptoTransformer class as per your implementation\n",
        "class CryptoTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_size, d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
        "                 dim_feedforward, dropout, activation, n_future, num_outputs, max_seq_length):\n",
        "        super(CryptoTransformer, self).__init__()\n",
        "        # Transformer implementation as per your code\n",
        "        self.transformer = torch.nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "        )\n",
        "        self.input_fc = torch.nn.Linear(input_size, d_model)\n",
        "        self.output_fc = torch.nn.Linear(d_model, num_outputs)\n",
        "        self.n_future = n_future\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.input_fc(src)\n",
        "        tgt = self.input_fc(tgt)\n",
        "        output = self.transformer(src, tgt)\n",
        "        output = self.output_fc(output)\n",
        "        return output\n",
        "\n",
        "# Define your CryptoLSTM class as per your implementation\n",
        "class CryptoLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size, has_ln=False):\n",
        "        super(CryptoLSTM, self).__init__()\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                                  dropout=dropout, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
        "        # Optionally include LayerNorm if your models use it\n",
        "        if has_ln:\n",
        "            self.ln = torch.nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        if hasattr(self, 'ln'):\n",
        "            out = self.ln(out)\n",
        "        # If the model outputs a sequence\n",
        "        if out.dim() == 3:\n",
        "            out = self.fc(out)\n",
        "        else:\n",
        "            out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Function to find a suitable number of attention heads\n",
        "def find_nhead(d_model, max_nhead=16, min_head_dim=8):\n",
        "    \"\"\"\n",
        "    Find the maximum nhead such that d_model is divisible by nhead\n",
        "    and the head dimension is at least min_head_dim.\n",
        "    \"\"\"\n",
        "    for nhead in range(max_nhead, 0, -1):\n",
        "        if d_model % nhead == 0:\n",
        "            head_dim = d_model // nhead\n",
        "            if head_dim >= min_head_dim:\n",
        "                return nhead\n",
        "    return 1  # Fallback to single head\n",
        "\n",
        "# Function to inverse transform data, adjusted to handle varying number of features\n",
        "def get_original_values(df_columns, input_np, target_np, prediction_np, scalers, n_future, num_features):\n",
        "    inv_pred = pd.DataFrame()\n",
        "    inv_target = pd.DataFrame()\n",
        "    inv_input = pd.DataFrame()\n",
        "\n",
        "    # Reshape prediction and target to (n_future, num_features)\n",
        "    prediction_np = prediction_np.reshape(n_future, num_features)\n",
        "    target_np = target_np.reshape(n_future, num_features)\n",
        "\n",
        "    # Inverse transform each feature across all future steps\n",
        "    for i in range(n_future):\n",
        "        for j, col in enumerate(df_columns):\n",
        "            scaler = scalers.get(col)\n",
        "            if scaler:\n",
        "                pred_val = np.exp(scaler.inverse_transform(prediction_np[i, j].reshape(1, -1)).flatten())\n",
        "                target_val = np.exp(scaler.inverse_transform(target_np[i, j].reshape(1, -1)).flatten())\n",
        "                input_val = np.exp(scalers[col].inverse_transform(input_np[j].reshape(1, -1)).flatten())\n",
        "\n",
        "                inv_pred.at[i, f\"{col}_step_{i}\"] = pred_val\n",
        "                inv_target.at[i, f\"{col}_step_{i}\"] = target_val\n",
        "                inv_input.at[i, f\"{col}_step_{i}\"] = input_val\n",
        "\n",
        "    return inv_input, inv_target, inv_pred\n",
        "\n",
        "# Function to calculate the score\n",
        "def calculate_score(inv_target, inv_pred):\n",
        "    scores = {}\n",
        "    for col in inv_target.columns:\n",
        "        # Ensure lengths match\n",
        "        min_len = min(len(inv_target[col]), len(inv_pred[col]))\n",
        "        target_col = inv_target[col][:min_len]\n",
        "        pred_col = inv_pred[col][:min_len]\n",
        "        # Calculate the absolute percentage error\n",
        "        ape = np.abs((target_col - pred_col) / target_col)\n",
        "        # Handle division by zero\n",
        "        ape = ape.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "        # Calculate the mean absolute percentage error\n",
        "        mape = ape.mean()\n",
        "        scores[col] = mape\n",
        "    # Calculate the overall score (average of individual scores)\n",
        "    overall_score = np.mean(list(scores.values()))\n",
        "    print(f\"Overall Score: {overall_score:.2%}\")\n",
        "    return overall_score\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*does not have many workers.*\")\n",
        "\n",
        "def load_model(model_file, cfg, device='cpu'):\n",
        "    try:\n",
        "        if not os.path.exists(model_file):\n",
        "            print(f\"File not found: {model_file}\")\n",
        "            return None\n",
        "\n",
        "        # Load the state dict\n",
        "        state_dict = torch.load(model_file, map_location=device)\n",
        "\n",
        "        # Check if it's a Lightning checkpoint\n",
        "        if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n",
        "            state_dict = state_dict['state_dict']\n",
        "\n",
        "        # Strip 'model.' prefix if present\n",
        "        if any(key.startswith('model.') for key in state_dict.keys()):\n",
        "            new_state_dict = {}\n",
        "            for k, v in state_dict.items():\n",
        "                if k.startswith('model.'):\n",
        "                    new_k = k[6:]  # Remove 'model.' prefix\n",
        "                else:\n",
        "                    new_k = k\n",
        "                new_state_dict[new_k] = v\n",
        "            state_dict = new_state_dict\n",
        "\n",
        "        # Determine the model type based on key prefixes\n",
        "        if any(key.startswith('lstm') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoLSTM\")\n",
        "\n",
        "            # Infer LSTM parameters\n",
        "            lstm_weight_ih_keys = [k for k in state_dict.keys() if k.startswith('lstm.weight_ih_l')]\n",
        "            num_layers = len(lstm_weight_ih_keys)\n",
        "            if num_layers == 0:\n",
        "                print(f\"No LSTM layers found in {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "                return None\n",
        "\n",
        "            sample_weight_ih = state_dict[lstm_weight_ih_keys[0]]\n",
        "            hidden_size = sample_weight_ih.shape[0] // 4  # LSTM gates\n",
        "            input_size = sample_weight_ih.shape[1]\n",
        "\n",
        "            if 'fc.weight' in state_dict:\n",
        "                output_size = state_dict['fc.weight'].shape[0]\n",
        "            elif 'fc.bias' in state_dict:\n",
        "                output_size = state_dict['fc.bias'].shape[0]\n",
        "            else:\n",
        "                print(f\"Could not infer output_size for LSTM in {model_file}. Using default: {cfg.NUM_FEATURES}\")\n",
        "                output_size = cfg.NUM_FEATURES\n",
        "\n",
        "            # Infer if LayerNorm is present\n",
        "            has_ln = any('layer_norm' in key or 'ln' in key for key in state_dict.keys())\n",
        "            print(f\"Inferred LSTM parameters: hidden_size={hidden_size}, num_layers={num_layers}, \"\n",
        "                  f\"input_size={input_size}, output_size={output_size}, LayerNorm={has_ln}\")\n",
        "\n",
        "            # Ensure output_size aligns with the data\n",
        "            expected_output_size = cfg.N_FUTURE * cfg.NUM_FEATURES\n",
        "            if output_size != expected_output_size:\n",
        "                print(f\"Model's output_size ({output_size}) does not match expected ({expected_output_size}). Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoLSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hidden_size,\n",
        "                num_layers=num_layers,\n",
        "                dropout=cfg.DROPOUT,\n",
        "                output_size=output_size,\n",
        "                has_ln=has_ln\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {'input_size': input_size, 'output_size': output_size,\n",
        "                          'n_past': cfg.N_PAST, 'n_future': cfg.N_FUTURE}\n",
        "\n",
        "        elif any(key.startswith('transformer') for key in state_dict.keys()):\n",
        "            # It's a Transformer model\n",
        "            print(f\"Loading {model_file} as CryptoTransformer\")\n",
        "            # Attempt to infer Transformer parameters from state_dict\n",
        "            # This is heuristic and may need adjustments based on actual model architecture\n",
        "\n",
        "            # Infer d_model from the first transformer's in_proj_weight\n",
        "            d_model = cfg.HIDDEN_SIZE  # Default value\n",
        "            for key in state_dict.keys():\n",
        "                if 'transformer_encoder.layers.0.self_attn.in_proj_weight' in key:\n",
        "                    weight = state_dict[key]\n",
        "                    d_model = weight.shape[1]  # Typically (3*d_model, d_model)\n",
        "                    break\n",
        "\n",
        "            # Find a suitable nhead\n",
        "            nhead = find_nhead(d_model)\n",
        "            if nhead == 1 and d_model < 8:\n",
        "                print(f\"Could not find a suitable nhead for d_model={d_model}. Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Infer number of encoder and decoder layers\n",
        "            transformer_encoder_keys = [k for k in state_dict.keys() if 'transformer_encoder.layers.' in k]\n",
        "            num_encoder_layers = len(set(k.split('.')[3] for k in transformer_encoder_keys))\n",
        "            transformer_decoder_keys = [k for k in state_dict.keys() if 'transformer_decoder.layers.' in k]\n",
        "            num_decoder_layers = len(set(k.split('.')[3] for k in transformer_decoder_keys))\n",
        "\n",
        "            # Infer dim_feedforward from the first linear layer\n",
        "            dim_feedforward = cfg.DIM_FEEDFORWARD if hasattr(cfg, 'DIM_FEEDFORWARD') else 2048\n",
        "            dropout = cfg.DROPOUT\n",
        "            activation = 'gelu'  # Defaulting to 'gelu'\n",
        "\n",
        "            print(f\"Inferred Transformer parameters: d_model={d_model}, nhead={nhead}, \"\n",
        "                  f\"num_encoder_layers={num_encoder_layers}, num_decoder_layers={num_decoder_layers}, \"\n",
        "                  f\"dim_feedforward={dim_feedforward}, dropout={dropout}, activation={activation}\")\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoTransformer(\n",
        "                input_size=cfg.NUM_FEATURES,\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                num_encoder_layers=num_encoder_layers,\n",
        "                num_decoder_layers=num_decoder_layers,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                activation=activation,\n",
        "                n_future=cfg.N_FUTURE,\n",
        "                num_outputs=cfg.N_FUTURE * cfg.NUM_FEATURES,  # Adjusted for multi-step prediction\n",
        "                max_seq_length=cfg.N_PAST + cfg.N_FUTURE\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {\n",
        "                'input_size': cfg.NUM_FEATURES,\n",
        "                'output_size': cfg.N_FUTURE * cfg.NUM_FEATURES,\n",
        "                'n_past': cfg.N_PAST,\n",
        "                'n_future': cfg.N_FUTURE\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"Unrecognized model format for {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load model {model_file}: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# Function to prepare input data\n",
        "def prepare_input(input_data, device):\n",
        "    input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    return input_tensor\n",
        "\n",
        "# Function to get a random sample from the DataFrame\n",
        "def get_random_sample(df, n_past, n_future, input_cols, target_cols):\n",
        "    max_start = len(df) - n_past - n_future\n",
        "    if max_start <= 0:\n",
        "        raise ValueError(\"DataFrame is too short for the given n_past and n_future\")\n",
        "    start_idx = np.random.randint(0, max_start)\n",
        "    input_data = df[input_cols].iloc[start_idx:start_idx + n_past].values\n",
        "    target_data = df[input_cols].iloc[start_idx + n_past:start_idx + n_past + n_future].values\n",
        "    return input_data, target_data\n",
        "\n",
        "# Function to convert tensors to numpy arrays\n",
        "def convert_to_numpy(input_tensor, target, prediction):\n",
        "    input_np = input_tensor.cpu().numpy()\n",
        "    target_np = target.cpu().numpy()\n",
        "    prediction_np = prediction.cpu().numpy()\n",
        "    return input_np, target_np, prediction_np\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    VERSION_N: int = 1\n",
        "    RECORDS_TO_LOAD: int = 1205040\n",
        "    N_PAST: int = 3 * 12 * 3  # 1 week of 10-minute intervals\n",
        "    N_FUTURE: int = 1 * 12 * 2  # 1 day of 10-minute intervals\n",
        "    BATCH_SIZE: int = 5000\n",
        "    HIDDEN_SIZE: int = 256\n",
        "    NUM_LAYERS: int = 2\n",
        "    DROPOUT: float = 0.2\n",
        "    NUM_EPOCHS: int = 150\n",
        "    HOT_RESTART: bool = True\n",
        "    TRAIN_FIRST: bool = True\n",
        "    EPOCH_TO_RESTART: int = 50\n",
        "    BATCH_FACTOR: int = 81\n",
        "    DEBUG_FREQ: int = 180\n",
        "    num_cpus = multiprocessing.cpu_count()\n",
        "    NUM_WORKERS = max((num_cpus // 4 - 4), 4) if num_cpus > 16 else 4\n",
        "    DEBUG_ON: bool = False\n",
        "    DATA_URL: str = 'https://sambo.us-iad-1.linodeobjects.com/fillnan_combined_df.csv'\n",
        "    DATA_FILE: str = './data/fill_nan_df.csv'\n",
        "    MODEL_PATH: str = \"/teamspace/studios/this_studio/models/TransformerModel355/model-355-epoch=40-val_loss=0.62.ckpt\"\n",
        "    MODEL_SAVE_PATH: str = f'./yay'\n",
        "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    EPSILON: float = 1e-4\n",
        "    PATH_TO_SEARCH: str = \"/content/drive/MyDrive/Kraken\"\n",
        "    # Additional parameters\n",
        "    NUM_FEATURES: int = None  # To be set after loading data\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_and_preprocess_data(file_path: str, download_url: str = None):\n",
        "    \"\"\"\n",
        "    Load and preprocess data from a CSV file. If the file does not exist, download it.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file.\n",
        "        download_url (str, optional): URL to download the CSV file. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Preprocessed DataFrame.\n",
        "        dict: Dictionary of scalers used for each column.\n",
        "    \"\"\"\n",
        "    ic(\"Starting data loading and preprocessing...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        ic(f\"File {file_path} does not exist.\")\n",
        "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "        if download_url:\n",
        "            ic(f\"Downloading file from {download_url}...\")\n",
        "            try:\n",
        "                response = requests.get(download_url, stream=True)\n",
        "                response.raise_for_status()\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    for chunk in response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "                ic(f\"File downloaded and saved to {file_path}\")\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                ic(f\"Failed to download the file: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            ic(\"Download URL not provided. Cannot download the file.\")\n",
        "            raise FileNotFoundError(f\"The file {file_path} does not exist and no download URL was provided.\")\n",
        "\n",
        "    # Load the DataFrame\n",
        "    df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "    df = df.tail(cfg.RECORDS_TO_LOAD)\n",
        "    scalers = {}\n",
        "    start_time_preprocess = time.time()\n",
        "\n",
        "    for col in df.columns:\n",
        "        # Ensure no non-positive values before log transform\n",
        "        if (df[col] <= 0).any():\n",
        "            raise ValueError(f\"Column {col} contains non-positive values, cannot apply log transform.\")\n",
        "\n",
        "        # Apply natural logarithm transformation\n",
        "        df[col] = np.log(df[col])\n",
        "\n",
        "        # Initialize and fit MinMaxScaler\n",
        "        scaler = MinMaxScaler()\n",
        "        df[col] = scaler.fit_transform(df[[col]])\n",
        "\n",
        "        # Save the scaler\n",
        "        scalers[col] = scaler\n",
        "\n",
        "    ic(f\"Data preprocessing completed in {time.time() - start_time_preprocess:.2f} seconds\")\n",
        "    ic(f\"DataFrame shape: {df.shape}\")\n",
        "\n",
        "    return df, scalers\n",
        "\n",
        "df, scalers = load_and_preprocess_data(cfg.DATA_FILE, cfg.DATA_URL)\n",
        "cfg.NUM_FEATURES = df.shape[1]\n",
        "\n",
        "def evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=10):\n",
        "    top_models = []\n",
        "    for model_file in model_files:\n",
        "        cfg.MODEL_PATH = model_file\n",
        "        print(f\"\\nLoading model from {cfg.MODEL_PATH}\")\n",
        "\n",
        "        result = load_model(cfg.MODEL_PATH, cfg, cfg.DEVICE)\n",
        "        if result is None:\n",
        "            print(f\"Skipping model {cfg.MODEL_PATH} due to loading error\")\n",
        "            continue\n",
        "\n",
        "        model, params = result\n",
        "        input_size = params['input_size']\n",
        "        output_size = params['output_size']\n",
        "        n_past = params['n_past']\n",
        "        n_future = params['n_future']\n",
        "        num_features = cfg.NUM_FEATURES\n",
        "\n",
        "        # Get the input columns\n",
        "        input_cols = df.columns[:input_size]\n",
        "\n",
        "        try:\n",
        "            input_data, target_data = get_random_sample(df, n_past, n_future, input_cols, input_cols)\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting random sample: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Prepare the tensors\n",
        "        try:\n",
        "            input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "            target_tensor = torch.tensor(target_data, dtype=torch.float32).to(cfg.DEVICE)\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing tensors: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if isinstance(model, CryptoTransformer):\n",
        "                    # For Transformer, prepare tgt_input with zeros\n",
        "                    tgt_input = torch.zeros((1, n_future, input_size), device=cfg.DEVICE)\n",
        "                    prediction = model(input_tensor, tgt_input)\n",
        "                elif isinstance(model, CryptoLSTM):\n",
        "                    prediction = model(input_tensor)\n",
        "                else:\n",
        "                    print(f\"Unknown model type for file: {model_file}\")\n",
        "                    continue\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to make predictions: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Convert tensors to numpy\n",
        "        input_np = input_tensor.squeeze(0).cpu().numpy()  # (n_past, num_features)\n",
        "        target_np = target_tensor.cpu().numpy()  # (n_future, num_features)\n",
        "        prediction_np = prediction.cpu().numpy()  # (1, output_size) or similar\n",
        "\n",
        "        # Handle multi-step predictions\n",
        "        if isinstance(model, CryptoTransformer) or output_size > num_features:\n",
        "            # Assume output_size = n_future * num_features\n",
        "            if output_size != n_future * num_features:\n",
        "                print(f\"Model's output_size ({output_size}) does not match n_future * num_features ({n_future * num_features}). Skipping model.\")\n",
        "                continue\n",
        "            prediction_np = prediction_np.reshape(n_future, num_features)\n",
        "            # Flatten the target_np for inverse transformation\n",
        "            target_np_flat = target_np.flatten()\n",
        "        else:\n",
        "            # Single-step prediction\n",
        "            prediction_np = prediction_np.reshape(-1, num_features)\n",
        "            target_np_flat = target_np.flatten()\n",
        "\n",
        "        # Inverse transform\n",
        "        try:\n",
        "            inv_input, inv_target, inv_pred = get_original_values(\n",
        "                df.columns, input_np, target_np, prediction_np, scalers, n_future, num_features\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error during inverse transformation: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        print(\"Calculating scores...\")\n",
        "        try:\n",
        "            model_score = calculate_score(inv_target, inv_pred)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating score: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Append and maintain top N\n",
        "        top_models.append((model_file, model_score))\n",
        "        top_models = sorted(top_models, key=lambda x: x[1])\n",
        "        top_models = top_models[:top_n]\n",
        "\n",
        "        print(f\"Current top {len(top_models)} models:\")\n",
        "        for m, s in top_models:\n",
        "            print(f\"  Model: {m}, Score: {s:.2%}\")\n",
        "\n",
        "    return top_models\n",
        "\n",
        "# Create a list of model files\n",
        "model_files = glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.ckpt\"), recursive=True) + \\\n",
        "              glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.pth\"), recursive=True)\n",
        "print(f\"Total model files found: {len(model_files)}\")\n",
        "\n",
        "# Optionally, truncate the list for testing\n",
        "model_files = model_files[:20]  # Adjust as needed\n",
        "\n",
        "# Evaluate models and get top N\n",
        "top_n = 10\n",
        "top_models = evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=top_n)\n",
        "\n",
        "# Display Top N models\n",
        "print(f\"\\nTop {len(top_models)} models:\")\n",
        "for model_file, score in top_models:\n",
        "    print(f\"Model: {model_file}, Score: {score:.2%}\")\n"
      ],
      "metadata": {
        "id": "kymgmtlw_Nrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "import multiprocessing\n",
        "import glob\n",
        "import numpy as np\n",
        "from rich.table import Table\n",
        "from rich.console import Console\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from icecream import ic  # Ensure icecream is installed (`pip install icecream`)\n",
        "import traceback\n",
        "import warnings\n",
        "\n",
        "# Initialize Rich Console\n",
        "console = Console()\n",
        "\n",
        "# Define your CryptoTransformer class as per your implementation\n",
        "class CryptoTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_size, d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
        "                 dim_feedforward, dropout, activation, n_future, num_outputs, max_seq_length):\n",
        "        super(CryptoTransformer, self).__init__()\n",
        "        # Transformer implementation as per your code\n",
        "        self.transformer = torch.nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "        )\n",
        "        self.input_fc = torch.nn.Linear(input_size, d_model)\n",
        "        self.output_fc = torch.nn.Linear(d_model, num_outputs)\n",
        "        self.n_future = n_future\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.input_fc(src)\n",
        "        tgt = self.input_fc(tgt)\n",
        "        output = self.transformer(src, tgt)\n",
        "        output = self.output_fc(output)\n",
        "        return output\n",
        "\n",
        "# Define your CryptoLSTM class as per your implementation\n",
        "class CryptoLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size, has_ln=False):\n",
        "        super(CryptoLSTM, self).__init__()\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                                  dropout=dropout, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
        "        # Optionally include LayerNorm if your models use it\n",
        "        if has_ln:\n",
        "            self.layer_norm = torch.nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        if hasattr(self, 'layer_norm'):\n",
        "            out = self.layer_norm(out)\n",
        "        # If the model outputs a sequence\n",
        "        if out.dim() == 3:\n",
        "            out = self.fc(out)\n",
        "        else:\n",
        "            out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Function to find a suitable number of attention heads\n",
        "def find_nhead(d_model, max_nhead=16, min_head_dim=8):\n",
        "    \"\"\"\n",
        "    Find the maximum nhead such that d_model is divisible by nhead\n",
        "    and the head dimension is at least min_head_dim.\n",
        "    \"\"\"\n",
        "    for nhead in range(max_nhead, 0, -1):\n",
        "        if d_model % nhead == 0:\n",
        "            head_dim = d_model // nhead\n",
        "            if head_dim >= min_head_dim:\n",
        "                return nhead\n",
        "    return 1  # Fallback to single head\n",
        "\n",
        "# Function to inverse transform data, adjusted to handle varying number of features\n",
        "def get_original_values(df_columns, input_np, target_np, prediction_np, scalers, n_future, num_features):\n",
        "    inv_pred = pd.DataFrame()\n",
        "    inv_target = pd.DataFrame()\n",
        "    inv_input = pd.DataFrame()\n",
        "\n",
        "    # Determine if the model outputs multi-step or single-step predictions\n",
        "    if prediction_np.shape[-1] == num_features:\n",
        "        # Single-step prediction\n",
        "        for i, col in enumerate(df_columns):\n",
        "            scaler = scalers.get(col)\n",
        "            if scaler:\n",
        "                inv_pred[col] = np.exp(scaler.inverse_transform(prediction_np[:, i].reshape(-1, 1)).flatten())\n",
        "                inv_target[col] = np.exp(scaler.inverse_transform(target_np[:, i].reshape(-1, 1)).flatten())\n",
        "                inv_input[col] = np.exp(scalers[col].inverse_transform(input_np[:, i].reshape(-1, 1)).flatten())\n",
        "    elif prediction_np.shape[-1] == n_future * num_features:\n",
        "        # Multi-step prediction\n",
        "        prediction_np = prediction_np.reshape(-1, n_future, num_features)\n",
        "        target_np = target_np.reshape(-1, n_future, num_features)\n",
        "        for i in range(n_future):\n",
        "            for j, col in enumerate(df_columns):\n",
        "                scaler = scalers.get(col)\n",
        "                if scaler:\n",
        "                    inv_pred[f\"{col}_step_{i}\"] = np.exp(scaler.inverse_transform(prediction_np[:, i, j].reshape(-1, 1)).flatten())\n",
        "                    inv_target[f\"{col}_step_{i}\"] = np.exp(scaler.inverse_transform(target_np[:, i, j].reshape(-1, 1)).flatten())\n",
        "                    inv_input[f\"{col}_step_{i}\"] = np.exp(scalers[col].inverse_transform(input_np[:, j].reshape(-1, 1)).flatten())\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected prediction output shape: {prediction_np.shape}\")\n",
        "\n",
        "    return inv_input, inv_target, inv_pred\n",
        "\n",
        "# Function to calculate the score\n",
        "def calculate_score(inv_target, inv_pred):\n",
        "    scores = {}\n",
        "    for col in inv_target.columns:\n",
        "        # Ensure lengths match\n",
        "        min_len = min(len(inv_target[col]), len(inv_pred[col]))\n",
        "        target_col = inv_target[col][:min_len]\n",
        "        pred_col = inv_pred[col][:min_len]\n",
        "        # Calculate the absolute percentage error\n",
        "        ape = np.abs((target_col - pred_col) / target_col)\n",
        "        # Handle division by zero\n",
        "        ape = ape.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "        # Calculate the mean absolute percentage error\n",
        "        mape = ape.mean()\n",
        "        scores[col] = mape\n",
        "    # Calculate the overall score (average of individual scores)\n",
        "    overall_score = np.mean(list(scores.values()))\n",
        "    print(f\"Overall Score: {overall_score:.2%}\")\n",
        "    return overall_score\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*does not have many workers.*\")\n",
        "\n",
        "def load_model(model_file, cfg, device='cpu'):\n",
        "    try:\n",
        "        if not os.path.exists(model_file):\n",
        "            print(f\"File not found: {model_file}\")\n",
        "            return None\n",
        "\n",
        "        # Load the state dict\n",
        "        state_dict = torch.load(model_file, map_location=device)\n",
        "\n",
        "        # Check if it's a Lightning checkpoint\n",
        "        if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n",
        "            state_dict = state_dict['state_dict']\n",
        "\n",
        "        # Strip 'model.' prefix if present\n",
        "        if any(key.startswith('model.') for key in state_dict.keys()):\n",
        "            new_state_dict = {}\n",
        "            for k, v in state_dict.items():\n",
        "                if k.startswith('model.'):\n",
        "                    new_k = k[6:]  # Remove 'model.' prefix\n",
        "                else:\n",
        "                    new_k = k\n",
        "                new_state_dict[new_k] = v\n",
        "            state_dict = new_state_dict\n",
        "\n",
        "        # Determine the model type based on key prefixes\n",
        "        if any(key.startswith('lstm') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoLSTM\")\n",
        "\n",
        "            # Infer LSTM parameters\n",
        "            lstm_weight_ih_keys = [k for k in state_dict.keys() if k.startswith('lstm.weight_ih_l')]\n",
        "            num_layers = len(lstm_weight_ih_keys)\n",
        "            if num_layers == 0:\n",
        "                print(f\"No LSTM layers found in {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "                return None\n",
        "\n",
        "            sample_weight_ih = state_dict[lstm_weight_ih_keys[0]]\n",
        "            hidden_size = sample_weight_ih.shape[0] // 4  # LSTM gates\n",
        "            input_size = sample_weight_ih.shape[1]\n",
        "\n",
        "            if 'fc.weight' in state_dict:\n",
        "                output_size = state_dict['fc.weight'].shape[0]\n",
        "            elif 'fc.bias' in state_dict:\n",
        "                output_size = state_dict['fc.bias'].shape[0]\n",
        "            else:\n",
        "                print(f\"Could not infer output_size for LSTM in {model_file}. Using default: {cfg.NUM_FEATURES}\")\n",
        "                output_size = cfg.NUM_FEATURES\n",
        "\n",
        "            # Infer if LayerNorm is present\n",
        "            has_ln = any('layer_norm' in key or 'ln' in key for key in state_dict.keys())\n",
        "            print(f\"Inferred LSTM parameters: hidden_size={hidden_size}, num_layers={num_layers}, \"\n",
        "                  f\"input_size={input_size}, output_size={output_size}, LayerNorm={has_ln}\")\n",
        "\n",
        "            # Determine expected output_size based on n_future and num_features\n",
        "            expected_output_size = cfg.N_FUTURE * cfg.NUM_FEATURES\n",
        "            if output_size != expected_output_size:\n",
        "                print(f\"Model's output_size ({output_size}) does not match expected ({expected_output_size}). Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoLSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hidden_size,\n",
        "                num_layers=num_layers,\n",
        "                dropout=cfg.DROPOUT,\n",
        "                output_size=output_size,\n",
        "                has_ln=has_ln\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {'input_size': input_size, 'output_size': output_size,\n",
        "                          'n_past': cfg.N_PAST, 'n_future': cfg.N_FUTURE}\n",
        "\n",
        "        elif any(key.startswith('transformer') for key in state_dict.keys()):\n",
        "            # It's a Transformer model\n",
        "            print(f\"Loading {model_file} as CryptoTransformer\")\n",
        "            # Attempt to infer Transformer parameters from state_dict\n",
        "            # This is heuristic and may need adjustments based on actual model architecture\n",
        "\n",
        "            # Infer d_model from the first transformer's in_proj_weight\n",
        "            d_model = cfg.HIDDEN_SIZE  # Default value\n",
        "            for key in state_dict.keys():\n",
        "                if 'transformer_encoder.layers.0.self_attn.in_proj_weight' in key:\n",
        "                    weight = state_dict[key]\n",
        "                    d_model = weight.shape[1]  # Typically (3*d_model, d_model)\n",
        "                    break\n",
        "\n",
        "            # Find a suitable nhead\n",
        "            nhead = find_nhead(d_model)\n",
        "            if nhead == 1 and d_model < 8:\n",
        "                print(f\"Could not find a suitable nhead for d_model={d_model}. Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Infer number of encoder and decoder layers\n",
        "            transformer_encoder_keys = [k for k in state_dict.keys() if 'transformer_encoder.layers.' in k]\n",
        "            num_encoder_layers = len(set(k.split('.')[3] for k in transformer_encoder_keys))\n",
        "            transformer_decoder_keys = [k for k in state_dict.keys() if 'transformer_decoder.layers.' in k]\n",
        "            num_decoder_layers = len(set(k.split('.')[3] for k in transformer_decoder_keys))\n",
        "\n",
        "            # Infer dim_feedforward from the first linear layer\n",
        "            dim_feedforward = cfg.DIM_FEEDFORWARD if hasattr(cfg, 'DIM_FEEDFORWARD') else 2048\n",
        "            dropout = cfg.DROPOUT\n",
        "            activation = 'gelu'  # Defaulting to 'gelu'\n",
        "\n",
        "            print(f\"Inferred Transformer parameters: d_model={d_model}, nhead={nhead}, \"\n",
        "                  f\"num_encoder_layers={num_encoder_layers}, num_decoder_layers={num_decoder_layers}, \"\n",
        "                  f\"dim_feedforward={dim_feedforward}, dropout={dropout}, activation={activation}\")\n",
        "\n",
        "            # Infer num_outputs based on state_dict\n",
        "            if 'output_fc.weight' in state_dict:\n",
        "                num_outputs = state_dict['output_fc.weight'].shape[0]\n",
        "            else:\n",
        "                num_outputs = cfg.N_FUTURE * cfg.NUM_FEATURES  # Default assumption\n",
        "\n",
        "            # Check if num_outputs is divisible by num_features to determine n_future\n",
        "            if num_outputs % cfg.NUM_FEATURES == 0:\n",
        "                n_future_model = num_outputs // cfg.NUM_FEATURES\n",
        "            else:\n",
        "                n_future_model = 1  # Single-step prediction\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoTransformer(\n",
        "                input_size=cfg.NUM_FEATURES,\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                num_encoder_layers=num_encoder_layers,\n",
        "                num_decoder_layers=num_decoder_layers,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                activation=activation,\n",
        "                n_future=n_future_model,\n",
        "                num_outputs=num_outputs,\n",
        "                max_seq_length=cfg.N_PAST + cfg.N_FUTURE\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {\n",
        "                'input_size': cfg.NUM_FEATURES,\n",
        "                'output_size': num_outputs,\n",
        "                'n_past': cfg.N_PAST,\n",
        "                'n_future': n_future_model\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"Unrecognized model format for {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load model {model_file}: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# Function to prepare input data\n",
        "def prepare_input(input_data, device):\n",
        "    input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    return input_tensor\n",
        "\n",
        "# Function to get a random sample from the DataFrame\n",
        "def get_random_sample(df, n_past, n_future, input_cols, target_cols):\n",
        "    max_start = len(df) - n_past - n_future\n",
        "    if max_start <= 0:\n",
        "        raise ValueError(\"DataFrame is too short for the given n_past and n_future\")\n",
        "    start_idx = np.random.randint(0, max_start)\n",
        "    input_data = df[input_cols].iloc[start_idx:start_idx + n_past].values\n",
        "    target_data = df[target_cols].iloc[start_idx + n_past:start_idx + n_past + n_future].values\n",
        "    return input_data, target_data\n",
        "\n",
        "# Function to convert tensors to numpy arrays\n",
        "def convert_to_numpy(input_tensor, target, prediction):\n",
        "    input_np = input_tensor.cpu().numpy()\n",
        "    target_np = target.cpu().numpy()\n",
        "    prediction_np = prediction.cpu().numpy()\n",
        "    return input_np, target_np, prediction_np\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    VERSION_N: int = 1\n",
        "    RECORDS_TO_LOAD: int = 1205040\n",
        "    N_PAST: int = 3 * 12 * 3  # 1 week of 10-minute intervals\n",
        "    N_FUTURE: int = 1 * 12 * 2  # 1 day of 10-minute intervals\n",
        "    BATCH_SIZE: int = 5000\n",
        "    HIDDEN_SIZE: int = 512  # Adjusted to match inferred d_model=512\n",
        "    NUM_LAYERS: int = 2\n",
        "    DROPOUT: float = 0.2\n",
        "    NUM_EPOCHS: int = 150\n",
        "    HOT_RESTART: bool = True\n",
        "    TRAIN_FIRST: bool = True\n",
        "    EPOCH_TO_RESTART: int = 50\n",
        "    BATCH_FACTOR: int = 81\n",
        "    DEBUG_FREQ: int = 180\n",
        "    num_cpus = multiprocessing.cpu_count()\n",
        "    NUM_WORKERS = max((num_cpus // 4 - 4), 4) if num_cpus > 16 else 4\n",
        "    DEBUG_ON: bool = False\n",
        "    DATA_URL: str = 'https://sambo.us-iad-1.linodeobjects.com/fillnan_combined_df.csv'\n",
        "    DATA_FILE: str = './data/fill_nan_df.csv'\n",
        "    MODEL_PATH: str = \"/teamspace/studios/this_studio/models/TransformerModel355/model-355-epoch=40-val_loss=0.62.ckpt\"\n",
        "    MODEL_SAVE_PATH: str = f'./yay'\n",
        "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    EPSILON: float = 1e-4\n",
        "    PATH_TO_SEARCH: str = \"/content/drive/MyDrive/Kraken\"\n",
        "    # Additional parameters\n",
        "    NUM_FEATURES: int = None  # To be set after loading data\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_and_preprocess_data(file_path: str, download_url: str = None):\n",
        "    \"\"\"\n",
        "    Load and preprocess data from a CSV file. If the file does not exist, download it.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file.\n",
        "        download_url (str, optional): URL to download the CSV file. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Preprocessed DataFrame.\n",
        "        dict: Dictionary of scalers used for each column.\n",
        "    \"\"\"\n",
        "    ic(\"Starting data loading and preprocessing...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        ic(f\"File {file_path} does not exist.\")\n",
        "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "        if download_url:\n",
        "            ic(f\"Downloading file from {download_url}...\")\n",
        "            try:\n",
        "                response = requests.get(download_url, stream=True)\n",
        "                response.raise_for_status()\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    for chunk in response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "                ic(f\"File downloaded and saved to {file_path}\")\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                ic(f\"Failed to download the file: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            ic(\"Download URL not provided. Cannot download the file.\")\n",
        "            raise FileNotFoundError(f\"The file {file_path} does not exist and no download URL was provided.\")\n",
        "\n",
        "    # Load the DataFrame\n",
        "    df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "    df = df.tail(cfg.RECORDS_TO_LOAD)\n",
        "    scalers = {}\n",
        "    start_time_preprocess = time.time()\n",
        "\n",
        "    for col in df.columns:\n",
        "        # Ensure no non-positive values before log transform\n",
        "        if (df[col] <= 0).any():\n",
        "            raise ValueError(f\"Column {col} contains non-positive values, cannot apply log transform.\")\n",
        "\n",
        "        # Apply natural logarithm transformation\n",
        "        df[col] = np.log(df[col])\n",
        "\n",
        "        # Initialize and fit MinMaxScaler\n",
        "        scaler = MinMaxScaler()\n",
        "        df[col] = scaler.fit_transform(df[[col]])\n",
        "\n",
        "        # Save the scaler\n",
        "        scalers[col] = scaler\n",
        "\n",
        "    ic(f\"Data preprocessing completed in {time.time() - start_time_preprocess:.2f} seconds\")\n",
        "    ic(f\"DataFrame shape: {df.shape}\")\n",
        "\n",
        "    return df, scalers\n",
        "\n",
        "df, scalers = load_and_preprocess_data(cfg.DATA_FILE, cfg.DATA_URL)\n",
        "cfg.NUM_FEATURES = df.shape[1]\n",
        "\n",
        "def evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=10):\n",
        "    top_models = []\n",
        "    for model_file in model_files:\n",
        "        cfg.MODEL_PATH = model_file\n",
        "        print(f\"\\nLoading model from {cfg.MODEL_PATH}\")\n",
        "\n",
        "        result = load_model(cfg.MODEL_PATH, cfg, cfg.DEVICE)\n",
        "        if result is None:\n",
        "            print(f\"Skipping model {cfg.MODEL_PATH} due to loading error\")\n",
        "            continue\n",
        "\n",
        "        model, params = result\n",
        "        input_size = params['input_size']\n",
        "        output_size = params['output_size']\n",
        "        n_past = params['n_past']\n",
        "        n_future = params['n_future']\n",
        "        num_features = cfg.NUM_FEATURES\n",
        "\n",
        "        # Get the input columns\n",
        "        input_cols = df.columns[:input_size]\n",
        "\n",
        "        try:\n",
        "            input_data, target_data = get_random_sample(df, n_past, n_future, input_cols, input_cols)\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting random sample: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Prepare the tensors\n",
        "        try:\n",
        "            input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "            target_tensor = torch.tensor(target_data, dtype=torch.float32).to(cfg.DEVICE)\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing tensors: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if isinstance(model, CryptoTransformer):\n",
        "                    # For Transformer, prepare tgt_input with zeros\n",
        "                    tgt_input = torch.zeros((1, n_future, input_size), device=cfg.DEVICE)\n",
        "                    prediction = model(input_tensor, tgt_input)\n",
        "                elif isinstance(model, CryptoLSTM):\n",
        "                    prediction = model(input_tensor)\n",
        "                else:\n",
        "                    print(f\"Unknown model type for file: {model_file}\")\n",
        "                    continue\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to make predictions: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Convert tensors to numpy\n",
        "        input_np = input_tensor.squeeze(0).cpu().numpy()  # (n_past, num_features)\n",
        "        target_np = target_tensor.cpu().numpy()  # (n_future, num_features)\n",
        "        prediction_np = prediction.cpu().numpy()  # (1, output_size) or similar\n",
        "\n",
        "        # Handle multi-step predictions\n",
        "        try:\n",
        "            if isinstance(model, CryptoTransformer) or output_size == n_future * num_features:\n",
        "                # Multi-step prediction\n",
        "                if output_size != n_future * num_features:\n",
        "                    print(f\"Model's output_size ({output_size}) does not match n_future * num_features ({n_future * num_features}). Skipping model.\")\n",
        "                    continue\n",
        "                prediction_np = prediction_np.reshape(-1, n_future, num_features)\n",
        "                target_np = target_np.reshape(-1, n_future, num_features)\n",
        "                input_np = input_np.reshape(-1, num_features)\n",
        "            elif output_size == num_features:\n",
        "                # Single-step prediction\n",
        "                prediction_np = prediction_np.reshape(-1, num_features)\n",
        "                target_np = target_np.reshape(-1, num_features)\n",
        "                input_np = input_np.reshape(-1, num_features)\n",
        "            else:\n",
        "                print(f\"Unexpected output_size ({output_size}) for model {model_file}. Skipping model.\")\n",
        "                continue\n",
        "        except ValueError as ve:\n",
        "            print(f\"ValueError during reshaping: {ve}. Skipping model.\")\n",
        "            continue\n",
        "\n",
        "        # Inverse transform\n",
        "        try:\n",
        "            inv_input, inv_target, inv_pred = get_original_values(\n",
        "                df.columns, input_np, target_np, prediction_np, scalers, n_future, num_features\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error during inverse transformation: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        print(\"Calculating scores...\")\n",
        "        try:\n",
        "            model_score = calculate_score(inv_target, inv_pred)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating score: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Append and maintain top N\n",
        "        top_models.append((model_file, model_score))\n",
        "        top_models = sorted(top_models, key=lambda x: x[1])\n",
        "        top_models = top_models[:top_n]\n",
        "\n",
        "        print(f\"Current top {len(top_models)} models:\")\n",
        "        for m, s in top_models:\n",
        "            print(f\"  Model: {m}, Score: {s:.2%}\")\n",
        "\n",
        "    return top_models\n",
        "\n",
        "# Create a list of model files\n",
        "model_files = glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.ckpt\"), recursive=True) + \\\n",
        "              glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.pth\"), recursive=True)\n",
        "print(f\"Total model files found: {len(model_files)}\")\n",
        "\n",
        "# Optionally, truncate the list for testing\n",
        "model_files = model_files[:20]  # Adjust as needed\n",
        "\n",
        "# Evaluate models and get top N\n",
        "top_n = 10\n",
        "top_models = evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=top_n)\n",
        "\n",
        "# Display Top N models\n",
        "print(f\"\\nTop {len(top_models)} models:\")\n",
        "for model_file, score in top_models:\n",
        "    print(f\"Model: {model_file}, Score: {score:.2%}\")\n"
      ],
      "metadata": {
        "id": "nMbML_RyGDWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "import multiprocessing\n",
        "import glob\n",
        "import numpy as np\n",
        "from rich.table import Table\n",
        "from rich.console import Console\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from icecream import ic  # Ensure icecream is installed (`pip install icecream`)\n",
        "import traceback\n",
        "import warnings\n",
        "\n",
        "# Initialize Rich Console\n",
        "console = Console()\n",
        "\n",
        "# Define your CryptoTransformer class as per your implementation\n",
        "class CryptoTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_size, d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
        "                 dim_feedforward, dropout, activation, n_future, num_outputs, max_seq_length):\n",
        "        super(CryptoTransformer, self).__init__()\n",
        "        # Transformer implementation as per your code\n",
        "        self.transformer = torch.nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "        )\n",
        "        self.input_fc = torch.nn.Linear(input_size, d_model)\n",
        "        self.output_fc = torch.nn.Linear(d_model, num_outputs)\n",
        "        self.n_future = n_future\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.input_fc(src)\n",
        "        tgt = self.input_fc(tgt)\n",
        "        output = self.transformer(src, tgt)\n",
        "        output = self.output_fc(output)\n",
        "        return output\n",
        "\n",
        "# Define your CryptoLSTM class with corrected LayerNorm naming\n",
        "class CryptoLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size, has_layer_norm=False):\n",
        "        super(CryptoLSTM, self).__init__()\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                                  dropout=dropout, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
        "        # Optionally include LayerNorm if your models use it\n",
        "        if has_layer_norm:\n",
        "            self.layer_norm = torch.nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        if hasattr(self, 'layer_norm'):\n",
        "            out = self.layer_norm(out)\n",
        "        # If the model outputs a sequence\n",
        "        if out.dim() == 3:\n",
        "            out = self.fc(out)\n",
        "        else:\n",
        "            out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Function to find a suitable number of attention heads\n",
        "def find_nhead(d_model, max_nhead=16, min_head_dim=8):\n",
        "    \"\"\"\n",
        "    Find the maximum nhead such that d_model is divisible by nhead\n",
        "    and the head dimension is at least min_head_dim.\n",
        "    \"\"\"\n",
        "    for nhead in range(max_nhead, 0, -1):\n",
        "        if d_model % nhead == 0:\n",
        "            head_dim = d_model // nhead\n",
        "            if head_dim >= min_head_dim:\n",
        "                return nhead\n",
        "    return 1  # Fallback to single head\n",
        "\n",
        "# Function to inverse transform data, adjusted to handle varying number of features\n",
        "def get_original_values(df_columns, input_np, target_np, prediction_np, scalers, n_future, num_features):\n",
        "    inv_pred = pd.DataFrame()\n",
        "    inv_target = pd.DataFrame()\n",
        "    inv_input = pd.DataFrame()\n",
        "\n",
        "    # Determine if the model outputs multi-step or single-step predictions\n",
        "    if prediction_np.shape[-1] == num_features:\n",
        "        # Single-step prediction\n",
        "        for i, col in enumerate(df_columns):\n",
        "            scaler = scalers.get(col)\n",
        "            if scaler:\n",
        "                inv_pred[col] = np.exp(scaler.inverse_transform(prediction_np[:, i].reshape(-1, 1)).flatten())\n",
        "                inv_target[col] = np.exp(scaler.inverse_transform(target_np[:, i].reshape(-1, 1)).flatten())\n",
        "                inv_input[col] = np.exp(scalers[col].inverse_transform(input_np[:, i].reshape(-1, 1)).flatten())\n",
        "    elif prediction_np.shape[-1] == n_future * num_features:\n",
        "        # Multi-step prediction\n",
        "        prediction_np = prediction_np.reshape(-1, n_future, num_features)\n",
        "        target_np = target_np.reshape(-1, n_future, num_features)\n",
        "        input_np = input_np.reshape(-1, num_features)\n",
        "        for i in range(n_future):\n",
        "            for j, col in enumerate(df_columns):\n",
        "                scaler = scalers.get(col)\n",
        "                if scaler:\n",
        "                    inv_pred[f\"{col}_step_{i}\"] = np.exp(scaler.inverse_transform(prediction_np[:, i, j].reshape(-1, 1)).flatten())\n",
        "                    inv_target[f\"{col}_step_{i}\"] = np.exp(scaler.inverse_transform(target_np[:, i, j].reshape(-1, 1)).flatten())\n",
        "                    inv_input[f\"{col}_step_{i}\"] = np.exp(scalers[col].inverse_transform(input_np[:, j].reshape(-1, 1)).flatten())\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected prediction output shape: {prediction_np.shape}\")\n",
        "\n",
        "    return inv_input, inv_target, inv_pred\n",
        "\n",
        "# Function to calculate the score\n",
        "def calculate_score(inv_target, inv_pred):\n",
        "    scores = {}\n",
        "    for col in inv_target.columns:\n",
        "        # Ensure lengths match\n",
        "        min_len = min(len(inv_target[col]), len(inv_pred[col]))\n",
        "        target_col = inv_target[col][:min_len]\n",
        "        pred_col = inv_pred[col][:min_len]\n",
        "        # Calculate the absolute percentage error\n",
        "        ape = np.abs((target_col - pred_col) / target_col)\n",
        "        # Handle division by zero\n",
        "        ape = ape.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "        # Calculate the mean absolute percentage error\n",
        "        mape = ape.mean()\n",
        "        scores[col] = mape\n",
        "    # Calculate the overall score (average of individual scores)\n",
        "    overall_score = np.mean(list(scores.values()))\n",
        "    print(f\"Overall Score: {overall_score:.2%}\")\n",
        "    return overall_score\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*does not have many workers.*\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*torch.load.*\")\n",
        "\n",
        "def load_model(model_file, cfg, device='cpu'):\n",
        "    try:\n",
        "        if not os.path.exists(model_file):\n",
        "            print(f\"File not found: {model_file}\")\n",
        "            return None\n",
        "\n",
        "        # Load the state dict\n",
        "        state_dict = torch.load(model_file, map_location=device)\n",
        "\n",
        "        # Check if it's a Lightning checkpoint\n",
        "        if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n",
        "            state_dict = state_dict['state_dict']\n",
        "\n",
        "        # Strip 'model.' prefix if present\n",
        "        if any(key.startswith('model.') for key in state_dict.keys()):\n",
        "            new_state_dict = {}\n",
        "            for k, v in state_dict.items():\n",
        "                if k.startswith('model.'):\n",
        "                    new_k = k[6:]  # Remove 'model.' prefix\n",
        "                else:\n",
        "                    new_k = k\n",
        "                new_state_dict[new_k] = v\n",
        "            state_dict = new_state_dict\n",
        "\n",
        "        # Determine the model type based on key prefixes\n",
        "        if any(key.startswith('lstm') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoLSTM\")\n",
        "\n",
        "            # Infer LSTM parameters\n",
        "            lstm_weight_ih_keys = [k for k in state_dict.keys() if k.startswith('lstm.weight_ih_l')]\n",
        "            num_layers = len(lstm_weight_ih_keys)\n",
        "            if num_layers == 0:\n",
        "                print(f\"No LSTM layers found in {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "                return None\n",
        "\n",
        "            sample_weight_ih = state_dict[lstm_weight_ih_keys[0]]\n",
        "            hidden_size = sample_weight_ih.shape[0] // 4  # LSTM gates\n",
        "            input_size = sample_weight_ih.shape[1]\n",
        "\n",
        "            if 'fc.weight' in state_dict:\n",
        "                output_size = state_dict['fc.weight'].shape[0]\n",
        "            elif 'fc.bias' in state_dict:\n",
        "                output_size = state_dict['fc.bias'].shape[0]\n",
        "            else:\n",
        "                print(f\"Could not infer output_size for LSTM in {model_file}. Using default: {cfg.NUM_FEATURES}\")\n",
        "                output_size = cfg.NUM_FEATURES\n",
        "\n",
        "            # Infer if LayerNorm is present\n",
        "            has_layer_norm = any('layer_norm' in key or 'ln' in key for key in state_dict.keys())\n",
        "            print(f\"Inferred LSTM parameters: hidden_size={hidden_size}, num_layers={num_layers}, \"\n",
        "                  f\"input_size={input_size}, output_size={output_size}, LayerNorm={has_layer_norm}\")\n",
        "\n",
        "            # Determine expected output_size based on n_future and num_features\n",
        "            expected_output_size = cfg.N_FUTURE * cfg.NUM_FEATURES\n",
        "            if output_size != expected_output_size:\n",
        "                print(f\"Model's output_size ({output_size}) does not match expected ({expected_output_size}). Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoLSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hidden_size,\n",
        "                num_layers=num_layers,\n",
        "                dropout=cfg.DROPOUT,\n",
        "                output_size=output_size,\n",
        "                has_layer_norm=has_layer_norm\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {'input_size': input_size, 'output_size': output_size,\n",
        "                          'n_past': cfg.N_PAST, 'n_future': cfg.N_FUTURE}\n",
        "\n",
        "        elif any(key.startswith('transformer') for key in state_dict.keys()):\n",
        "            # It's a Transformer model\n",
        "            print(f\"Loading {model_file} as CryptoTransformer\")\n",
        "            # Attempt to infer Transformer parameters from state_dict\n",
        "            # This is heuristic and may need adjustments based on actual model architecture\n",
        "\n",
        "            # Infer d_model from the first transformer's in_proj_weight\n",
        "            d_model = cfg.HIDDEN_SIZE  # Default value\n",
        "            for key in state_dict.keys():\n",
        "                if 'transformer_encoder.layers.0.self_attn.in_proj_weight' in key:\n",
        "                    weight = state_dict[key]\n",
        "                    d_model = weight.shape[1]  # Typically (3*d_model, d_model)\n",
        "                    break\n",
        "\n",
        "            # Find a suitable nhead\n",
        "            nhead = find_nhead(d_model)\n",
        "            if nhead == 1 and d_model < 8:\n",
        "                print(f\"Could not find a suitable nhead for d_model={d_model}. Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Infer number of encoder and decoder layers\n",
        "            transformer_encoder_keys = [k for k in state_dict.keys() if 'transformer_encoder.layers.' in k]\n",
        "            num_encoder_layers = len(set(k.split('.')[3] for k in transformer_encoder_keys))\n",
        "            transformer_decoder_keys = [k for k in state_dict.keys() if 'transformer_decoder.layers.' in k]\n",
        "            num_decoder_layers = len(set(k.split('.')[3] for k in transformer_decoder_keys))\n",
        "\n",
        "            # Infer dim_feedforward from the first linear layer\n",
        "            dim_feedforward = cfg.DIM_FEEDFORWARD if hasattr(cfg, 'DIM_FEEDFORWARD') else 2048\n",
        "            dropout = cfg.DROPOUT\n",
        "            activation = 'gelu'  # Defaulting to 'gelu'\n",
        "\n",
        "            print(f\"Inferred Transformer parameters: d_model={d_model}, nhead={nhead}, \"\n",
        "                  f\"num_encoder_layers={num_encoder_layers}, num_decoder_layers={num_decoder_layers}, \"\n",
        "                  f\"dim_feedforward={dim_feedforward}, dropout={dropout}, activation={activation}\")\n",
        "\n",
        "            # Infer num_outputs based on state_dict\n",
        "            if 'output_fc.weight' in state_dict:\n",
        "                num_outputs = state_dict['output_fc.weight'].shape[0]\n",
        "            else:\n",
        "                num_outputs = cfg.N_FUTURE * cfg.NUM_FEATURES  # Default assumption\n",
        "\n",
        "            # Check if num_outputs is divisible by num_features to determine n_future\n",
        "            if num_outputs % cfg.NUM_FEATURES == 0:\n",
        "                n_future_model = num_outputs // cfg.NUM_FEATURES\n",
        "            elif num_outputs == cfg.NUM_FEATURES:\n",
        "                n_future_model = 1  # Single-step prediction\n",
        "            else:\n",
        "                print(f\"Unexpected num_outputs ({num_outputs}) for model {model_file}. Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Ensure that we are only processing models trained with 13 features\n",
        "            if cfg.NUM_FEATURES != 13:\n",
        "                print(f\"Model {model_file} uses {cfg.NUM_FEATURES} features instead of 13. Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoTransformer(\n",
        "                input_size=cfg.NUM_FEATURES,\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                num_encoder_layers=num_encoder_layers,\n",
        "                num_decoder_layers=num_decoder_layers,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                activation=activation,\n",
        "                n_future=n_future_model,\n",
        "                num_outputs=num_outputs,\n",
        "                max_seq_length=cfg.N_PAST + cfg.N_FUTURE\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {\n",
        "                'input_size': cfg.NUM_FEATURES,\n",
        "                'output_size': num_outputs,\n",
        "                'n_past': cfg.N_PAST,\n",
        "                'n_future': n_future_model\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"Unrecognized model format for {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model {model_file}: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "    # Function to prepare input data\n",
        "    def prepare_input(input_data, device):\n",
        "        input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "        return input_tensor\n",
        "\n",
        "    # Function to get a random sample from the DataFrame\n",
        "    def get_random_sample(df, n_past, n_future, input_cols, target_cols):\n",
        "        max_start = len(df) - n_past - n_future\n",
        "        if max_start <= 0:\n",
        "            raise ValueError(\"DataFrame is too short for the given n_past and n_future\")\n",
        "        start_idx = np.random.randint(0, max_start)\n",
        "        input_data = df[input_cols].iloc[start_idx:start_idx + n_past].values\n",
        "        target_data = df[target_cols].iloc[start_idx + n_past:start_idx + n_past + n_future].values\n",
        "        return input_data, target_data\n",
        "\n",
        "    # Function to convert tensors to numpy arrays\n",
        "    def convert_to_numpy(input_tensor, target, prediction):\n",
        "        input_np = input_tensor.cpu().numpy()\n",
        "        target_np = target.cpu().numpy()\n",
        "        prediction_np = prediction.cpu().numpy()\n",
        "        return input_np, target_np, prediction_np\n",
        "\n",
        "    @dataclass\n",
        "    class Config:\n",
        "        VERSION_N: int = 1\n",
        "        RECORDS_TO_LOAD: int = 1205040\n",
        "        N_PAST: int = 3 * 12 * 3  # 1 week of 10-minute intervals (108)\n",
        "        N_FUTURE: int = 1 * 12 * 2  # 1 day of 10-minute intervals (24)\n",
        "        BATCH_SIZE: int = 5000\n",
        "        HIDDEN_SIZE: int = 512  # Adjusted to match inferred d_model=512\n",
        "        NUM_LAYERS: int = 2\n",
        "        DROPOUT: float = 0.2\n",
        "        NUM_EPOCHS: int = 150\n",
        "        HOT_RESTART: bool = True\n",
        "        TRAIN_FIRST: bool = True\n",
        "        EPOCH_TO_RESTART: int = 50\n",
        "        BATCH_FACTOR: int = 81\n",
        "        DEBUG_FREQ: int = 180\n",
        "        num_cpus = multiprocessing.cpu_count()\n",
        "        NUM_WORKERS = max((num_cpus // 4 - 4), 4) if num_cpus > 16 else 4\n",
        "        DEBUG_ON: bool = False\n",
        "        DATA_URL: str = 'https://sambo.us-iad-1.linodeobjects.com/fillnan_combined_df.csv'\n",
        "        DATA_FILE: str = './data/fill_nan_df.csv'\n",
        "        MODEL_PATH: str = \"/teamspace/studios/this_studio/models/TransformerModel355/model-355-epoch=40-val_loss=0.62.ckpt\"\n",
        "        MODEL_SAVE_PATH: str = f'./yay'\n",
        "        DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        EPSILON: float = 1e-4\n",
        "        PATH_TO_SEARCH: str = \"/content/drive/MyDrive/Kraken\"\n",
        "        # Additional parameters\n",
        "        NUM_FEATURES: int = None  # To be set after loading data\n",
        "\n",
        "    cfg = Config()\n",
        "\n",
        "    # Load and preprocess data\n",
        "    def load_and_preprocess_data(file_path: str, download_url: str = None):\n",
        "        \"\"\"\n",
        "        Load and preprocess data from a CSV file. If the file does not exist, download it.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to the CSV file.\n",
        "            download_url (str, optional): URL to download the CSV file. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Preprocessed DataFrame.\n",
        "            dict: Dictionary of scalers used for each column.\n",
        "        \"\"\"\n",
        "        ic(\"Starting data loading and preprocessing...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Check if the file exists\n",
        "        if not os.path.exists(file_path):\n",
        "            ic(f\"File {file_path} does not exist.\")\n",
        "            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "            if download_url:\n",
        "                ic(f\"Downloading file from {download_url}...\")\n",
        "                try:\n",
        "                    response = requests.get(download_url, stream=True)\n",
        "                    response.raise_for_status()\n",
        "                    with open(file_path, 'wb') as f:\n",
        "                        for chunk in response.iter_content(chunk_size=8192):\n",
        "                            f.write(chunk)\n",
        "                    ic(f\"File downloaded and saved to {file_path}\")\n",
        "                except requests.exceptions.RequestException as e:\n",
        "                    ic(f\"Failed to download the file: {e}\")\n",
        "                    raise\n",
        "            else:\n",
        "                ic(\"Download URL not provided. Cannot download the file.\")\n",
        "                raise FileNotFoundError(f\"The file {file_path} does not exist and no download URL was provided.\")\n",
        "\n",
        "        # Load the DataFrame\n",
        "        df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
        "        df.set_index('timestamp', inplace=True)\n",
        "        df = df.tail(cfg.RECORDS_TO_LOAD)\n",
        "        scalers = {}\n",
        "        start_time_preprocess = time.time()\n",
        "\n",
        "        for col in df.columns:\n",
        "            # Ensure no non-positive values before log transform\n",
        "            if (df[col] <= 0).any():\n",
        "                raise ValueError(f\"Column {col} contains non-positive values, cannot apply log transform.\")\n",
        "\n",
        "            # Apply natural logarithm transformation\n",
        "            df[col] = np.log(df[col])\n",
        "\n",
        "            # Initialize and fit MinMaxScaler\n",
        "            scaler = MinMaxScaler()\n",
        "            df[col] = scaler.fit_transform(df[[col]])\n",
        "\n",
        "            # Save the scaler\n",
        "            scalers[col] = scaler\n",
        "\n",
        "        ic(f\"Data preprocessing completed in {time.time() - start_time_preprocess:.2f} seconds\")\n",
        "        ic(f\"DataFrame shape: {df.shape}\")\n",
        "\n",
        "        return df, scalers\n",
        "\n",
        "    df, scalers = load_and_preprocess_data(cfg.DATA_FILE, cfg.DATA_URL)\n",
        "    cfg.NUM_FEATURES = df.shape[1]\n",
        "\n",
        "    def evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=10):\n",
        "        top_models = []\n",
        "        for model_file in model_files:\n",
        "            cfg.MODEL_PATH = model_file\n",
        "            print(f\"\\nLoading model from {cfg.MODEL_PATH}\")\n",
        "\n",
        "            result = load_model(cfg.MODEL_PATH, cfg, cfg.DEVICE)\n",
        "            if result is None:\n",
        "                print(f\"Skipping model {cfg.MODEL_PATH} due to loading error\")\n",
        "                continue\n",
        "\n",
        "            model, params = result\n",
        "            input_size = params['input_size']\n",
        "            output_size = params['output_size']\n",
        "            n_past = params['n_past']\n",
        "            n_future = params['n_future']\n",
        "            num_features = cfg.NUM_FEATURES\n",
        "\n",
        "            # Get the input columns\n",
        "            input_cols = df.columns[:input_size]\n",
        "\n",
        "            try:\n",
        "                input_data, target_data = get_random_sample(df, n_past, n_future, input_cols, input_cols)\n",
        "            except Exception as e:\n",
        "                print(f\"Error getting random sample: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            # Prepare the tensors\n",
        "            try:\n",
        "                input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "                target_tensor = torch.tensor(target_data, dtype=torch.float32).to(cfg.DEVICE)\n",
        "            except Exception as e:\n",
        "                print(f\"Error preparing tensors: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    if isinstance(model, CryptoTransformer):\n",
        "                        # For Transformer, prepare tgt_input with zeros\n",
        "                        tgt_input = torch.zeros((1, n_future, input_size), device=cfg.DEVICE)\n",
        "                        prediction = model(input_tensor, tgt_input)\n",
        "                    elif isinstance(model, CryptoLSTM):\n",
        "                        prediction = model(input_tensor)\n",
        "                    else:\n",
        "                        print(f\"Unknown model type for file: {model_file}\")\n",
        "                        continue\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to make predictions: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Convert tensors to numpy\n",
        "            input_np = input_tensor.squeeze(0).cpu().numpy()  # (n_past, num_features)\n",
        "            target_np = target_tensor.cpu().numpy()  # (n_future, num_features)\n",
        "            prediction_np = prediction.cpu().numpy()  # (1, output_size) or similar\n",
        "\n",
        "            # Handle multi-step predictions\n",
        "            try:\n",
        "                if isinstance(model, CryptoTransformer) or output_size == n_future * num_features:\n",
        "                    # Multi-step prediction\n",
        "                    if output_size != n_future * num_features:\n",
        "                        print(f\"Model's output_size ({output_size}) does not match n_future * num_features ({n_future * num_features}). Skipping model.\")\n",
        "                        continue\n",
        "                    prediction_np = prediction_np.reshape(-1, n_future, num_features)\n",
        "                    target_np = target_np.reshape(-1, n_future, num_features)\n",
        "                    input_np = input_np.reshape(-1, num_features)\n",
        "                elif output_size == num_features:\n",
        "                    # Single-step prediction\n",
        "                    prediction_np = prediction_np.reshape(-1, num_features)\n",
        "                    target_np = target_np.reshape(-1, num_features)\n",
        "                    input_np = input_np.reshape(-1, num_features)\n",
        "                else:\n",
        "                    print(f\"Unexpected output_size ({output_size}) for model {model_file}. Skipping model.\")\n",
        "                    continue\n",
        "            except ValueError as ve:\n",
        "                print(f\"ValueError during reshaping: {ve}. Skipping model.\")\n",
        "                continue\n",
        "\n",
        "            # Inverse transform\n",
        "            try:\n",
        "                inv_input, inv_target, inv_pred = get_original_values(\n",
        "                    df.columns, input_np, target_np, prediction_np, scalers, n_future, num_features\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"Error during inverse transformation: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            print(\"Calculating scores...\")\n",
        "            try:\n",
        "                model_score = calculate_score(inv_target, inv_pred)\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating score: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Append and maintain top N\n",
        "            top_models.append((model_file, model_score))\n",
        "            top_models = sorted(top_models, key=lambda x: x[1])\n",
        "            top_models = top_models[:top_n]\n",
        "\n",
        "            print(f\"Current top {len(top_models)} models:\")\n",
        "            for m, s in top_models:\n",
        "                print(f\"  Model: {m}, Score: {s:.2%}\")\n",
        "\n",
        "        return top_models\n",
        "\n",
        "    # Create a list of model files\n",
        "    model_files = glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.ckpt\"), recursive=True) + \\\n",
        "                  glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.pth\"), recursive=True)\n",
        "    print(f\"Total model files found: {len(model_files)}\")\n",
        "\n",
        "    # Optionally, truncate the list for testing\n",
        "    model_files = model_files[:20]  # Adjust as needed\n",
        "\n",
        "    # Evaluate models and get top N\n",
        "    top_n = 10\n",
        "    top_models = evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=top_n)\n",
        "\n",
        "    # Display Top N models\n",
        "    print(f\"\\nTop {len(top_models)} models:\")\n",
        "    for model_file, score in top_models:\n",
        "        print(f\"Model: {model_file}, Score: {score:.2%}\")\n",
        "\n",
        "# Create a list of model files\n",
        "model_files = glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.ckpt\"), recursive=True) + \\\n",
        "              glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.pth\"), recursive=True)\n",
        "print(f\"Total model files found: {len(model_files)}\")\n",
        "\n",
        "# Optionally, truncate the list for testing\n",
        "model_files = model_files[:20]  # Adjust as needed\n",
        "\n",
        "# Evaluate models and get top N\n",
        "top_n = 10\n",
        "top_models = evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=top_n)\n",
        "\n",
        "# Display Top N models\n",
        "print(f\"\\nTop {len(top_models)} models:\")\n",
        "for model_file, score in top_models:\n",
        "    print(f\"Model: {model_file}, Score: {score:.2%}\")\n"
      ],
      "metadata": {
        "id": "c6IciW69G3NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "import multiprocessing\n",
        "import glob\n",
        "import numpy as np\n",
        "from rich.table import Table\n",
        "from rich.console import Console\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from icecream import ic  # Ensure icecream is installed (`pip install icecream`)\n",
        "import traceback\n",
        "import warnings\n",
        "\n",
        "# Initialize Rich Console\n",
        "console = Console()\n",
        "\n",
        "# Define your CryptoTransformer class as per your implementation\n",
        "class CryptoTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_size, d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
        "                 dim_feedforward, dropout, activation, n_future, num_outputs, max_seq_length):\n",
        "        super(CryptoTransformer, self).__init__()\n",
        "        # Transformer implementation as per your code\n",
        "        self.transformer = torch.nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "        )\n",
        "        self.input_fc = torch.nn.Linear(input_size, d_model)\n",
        "        self.output_fc = torch.nn.Linear(d_model, num_outputs)\n",
        "        self.n_future = n_future\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.input_fc(src)\n",
        "        tgt = self.input_fc(tgt)\n",
        "        output = self.transformer(src, tgt)\n",
        "        output = self.output_fc(output)\n",
        "        return output\n",
        "\n",
        "# Define your CryptoLSTM class with corrected LayerNorm naming\n",
        "class CryptoLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size, has_layer_norm=False):\n",
        "        super(CryptoLSTM, self).__init__()\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                                  dropout=dropout, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
        "        # Optionally include LayerNorm if your models use it\n",
        "        if has_layer_norm:\n",
        "            self.layer_norm = torch.nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        if hasattr(self, 'layer_norm'):\n",
        "            out = self.layer_norm(out)\n",
        "        # If the model outputs a sequence\n",
        "        if out.dim() == 3:\n",
        "            out = self.fc(out)\n",
        "        else:\n",
        "            out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Function to find a suitable number of attention heads\n",
        "def find_nhead(d_model, max_nhead=16, min_head_dim=8):\n",
        "    \"\"\"\n",
        "    Find the maximum nhead such that d_model is divisible by nhead\n",
        "    and the head dimension is at least min_head_dim.\n",
        "    \"\"\"\n",
        "    for nhead in range(max_nhead, 0, -1):\n",
        "        if d_model % nhead == 0:\n",
        "            head_dim = d_model // nhead\n",
        "            if head_dim >= min_head_dim:\n",
        "                return nhead\n",
        "    return 1  # Fallback to single head\n",
        "\n",
        "# Function to inverse transform data, adjusted to handle varying number of features\n",
        "def get_original_values(df_columns, input_np, target_np, prediction_np, scalers, n_future, num_features):\n",
        "    inv_pred = pd.DataFrame()\n",
        "    inv_target = pd.DataFrame()\n",
        "    inv_input = pd.DataFrame()\n",
        "\n",
        "    # Determine if the model outputs multi-step or single-step predictions\n",
        "    if prediction_np.shape[-1] == num_features:\n",
        "        # Single-step prediction\n",
        "        for i, col in enumerate(df_columns):\n",
        "            scaler = scalers.get(col)\n",
        "            if scaler:\n",
        "                inv_pred[col] = np.exp(scaler.inverse_transform(prediction_np[:, i].reshape(-1, 1)).flatten())\n",
        "                inv_target[col] = np.exp(scaler.inverse_transform(target_np[:, i].reshape(-1, 1)).flatten())\n",
        "                inv_input[col] = np.exp(scalers[col].inverse_transform(input_np[:, i].reshape(-1, 1)).flatten())\n",
        "    elif prediction_np.shape[-1] == n_future * num_features:\n",
        "        # Multi-step prediction\n",
        "        prediction_np = prediction_np.reshape(-1, n_future, num_features)\n",
        "        target_np = target_np.reshape(-1, n_future, num_features)\n",
        "        input_np = input_np.reshape(-1, num_features)\n",
        "        for i in range(n_future):\n",
        "            for j, col in enumerate(df_columns):\n",
        "                scaler = scalers.get(col)\n",
        "                if scaler:\n",
        "                    inv_pred[f\"{col}_step_{i}\"] = np.exp(scaler.inverse_transform(prediction_np[:, i, j].reshape(-1, 1)).flatten())\n",
        "                    inv_target[f\"{col}_step_{i}\"] = np.exp(scaler.inverse_transform(target_np[:, i, j].reshape(-1, 1)).flatten())\n",
        "                    inv_input[f\"{col}_step_{i}\"] = np.exp(scalers[col].inverse_transform(input_np[:, j].reshape(-1, 1)).flatten())\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected prediction output shape: {prediction_np.shape}\")\n",
        "\n",
        "    return inv_input, inv_target, inv_pred\n",
        "\n",
        "# Function to calculate the score\n",
        "def calculate_score(inv_target, inv_pred):\n",
        "    scores = {}\n",
        "    for col in inv_target.columns:\n",
        "        # Ensure lengths match\n",
        "        min_len = min(len(inv_target[col]), len(inv_pred[col]))\n",
        "        target_col = inv_target[col][:min_len]\n",
        "        pred_col = inv_pred[col][:min_len]\n",
        "        # Calculate the absolute percentage error\n",
        "        ape = np.abs((target_col - pred_col) / target_col)\n",
        "        # Handle division by zero\n",
        "        ape = ape.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "        # Calculate the mean absolute percentage error\n",
        "        mape = ape.mean()\n",
        "        scores[col] = mape\n",
        "    # Calculate the overall score (average of individual scores)\n",
        "    overall_score = np.mean(list(scores.values()))\n",
        "    print(f\"Overall Score: {overall_score:.2%}\")\n",
        "    return overall_score\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*does not have many workers.*\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*torch.load.*\")\n",
        "\n",
        "def load_model(model_file, cfg, device='cpu'):\n",
        "    try:\n",
        "        if not os.path.exists(model_file):\n",
        "            print(f\"File not found: {model_file}\")\n",
        "            return None\n",
        "\n",
        "        # Load the state dict\n",
        "        state_dict = torch.load(model_file, map_location=device)\n",
        "\n",
        "        # Check if it's a Lightning checkpoint\n",
        "        if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n",
        "            state_dict = state_dict['state_dict']\n",
        "\n",
        "        # Strip 'model.' prefix if present\n",
        "        if any(key.startswith('model.') for key in state_dict.keys()):\n",
        "            new_state_dict = {}\n",
        "            for k, v in state_dict.items():\n",
        "                if k.startswith('model.'):\n",
        "                    new_k = k[6:]  # Remove 'model.' prefix\n",
        "                else:\n",
        "                    new_k = k\n",
        "                new_state_dict[new_k] = v\n",
        "            state_dict = new_state_dict\n",
        "\n",
        "        # Determine the model type based on key prefixes\n",
        "        if any(key.startswith('lstm') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoLSTM\")\n",
        "\n",
        "            # Infer LSTM parameters\n",
        "            lstm_weight_ih_keys = [k for k in state_dict.keys() if k.startswith('lstm.weight_ih_l')]\n",
        "            num_layers = len(lstm_weight_ih_keys)\n",
        "            if num_layers == 0:\n",
        "                print(f\"No LSTM layers found in {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "                return None\n",
        "\n",
        "            sample_weight_ih = state_dict[lstm_weight_ih_keys[0]]\n",
        "            hidden_size = sample_weight_ih.shape[0] // 4  # LSTM gates\n",
        "            input_size = sample_weight_ih.shape[1]\n",
        "\n",
        "            if 'fc.weight' in state_dict:\n",
        "                output_size = state_dict['fc.weight'].shape[0]\n",
        "            elif 'fc.bias' in state_dict:\n",
        "                output_size = state_dict['fc.bias'].shape[0]\n",
        "            else:\n",
        "                print(f\"Could not infer output_size for LSTM in {model_file}. Using default: {cfg.NUM_FEATURES}\")\n",
        "                output_size = cfg.NUM_FEATURES\n",
        "\n",
        "            # Infer if LayerNorm is present\n",
        "            has_layer_norm = any('layer_norm' in key or 'ln' in key for key in state_dict.keys())\n",
        "            print(f\"Inferred LSTM parameters: hidden_size={hidden_size}, num_layers={num_layers}, \"\n",
        "                  f\"input_size={input_size}, output_size={output_size}, LayerNorm={has_layer_norm}\")\n",
        "\n",
        "            # Determine expected output_size based on n_future and num_features\n",
        "            expected_output_size = cfg.N_FUTURE * cfg.NUM_FEATURES\n",
        "            if output_size != expected_output_size:\n",
        "                print(f\"Model's output_size ({output_size}) does not match expected ({expected_output_size}). Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoLSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hidden_size,\n",
        "                num_layers=num_layers,\n",
        "                dropout=cfg.DROPOUT,\n",
        "                output_size=output_size,\n",
        "                has_layer_norm=has_layer_norm\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {'input_size': input_size, 'output_size': output_size,\n",
        "                          'n_past': cfg.N_PAST, 'n_future': cfg.N_FUTURE}\n",
        "\n",
        "        elif any(key.startswith('transformer') for key in state_dict.keys()):\n",
        "            # It's a Transformer model\n",
        "            print(f\"Loading {model_file} as CryptoTransformer\")\n",
        "            # Attempt to infer Transformer parameters from state_dict\n",
        "            # This is heuristic and may need adjustments based on actual model architecture\n",
        "\n",
        "            # Infer d_model from the first transformer's in_proj_weight\n",
        "            d_model = cfg.HIDDEN_SIZE  # Default value\n",
        "            for key in state_dict.keys():\n",
        "                if 'transformer_encoder.layers.0.self_attn.in_proj_weight' in key:\n",
        "                    weight = state_dict[key]\n",
        "                    d_model = weight.shape[1]  # Typically (3*d_model, d_model)\n",
        "                    break\n",
        "\n",
        "            # Find a suitable nhead\n",
        "            nhead = find_nhead(d_model)\n",
        "            if nhead == 1 and d_model < 8:\n",
        "                print(f\"Could not find a suitable nhead for d_model={d_model}. Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Infer number of encoder and decoder layers\n",
        "            transformer_encoder_keys = [k for k in state_dict.keys() if 'transformer_encoder.layers.' in k]\n",
        "            num_encoder_layers = len(set(k.split('.')[3] for k in transformer_encoder_keys))\n",
        "            transformer_decoder_keys = [k for k in state_dict.keys() if 'transformer_decoder.layers.' in k]\n",
        "            num_decoder_layers = len(set(k.split('.')[3] for k in transformer_decoder_keys))\n",
        "\n",
        "            # Infer dim_feedforward from the first linear layer\n",
        "            dim_feedforward = cfg.DIM_FEEDFORWARD if hasattr(cfg, 'DIM_FEEDFORWARD') else 2048\n",
        "            dropout = cfg.DROPOUT\n",
        "            activation = 'gelu'  # Defaulting to 'gelu'\n",
        "\n",
        "            print(f\"Inferred Transformer parameters: d_model={d_model}, nhead={nhead}, \"\n",
        "                  f\"num_encoder_layers={num_encoder_layers}, num_decoder_layers={num_decoder_layers}, \"\n",
        "                  f\"dim_feedforward={dim_feedforward}, dropout={dropout}, activation={activation}\")\n",
        "\n",
        "            # Infer num_outputs based on state_dict\n",
        "            if 'output_fc.weight' in state_dict:\n",
        "                num_outputs = state_dict['output_fc.weight'].shape[0]\n",
        "            else:\n",
        "                num_outputs = cfg.N_FUTURE * cfg.NUM_FEATURES  # Default assumption\n",
        "\n",
        "            # Check if num_outputs is divisible by num_features to determine n_future\n",
        "            if num_outputs % cfg.NUM_FEATURES == 0:\n",
        "                n_future_model = num_outputs // cfg.NUM_FEATURES\n",
        "            elif num_outputs == cfg.NUM_FEATURES:\n",
        "                n_future_model = 1  # Single-step prediction\n",
        "            else:\n",
        "                print(f\"Unexpected num_outputs ({num_outputs}) for model {model_file}. Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Ensure that we are only processing models trained with 13 features\n",
        "            if cfg.NUM_FEATURES != 13:\n",
        "                print(f\"Model {model_file} uses {cfg.NUM_FEATURES} features instead of 13. Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoTransformer(\n",
        "                input_size=cfg.NUM_FEATURES,\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                num_encoder_layers=num_encoder_layers,\n",
        "                num_decoder_layers=num_decoder_layers,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                activation=activation,\n",
        "                n_future=n_future_model,\n",
        "                num_outputs=num_outputs,\n",
        "                max_seq_length=cfg.N_PAST + cfg.N_FUTURE\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {\n",
        "                'input_size': cfg.NUM_FEATURES,\n",
        "                'output_size': num_outputs,\n",
        "                'n_past': cfg.N_PAST,\n",
        "                'n_future': n_future_model\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"Unrecognized model format for {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model {model_file}: {e}\")\n",
        "        return None\n",
        "    # Function to prepare input data\n",
        "    def prepare_input(input_data, device):\n",
        "        input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "        return input_tensor\n",
        "\n",
        "    # Function to get a random sample from the DataFrame\n",
        "    def get_random_sample(df, n_past, n_future, input_cols, target_cols):\n",
        "        max_start = len(df) - n_past - n_future\n",
        "        if max_start <= 0:\n",
        "            raise ValueError(\"DataFrame is too short for the given n_past and n_future\")\n",
        "        start_idx = np.random.randint(0, max_start)\n",
        "        input_data = df[input_cols].iloc[start_idx:start_idx + n_past].values\n",
        "        target_data = df[target_cols].iloc[start_idx + n_past:start_idx + n_past + n_future].values\n",
        "        return input_data, target_data\n",
        "\n",
        "    # Function to convert tensors to numpy arrays\n",
        "    def convert_to_numpy(input_tensor, target, prediction):\n",
        "        input_np = input_tensor.cpu().numpy()\n",
        "        target_np = target.cpu().numpy()\n",
        "        prediction_np = prediction.cpu().numpy()\n",
        "        return input_np, target_np, prediction_np\n",
        "\n",
        "    @dataclass\n",
        "    class Config:\n",
        "        VERSION_N: int = 1\n",
        "        RECORDS_TO_LOAD: int = 1205040\n",
        "        N_PAST: int = 3 * 12 * 3  # 1 week of 10-minute intervals (108)\n",
        "        N_FUTURE: int = 1 * 12 * 2  # 1 day of 10-minute intervals (24)\n",
        "        BATCH_SIZE: int = 5000\n",
        "        HIDDEN_SIZE: int = 512  # Adjusted to match inferred d_model=512\n",
        "        NUM_LAYERS: int = 2\n",
        "        DROPOUT: float = 0.2\n",
        "        NUM_EPOCHS: int = 150\n",
        "        HOT_RESTART: bool = True\n",
        "        TRAIN_FIRST: bool = True\n",
        "        EPOCH_TO_RESTART: int = 50\n",
        "        BATCH_FACTOR: int = 81\n",
        "        DEBUG_FREQ: int = 180\n",
        "        num_cpus = multiprocessing.cpu_count()\n",
        "        NUM_WORKERS = max((num_cpus // 4 - 4), 4) if num_cpus > 16 else 4\n",
        "        DEBUG_ON: bool = False\n",
        "        DATA_URL: str = 'https://sambo.us-iad-1.linodeobjects.com/fillnan_combined_df.csv'\n",
        "        DATA_FILE: str = './data/fill_nan_df.csv'\n",
        "        MODEL_PATH: str = \"/teamspace/studios/this_studio/models/TransformerModel355/model-355-epoch=40-val_loss=0.62.ckpt\"\n",
        "        MODEL_SAVE_PATH: str = f'./yay'\n",
        "        DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        EPSILON: float = 1e-4\n",
        "        PATH_TO_SEARCH: str = \"/content/drive/MyDrive/Kraken\"\n",
        "        # Additional parameters\n",
        "        NUM_FEATURES: int = None  # To be set after loading data\n",
        "\n",
        "    cfg = Config()\n",
        "\n",
        "    # Load and preprocess data\n",
        "    def load_and_preprocess_data(file_path: str, download_url: str = None):\n",
        "        \"\"\"\n",
        "        Load and preprocess data from a CSV file. If the file does not exist, download it.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to the CSV file.\n",
        "            download_url (str, optional): URL to download the CSV file. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Preprocessed DataFrame.\n",
        "            dict: Dictionary of scalers used for each column.\n",
        "        \"\"\"\n",
        "        ic(\"Starting data loading and preprocessing...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Check if the file exists\n",
        "        if not os.path.exists(file_path):\n",
        "            ic(f\"File {file_path} does not exist.\")\n",
        "            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "            if download_url:\n",
        "                ic(f\"Downloading file from {download_url}...\")\n",
        "                try:\n",
        "                    response = requests.get(download_url, stream=True)\n",
        "                    response.raise_for_status()\n",
        "                    with open(file_path, 'wb') as f:\n",
        "                        for chunk in response.iter_content(chunk_size=8192):\n",
        "                            f.write(chunk)\n",
        "                    ic(f\"File downloaded and saved to {file_path}\")\n",
        "                except requests.exceptions.RequestException as e:\n",
        "                    ic(f\"Failed to download the file: {e}\")\n",
        "                    raise\n",
        "            else:\n",
        "                ic(\"Download URL not provided. Cannot download the file.\")\n",
        "                raise FileNotFoundError(f\"The file {file_path} does not exist and no download URL was provided.\")\n",
        "\n",
        "        # Load the DataFrame\n",
        "        df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
        "        df.set_index('timestamp', inplace=True)\n",
        "        df = df.tail(cfg.RECORDS_TO_LOAD)\n",
        "        scalers = {}\n",
        "        start_time_preprocess = time.time()\n",
        "\n",
        "        for col in df.columns:\n",
        "            # Ensure no non-positive values before log transform\n",
        "            if (df[col] <= 0).any():\n",
        "                raise ValueError(f\"Column {col} contains non-positive values, cannot apply log transform.\")\n",
        "\n",
        "            # Apply natural logarithm transformation\n",
        "            df[col] = np.log(df[col])\n",
        "\n",
        "            # Initialize and fit MinMaxScaler\n",
        "            scaler = MinMaxScaler()\n",
        "            df[col] = scaler.fit_transform(df[[col]])\n",
        "\n",
        "            # Save the scaler\n",
        "            scalers[col] = scaler\n",
        "\n",
        "        ic(f\"Data preprocessing completed in {time.time() - start_time_preprocess:.2f} seconds\")\n",
        "        ic(f\"DataFrame shape: {df.shape}\")\n",
        "\n",
        "        return df, scalers\n",
        "\n",
        "    df, scalers = load_and_preprocess_data(cfg.DATA_FILE, cfg.DATA_URL)\n",
        "    cfg.NUM_FEATURES = df.shape[1]\n",
        "\n",
        "    def evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=10):\n",
        "        top_models = []\n",
        "        for model_file in model_files:\n",
        "            cfg.MODEL_PATH = model_file\n",
        "            print(f\"\\nLoading model from {cfg.MODEL_PATH}\")\n",
        "\n",
        "            result = load_model(cfg.MODEL_PATH, cfg, cfg.DEVICE)\n",
        "            if result is None:\n",
        "                print(f\"Skipping model {cfg.MODEL_PATH} due to loading error\")\n",
        "                continue\n",
        "\n",
        "            model, params = result\n",
        "            input_size = params['input_size']\n",
        "            output_size = params['output_size']\n",
        "            n_past = params['n_past']\n",
        "            n_future = params['n_future']\n",
        "            num_features = cfg.NUM_FEATURES\n",
        "\n",
        "            # Get the input columns\n",
        "            input_cols = df.columns[:input_size]\n",
        "\n",
        "            try:\n",
        "                input_data, target_data = get_random_sample(df, n_past, n_future, input_cols, input_cols)\n",
        "            except Exception as e:\n",
        "                print(f\"Error getting random sample: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            # Prepare the tensors\n",
        "            try:\n",
        "                input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "                target_tensor = torch.tensor(target_data, dtype=torch.float32).to(cfg.DEVICE)\n",
        "            except Exception as e:\n",
        "                print(f\"Error preparing tensors: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    if isinstance(model, CryptoTransformer):\n",
        "                        # For Transformer, prepare tgt_input with zeros\n",
        "                        tgt_input = torch.zeros((1, n_future, input_size), device=cfg.DEVICE)\n",
        "                        prediction = model(input_tensor, tgt_input)\n",
        "                    elif isinstance(model, CryptoLSTM):\n",
        "                        # For LSTM, perform iterative predictions\n",
        "                        prediction = []\n",
        "                        current_input = input_tensor.clone()\n",
        "                        for _ in range(n_future):\n",
        "                            pred = model(current_input)\n",
        "                            prediction.append(pred)\n",
        "                            # Append the prediction to current_input and remove the first timestep\n",
        "                            current_input = torch.cat((current_input[:, 1:, :], pred.unsqueeze(1)), dim=1)\n",
        "                        prediction = torch.cat(prediction, dim=1)  # Shape: (1, n_future, num_features)\n",
        "                    else:\n",
        "                        print(f\"Unknown model type for file: {model_file}\")\n",
        "                        continue\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to make predictions: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Convert tensors to numpy\n",
        "            input_np = input_tensor.squeeze(0).cpu().numpy()  # (n_past, num_features)\n",
        "            target_np = target_tensor.cpu().numpy()  # (n_future, num_features)\n",
        "            prediction_np = prediction.cpu().numpy()  # (1, n_future, num_features)\n",
        "\n",
        "            # Handle multi-step predictions\n",
        "            try:\n",
        "                if isinstance(model, CryptoTransformer):\n",
        "                    # Transformer: output_size should be n_future * num_features\n",
        "                    if output_size != n_future * num_features:\n",
        "                        print(f\"Model's output_size ({output_size}) does not match n_future * num_features ({n_future * num_features}). Skipping model.\")\n",
        "                        continue\n",
        "                    prediction_np = prediction_np.reshape(-1, n_future, num_features)\n",
        "                    target_np = target_np.reshape(-1, n_future, num_features)\n",
        "                    input_np = input_np.reshape(-1, num_features)\n",
        "                elif isinstance(model, CryptoLSTM):\n",
        "                    # LSTM: output is already (1, n_future, num_features)\n",
        "                    if output_size != num_features:\n",
        "                        print(f\"LSTM model's output_size ({output_size}) does not match num_features ({num_features}). Skipping model.\")\n",
        "                        continue\n",
        "                    prediction_np = prediction_np.reshape(-1, n_future, num_features)\n",
        "                    target_np = target_np.reshape(-1, n_future, num_features)\n",
        "                    input_np = input_np.reshape(-1, num_features)\n",
        "                else:\n",
        "                    print(f\"Unexpected model type for {model_file}. Skipping model.\")\n",
        "                    continue\n",
        "            except ValueError as ve:\n",
        "                print(f\"ValueError during reshaping: {ve}. Skipping model.\")\n",
        "                continue\n",
        "\n",
        "            # Inverse transform\n",
        "            try:\n",
        "                inv_input, inv_target, inv_pred = get_original_values(\n",
        "                    df.columns, input_np, target_np, prediction_np, scalers, n_future, num_features\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"Error during inverse transformation: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            print(\"Calculating scores...\")\n",
        "            try:\n",
        "                model_score = calculate_score(inv_target, inv_pred)\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating score: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Append and maintain top N\n",
        "            top_models.append((model_file, model_score))\n",
        "            top_models = sorted(top_models, key=lambda x: x[1])\n",
        "            top_models = top_models[:top_n]\n",
        "\n",
        "            print(f\"Current top {len(top_models)} models:\")\n",
        "            for m, s in top_models:\n",
        "                print(f\"  Model: {m}, Score: {s:.2%}\")\n",
        "\n",
        "        return top_models\n",
        "\n",
        "    # Create a list of model files\n",
        "    model_files = glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.ckpt\"), recursive=True) + \\\n",
        "                  glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.pth\"), recursive=True)\n",
        "    print(f\"Total model files found: {len(model_files)}\")\n",
        "\n",
        "    # Optionally, truncate the list for testing\n",
        "    model_files = model_files[:20]  # Adjust as needed\n",
        "\n",
        "    # Evaluate models and get top N\n",
        "    top_n = 10\n",
        "    top_models = evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=top_n)\n",
        "\n",
        "    # Display Top N models\n",
        "    print(f\"\\nTop {len(top_models)} models:\")\n",
        "    for model_file, score in top_models:\n",
        "        print(f\"Model: {model_file}, Score: {score:.2%}\")\n",
        "\n",
        "\n",
        "# ```python\n",
        "# # Ensure that we are only processing models trained with 13 features\n",
        "# if cfg.NUM_FEATURES != 13:\n",
        "#     print(f\"Model {model_file} uses {cfg.NUM_FEATURES} features instead of 13. Skipping model.\")\n",
        "#     return None\n",
        "\n",
        "# Create a list of model files\n",
        "model_files = glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.ckpt\"), recursive=True) + \\\n",
        "              glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.pth\"), recursive=True)\n",
        "print(f\"Total model files found: {len(model_files)}\")\n",
        "\n",
        "# Optionally, truncate the list for testing\n",
        "model_files = model_files[:20]  # Adjust as needed\n",
        "\n",
        "# Evaluate models and get top N\n",
        "top_n = 10\n",
        "top_models = evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=top_n)\n",
        "\n",
        "# Display Top N models\n",
        "print(f\"\\nTop {len(top_models)} models:\")\n",
        "for model_file, score in top_models:\n",
        "    print(f\"Model: {model_file}, Score: {score:.2%}\")\n"
      ],
      "metadata": {
        "id": "11b13YwcMfPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "import multiprocessing\n",
        "import glob\n",
        "import numpy as np\n",
        "from rich.table import Table\n",
        "from rich.console import Console\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from icecream import ic  # Ensure icecream is installed (`pip install icecream`)\n",
        "import traceback\n",
        "import warnings\n",
        "\n",
        "# Initialize Rich Console\n",
        "console = Console()\n",
        "\n",
        "# Define your CryptoTransformer class as per your implementation\n",
        "class CryptoTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_size, d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
        "                 dim_feedforward, dropout, activation, n_future, num_outputs, max_seq_length):\n",
        "        super(CryptoTransformer, self).__init__()\n",
        "        # Transformer implementation as per your code\n",
        "        self.transformer = torch.nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "        )\n",
        "        self.input_fc = torch.nn.Linear(input_size, d_model)\n",
        "        self.output_fc = torch.nn.Linear(d_model, num_outputs)\n",
        "        self.n_future = n_future\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.input_fc(src)\n",
        "        tgt = self.input_fc(tgt)\n",
        "        output = self.transformer(src, tgt)\n",
        "        output = self.output_fc(output)\n",
        "        return output\n",
        "\n",
        "# Define your CryptoLSTM class with corrected LayerNorm naming\n",
        "class CryptoLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size, has_layer_norm=False):\n",
        "        super(CryptoLSTM, self).__init__()\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                                  dropout=dropout, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
        "        # Optionally include LayerNorm if your models use it\n",
        "        if has_layer_norm:\n",
        "            self.layer_norm = torch.nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        if hasattr(self, 'layer_norm'):\n",
        "            out = self.layer_norm(out)\n",
        "        # If the model outputs a sequence\n",
        "        if out.dim() == 3:\n",
        "            out = self.fc(out)\n",
        "        else:\n",
        "            out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Function to find a suitable number of attention heads\n",
        "def find_nhead(d_model, max_nhead=16, min_head_dim=8):\n",
        "    \"\"\"\n",
        "    Find the maximum nhead such that d_model is divisible by nhead\n",
        "    and the head dimension is at least min_head_dim.\n",
        "    \"\"\"\n",
        "    for nhead in range(max_nhead, 0, -1):\n",
        "        if d_model % nhead == 0:\n",
        "            head_dim = d_model // nhead\n",
        "            if head_dim >= min_head_dim:\n",
        "                return nhead\n",
        "    return 1  # Fallback to single head\n",
        "\n",
        "# Function to inverse transform data, adjusted to handle varying number of features\n",
        "def get_original_values(df_columns, input_np, target_np, prediction_np, scalers, n_future, num_features):\n",
        "    inv_pred = pd.DataFrame()\n",
        "    inv_target = pd.DataFrame()\n",
        "    inv_input = pd.DataFrame()\n",
        "\n",
        "    # Determine if the model outputs multi-step or single-step predictions\n",
        "    if prediction_np.shape[-1] == num_features:\n",
        "        # Single-step prediction\n",
        "        for i, col in enumerate(df_columns):\n",
        "            scaler = scalers.get(col)\n",
        "            if scaler:\n",
        "                inv_pred[col] = np.exp(scaler.inverse_transform(prediction_np[:, i].reshape(-1, 1)).flatten())\n",
        "                inv_target[col] = np.exp(scaler.inverse_transform(target_np[:, i].reshape(-1, 1)).flatten())\n",
        "                inv_input[col] = np.exp(scalers[col].inverse_transform(input_np[:, i].reshape(-1, 1)).flatten())\n",
        "    elif prediction_np.shape[-1] == n_future * num_features:\n",
        "        # Multi-step prediction (Transformer)\n",
        "        prediction_np = prediction_np.reshape(-1, n_future, num_features)\n",
        "        target_np = target_np.reshape(-1, n_future, num_features)\n",
        "        input_np = input_np.reshape(-1, num_features)\n",
        "        for i in range(n_future):\n",
        "            for j, col in enumerate(df_columns):\n",
        "                scaler = scalers.get(col)\n",
        "                if scaler:\n",
        "                    inv_pred[f\"{col}_step_{i}\"] = np.exp(scaler.inverse_transform(prediction_np[:, i, j].reshape(-1, 1)).flatten())\n",
        "                    inv_target[f\"{col}_step_{i}\"] = np.exp(scaler.inverse_transform(target_np[:, i, j].reshape(-1, 1)).flatten())\n",
        "                    inv_input[f\"{col}_step_{i}\"] = np.exp(scalers[col].inverse_transform(input_np[:, j].reshape(-1, 1)).flatten())\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected prediction output shape: {prediction_np.shape}\")\n",
        "\n",
        "    return inv_input, inv_target, inv_pred\n",
        "\n",
        "# Function to calculate the score\n",
        "def calculate_score(inv_target, inv_pred):\n",
        "    scores = {}\n",
        "    for col in inv_target.columns:\n",
        "        # Ensure lengths match\n",
        "        min_len = min(len(inv_target[col]), len(inv_pred[col]))\n",
        "        target_col = inv_target[col][:min_len]\n",
        "        pred_col = inv_pred[col][:min_len]\n",
        "        # Calculate the absolute percentage error\n",
        "        ape = np.abs((target_col - pred_col) / target_col)\n",
        "        # Handle division by zero\n",
        "        ape = ape.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "        # Calculate the mean absolute percentage error\n",
        "        mape = ape.mean()\n",
        "        scores[col] = mape\n",
        "    # Calculate the overall score (average of individual scores)\n",
        "    overall_score = np.mean(list(scores.values()))\n",
        "    print(f\"Overall Score: {overall_score:.2%}\")\n",
        "    return overall_score\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*does not have many workers.*\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*torch.load.*\")\n",
        "\n",
        "def load_model(model_file, cfg, device='cpu'):\n",
        "    try:\n",
        "        if not os.path.exists(model_file):\n",
        "            print(f\"File not found: {model_file}\")\n",
        "            return None\n",
        "\n",
        "        # Load the state dict\n",
        "        state_dict = torch.load(model_file, map_location=device)\n",
        "\n",
        "        # Check if it's a Lightning checkpoint\n",
        "        if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n",
        "            state_dict = state_dict['state_dict']\n",
        "\n",
        "        # Strip 'model.' prefix if present\n",
        "        if any(key.startswith('model.') for key in state_dict.keys()):\n",
        "            new_state_dict = {}\n",
        "            for k, v in state_dict.items():\n",
        "                if k.startswith('model.'):\n",
        "                    new_k = k[6:]  # Remove 'model.' prefix\n",
        "                else:\n",
        "                    new_k = k\n",
        "                new_state_dict[new_k] = v\n",
        "            state_dict = new_state_dict\n",
        "\n",
        "        # Determine the model type based on key prefixes\n",
        "        if any(key.startswith('lstm') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoLSTM\")\n",
        "\n",
        "            # Infer LSTM parameters\n",
        "            lstm_weight_ih_keys = [k for k in state_dict.keys() if k.startswith('lstm.weight_ih_l')]\n",
        "            num_layers = len(lstm_weight_ih_keys)\n",
        "            if num_layers == 0:\n",
        "                print(f\"No LSTM layers found in {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "                return None\n",
        "\n",
        "            sample_weight_ih = state_dict[lstm_weight_ih_keys[0]]\n",
        "            hidden_size = sample_weight_ih.shape[0] // 4  # LSTM gates\n",
        "            input_size = sample_weight_ih.shape[1]\n",
        "\n",
        "            if 'fc.weight' in state_dict:\n",
        "                output_size = state_dict['fc.weight'].shape[0]\n",
        "            elif 'fc.bias' in state_dict:\n",
        "                output_size = state_dict['fc.bias'].shape[0]\n",
        "            else:\n",
        "                print(f\"Could not infer output_size for LSTM in {model_file}. Using default: {cfg.NUM_FEATURES}\")\n",
        "                output_size = cfg.NUM_FEATURES\n",
        "\n",
        "            # Infer if LayerNorm is present\n",
        "            has_layer_norm = any('layer_norm' in key or 'ln' in key for key in state_dict.keys())\n",
        "            print(f\"Inferred LSTM parameters: hidden_size={hidden_size}, num_layers={num_layers}, \"\n",
        "                  f\"input_size={input_size}, output_size={output_size}, LayerNorm={has_layer_norm}\")\n",
        "\n",
        "            # Determine expected output_size based on model type\n",
        "            if output_size == cfg.NUM_FEATURES:\n",
        "                # Single-step LSTM model (requires iterative predictions)\n",
        "                expected_output_size = cfg.NUM_FEATURES\n",
        "                model_type = 'single_step_lstm'\n",
        "            else:\n",
        "                # Assuming multi-step LSTM model outputs all predictions at once\n",
        "                expected_output_size = cfg.N_FUTURE * cfg.NUM_FEATURES\n",
        "                model_type = 'multi_step_lstm'\n",
        "\n",
        "            if model_type == 'multi_step_lstm' and output_size != expected_output_size:\n",
        "                print(f\"Model's output_size ({output_size}) does not match expected ({expected_output_size}). Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoLSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hidden_size,\n",
        "                num_layers=num_layers,\n",
        "                dropout=cfg.DROPOUT,\n",
        "                output_size=output_size,\n",
        "                has_layer_norm=has_layer_norm\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {'input_size': input_size, 'output_size': output_size,\n",
        "                          'n_past': cfg.N_PAST, 'n_future': cfg.N_FUTURE, 'model_type': model_type}\n",
        "\n",
        "        elif any(key.startswith('transformer') for key in state_dict.keys()):\n",
        "            # It's a Transformer model\n",
        "            print(f\"Loading {model_file} as CryptoTransformer\")\n",
        "            # Attempt to infer Transformer parameters from state_dict\n",
        "            # This is heuristic and may need adjustments based on actual model architecture\n",
        "\n",
        "            # Infer d_model from the first transformer's in_proj_weight\n",
        "            d_model = cfg.HIDDEN_SIZE  # Default value\n",
        "            for key in state_dict.keys():\n",
        "                if 'transformer_encoder.layers.0.self_attn.in_proj_weight' in key:\n",
        "                    weight = state_dict[key]\n",
        "                    d_model = weight.shape[1]  # Typically (3*d_model, d_model)\n",
        "                    break\n",
        "\n",
        "            # Find a suitable nhead\n",
        "            nhead = find_nhead(d_model)\n",
        "            if nhead == 1 and d_model < 8:\n",
        "                print(f\"Could not find a suitable nhead for d_model={d_model}. Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Infer number of encoder and decoder layers\n",
        "            transformer_encoder_keys = [k for k in state_dict.keys() if 'transformer_encoder.layers.' in k]\n",
        "            num_encoder_layers = len(set(k.split('.')[3] for k in transformer_encoder_keys))\n",
        "            transformer_decoder_keys = [k for k in state_dict.keys() if 'transformer_decoder.layers.' in k]\n",
        "            num_decoder_layers = len(set(k.split('.')[3] for k in transformer_decoder_keys))\n",
        "\n",
        "            # Infer dim_feedforward from the first linear layer\n",
        "            dim_feedforward = cfg.DIM_FEEDFORWARD if hasattr(cfg, 'DIM_FEEDFORWARD') else 2048\n",
        "            dropout = cfg.DROPOUT\n",
        "            activation = 'gelu'  # Defaulting to 'gelu'\n",
        "\n",
        "            print(f\"Inferred Transformer parameters: d_model={d_model}, nhead={nhead}, \"\n",
        "                  f\"num_encoder_layers={num_encoder_layers}, num_decoder_layers={num_decoder_layers}, \"\n",
        "                  f\"dim_feedforward={dim_feedforward}, dropout={dropout}, activation={activation}\")\n",
        "\n",
        "            # Infer num_outputs based on state_dict\n",
        "            if 'output_fc.weight' in state_dict:\n",
        "                num_outputs = state_dict['output_fc.weight'].shape[0]\n",
        "            else:\n",
        "                num_outputs = cfg.N_FUTURE * cfg.NUM_FEATURES  # Default assumption\n",
        "\n",
        "            # Check if num_outputs is divisible by num_features to determine n_future\n",
        "            if num_outputs % cfg.NUM_FEATURES == 0:\n",
        "                n_future_model = num_outputs // cfg.NUM_FEATURES\n",
        "            elif num_outputs == cfg.NUM_FEATURES:\n",
        "                n_future_model = 1  # Single-step prediction\n",
        "            else:\n",
        "                print(f\"Unexpected num_outputs ({num_outputs}) for model {model_file}. Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Ensure that we are only processing models trained with 13 features\n",
        "            if cfg.NUM_FEATURES != 13:\n",
        "                print(f\"Model {model_file} uses {cfg.NUM_FEATURES} features instead of 13. Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Expected output_size for Transformer is n_future * num_features\n",
        "            expected_output_size = cfg.N_FUTURE * cfg.NUM_FEATURES\n",
        "            if num_outputs != expected_output_size:\n",
        "                print(f\"Model's output_size ({num_outputs}) does not match expected ({expected_output_size}). Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoTransformer(\n",
        "                input_size=cfg.NUM_FEATURES,\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                num_encoder_layers=num_encoder_layers,\n",
        "                num_decoder_layers=num_decoder_layers,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                activation=activation,\n",
        "                n_future=n_future_model,\n",
        "                num_outputs=num_outputs,\n",
        "                max_seq_length=cfg.N_PAST + cfg.N_FUTURE\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {\n",
        "                'input_size': cfg.NUM_FEATURES,\n",
        "                'output_size': num_outputs,\n",
        "                'n_past': cfg.N_PAST,\n",
        "                'n_future': n_future_model,\n",
        "                'model_type': 'transformer'\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"Unrecognized model format for {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model {model_file}: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "    # Function to prepare input data\n",
        "    def prepare_input(input_data, device):\n",
        "        input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "        return input_tensor\n",
        "\n",
        "    # Function to get a random sample from the DataFrame\n",
        "    def get_random_sample(df, n_past, n_future, input_cols, target_cols):\n",
        "        max_start = len(df) - n_past - n_future\n",
        "        if max_start <= 0:\n",
        "            raise ValueError(\"DataFrame is too short for the given n_past and n_future\")\n",
        "        start_idx = np.random.randint(0, max_start)\n",
        "        input_data = df[input_cols].iloc[start_idx:start_idx + n_past].values\n",
        "        target_data = df[target_cols].iloc[start_idx + n_past:start_idx + n_past + n_future].values\n",
        "        return input_data, target_data\n",
        "\n",
        "    # Function to convert tensors to numpy arrays\n",
        "    def convert_to_numpy(input_tensor, target, prediction):\n",
        "        input_np = input_tensor.cpu().numpy()\n",
        "        target_np = target.cpu().numpy()\n",
        "        prediction_np = prediction.cpu().numpy()\n",
        "        return input_np, target_np, prediction_np\n",
        "\n",
        "    @dataclass\n",
        "    class Config:\n",
        "        VERSION_N: int = 1\n",
        "        RECORDS_TO_LOAD: int = 1205040\n",
        "        N_PAST: int = 3 * 12 * 3  # 1 week of 10-minute intervals (108)\n",
        "        N_FUTURE: int = 1 * 12 * 2  # 1 day of 10-minute intervals (24)\n",
        "        BATCH_SIZE: int = 5000\n",
        "        HIDDEN_SIZE: int = 512  # Adjusted to match inferred d_model=512\n",
        "        NUM_LAYERS: int = 2\n",
        "        DROPOUT: float = 0.2\n",
        "        NUM_EPOCHS: int = 150\n",
        "        HOT_RESTART: bool = True\n",
        "        TRAIN_FIRST: bool = True\n",
        "        EPOCH_TO_RESTART: int = 50\n",
        "        BATCH_FACTOR: int = 81\n",
        "        DEBUG_FREQ: int = 180\n",
        "        num_cpus = multiprocessing.cpu_count()\n",
        "        NUM_WORKERS = max((num_cpus // 4 - 4), 4) if num_cpus > 16 else 4\n",
        "        DEBUG_ON: bool = False\n",
        "        DATA_URL: str = 'https://sambo.us-iad-1.linodeobjects.com/fillnan_combined_df.csv'\n",
        "        DATA_FILE: str = './data/fill_nan_df.csv'\n",
        "        MODEL_PATH: str = \"/teamspace/studios/this_studio/models/TransformerModel355/model-355-epoch=40-val_loss=0.62.ckpt\"\n",
        "        MODEL_SAVE_PATH: str = f'./yay'\n",
        "        DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        EPSILON: float = 1e-4\n",
        "        PATH_TO_SEARCH: str = \"/content/drive/MyDrive/Kraken\"\n",
        "        # Additional parameters\n",
        "        NUM_FEATURES: int = None  # To be set after loading data\n",
        "\n",
        "    cfg = Config()\n",
        "\n",
        "    # Load and preprocess data\n",
        "    def load_and_preprocess_data(file_path: str, download_url: str = None):\n",
        "        \"\"\"\n",
        "        Load and preprocess data from a CSV file. If the file does not exist, download it.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to the CSV file.\n",
        "            download_url (str, optional): URL to download the CSV file. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Preprocessed DataFrame.\n",
        "            dict: Dictionary of scalers used for each column.\n",
        "        \"\"\"\n",
        "        ic(\"Starting data loading and preprocessing...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Check if the file exists\n",
        "        if not os.path.exists(file_path):\n",
        "            ic(f\"File {file_path} does not exist.\")\n",
        "            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "            if download_url:\n",
        "                ic(f\"Downloading file from {download_url}...\")\n",
        "                try:\n",
        "                    response = requests.get(download_url, stream=True)\n",
        "                    response.raise_for_status()\n",
        "                    with open(file_path, 'wb') as f:\n",
        "                        for chunk in response.iter_content(chunk_size=8192):\n",
        "                            f.write(chunk)\n",
        "                    ic(f\"File downloaded and saved to {file_path}\")\n",
        "                except requests.exceptions.RequestException as e:\n",
        "                    ic(f\"Failed to download the file: {e}\")\n",
        "                    raise\n",
        "            else:\n",
        "                ic(\"Download URL not provided. Cannot download the file.\")\n",
        "                raise FileNotFoundError(f\"The file {file_path} does not exist and no download URL was provided.\")\n",
        "\n",
        "        # Load the DataFrame\n",
        "        df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
        "        df.set_index('timestamp', inplace=True)\n",
        "        df = df.tail(cfg.RECORDS_TO_LOAD)\n",
        "        scalers = {}\n",
        "        start_time_preprocess = time.time()\n",
        "\n",
        "        for col in df.columns:\n",
        "            # Ensure no non-positive values before log transform\n",
        "            if (df[col] <= 0).any():\n",
        "                raise ValueError(f\"Column {col} contains non-positive values, cannot apply log transform.\")\n",
        "\n",
        "            # Apply natural logarithm transformation\n",
        "            df[col] = np.log(df[col])\n",
        "\n",
        "            # Initialize and fit MinMaxScaler\n",
        "            scaler = MinMaxScaler()\n",
        "            df[col] = scaler.fit_transform(df[[col]])\n",
        "\n",
        "            # Save the scaler\n",
        "            scalers[col] = scaler\n",
        "\n",
        "        ic(f\"Data preprocessing completed in {time.time() - start_time_preprocess:.2f} seconds\")\n",
        "        ic(f\"DataFrame shape: {df.shape}\")\n",
        "\n",
        "        return df, scalers\n",
        "\n",
        "    df, scalers = load_and_preprocess_data(cfg.DATA_FILE, cfg.DATA_URL)\n",
        "    cfg.NUM_FEATURES = df.shape[1]\n",
        "\n",
        "    def evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=10):\n",
        "        top_models = []\n",
        "        for model_file in model_files:\n",
        "            cfg.MODEL_PATH = model_file\n",
        "            print(f\"\\nLoading model from {cfg.MODEL_PATH}\")\n",
        "\n",
        "            result = load_model(cfg.MODEL_PATH, cfg, cfg.DEVICE)\n",
        "            if result is None:\n",
        "                print(f\"Skipping model {cfg.MODEL_PATH} due to loading error\")\n",
        "                continue\n",
        "\n",
        "            model, params = result\n",
        "            input_size = params['input_size']\n",
        "            output_size = params['output_size']\n",
        "            n_past = params['n_past']\n",
        "            n_future = params['n_future']\n",
        "            num_features = cfg.NUM_FEATURES\n",
        "            model_type = params.get('model_type', 'unknown')\n",
        "\n",
        "            # Get the input columns\n",
        "            input_cols = df.columns[:input_size]\n",
        "\n",
        "            try:\n",
        "                input_data, target_data = get_random_sample(df, n_past, n_future, input_cols, input_cols)\n",
        "            except Exception as e:\n",
        "                print(f\"Error getting random sample: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            # Prepare the tensors\n",
        "            try:\n",
        "                input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "                target_tensor = torch.tensor(target_data, dtype=torch.float32).to(cfg.DEVICE)\n",
        "            except Exception as e:\n",
        "                print(f\"Error preparing tensors: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    if model_type == 'transformer':\n",
        "                        # For Transformer, prepare tgt_input with zeros\n",
        "                        tgt_input = torch.zeros((1, n_future, input_size), device=cfg.DEVICE)\n",
        "                        prediction = model(input_tensor, tgt_input)\n",
        "                    elif model_type == 'single_step_lstm':\n",
        "                        # For single-step LSTM, perform iterative predictions\n",
        "                        prediction = []\n",
        "                        current_input = input_tensor.clone()\n",
        "                        for _ in range(n_future):\n",
        "                            pred = model(current_input)  # pred shape: (1, 13)\n",
        "                            prediction.append(pred)\n",
        "                            # Append the prediction to current_input and remove the first timestep\n",
        "                            pred_unsqueezed = pred.unsqueeze(1)  # (1, 1, 13)\n",
        "                            current_input = torch.cat((current_input[:, 1:, :], pred_unsqueezed), dim=1)  # (1, n_past, 13)\n",
        "                        prediction = torch.cat(prediction, dim=1)  # (1, n_future, 13)\n",
        "                    else:\n",
        "                        print(f\"Unknown model type for file: {model_file}\")\n",
        "                        continue\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to make predictions: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Convert tensors to numpy\n",
        "            input_np = input_tensor.squeeze(0).cpu().numpy()  # (n_past, 13)\n",
        "            target_np = target_tensor.cpu().numpy()  # (n_future, 13)\n",
        "            prediction_np = prediction.cpu().numpy()  # (1, n_future, 13)\n",
        "\n",
        "            # Handle multi-step predictions\n",
        "            try:\n",
        "                if model_type == 'transformer':\n",
        "                    # Transformer: output_size should be n_future * num_features\n",
        "                    if output_size != n_future * num_features:\n",
        "                        print(f\"Model's output_size ({output_size}) does not match n_future * num_features ({n_future * num_features}). Skipping model.\")\n",
        "                        continue\n",
        "                    prediction_np = prediction_np.reshape(-1, n_future, num_features)\n",
        "                    target_np = target_np.reshape(-1, n_future, num_features)\n",
        "                    input_np = input_np.reshape(-1, num_features)\n",
        "                elif model_type == 'single_step_lstm':\n",
        "                    # LSTM: prediction_np is already (1, n_future, 13)\n",
        "                    if output_size != num_features:\n",
        "                        print(f\"LSTM model's output_size ({output_size}) does not match num_features ({num_features}). Skipping model.\")\n",
        "                        continue\n",
        "                    # Reshape to (-1, n_future, num_features)\n",
        "                    prediction_np = prediction_np.reshape(-1, n_future, num_features)\n",
        "                    target_np = target_np.reshape(-1, n_future, num_features)\n",
        "                    input_np = input_np.reshape(-1, num_features)\n",
        "                else:\n",
        "                    print(f\"Unexpected model type for {model_file}. Skipping model.\")\n",
        "                    continue\n",
        "            except ValueError as ve:\n",
        "                print(f\"ValueError during reshaping: {ve}. Skipping model.\")\n",
        "                continue\n",
        "\n",
        "            # Inverse transform\n",
        "            try:\n",
        "                inv_input, inv_target, inv_pred = get_original_values(\n",
        "                    df.columns, input_np, target_np, prediction_np, scalers, n_future, num_features\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"Error during inverse transformation: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            print(\"Calculating scores...\")\n",
        "            try:\n",
        "                model_score = calculate_score(inv_target, inv_pred)\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating score: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Append and maintain top N\n",
        "            top_models.append((model_file, model_score))\n",
        "            top_models = sorted(top_models, key=lambda x: x[1])\n",
        "            top_models = top_models[:top_n]\n",
        "\n",
        "            print(f\"Current top {len(top_models)} models:\")\n",
        "            for m, s in top_models:\n",
        "                print(f\"  Model: {m}, Score: {s:.2%}\")\n",
        "\n",
        "        return top_models\n",
        "\n",
        "    # Create a list of model files\n",
        "    model_files = glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.ckpt\"), recursive=True) + \\\n",
        "                  glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.pth\"), recursive=True)\n",
        "    print(f\"Total model files found: {len(model_files)}\")\n",
        "\n",
        "    # Optionally, truncate the list for testing\n",
        "    model_files = model_files[:20]  # Adjust as needed\n",
        "\n",
        "    # Evaluate models and get top N\n",
        "    top_n = 10\n",
        "    top_models = evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=top_n)\n",
        "\n",
        "    # Display Top N models\n",
        "    print(f\"\\nTop {len(top_models)} models:\")\n",
        "    for model_file, score in top_models:\n",
        "        print(f\"Model: {model_file}, Score: {score:.2%}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a list of model files\n",
        "model_files = glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.ckpt\"), recursive=True) + \\\n",
        "              glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.pth\"), recursive=True)\n",
        "print(f\"Total model files found: {len(model_files)}\")\n",
        "\n",
        "# Optionally, truncate the list for testing\n",
        "model_files = model_files[:20]  # Adjust as needed\n",
        "\n",
        "# Evaluate models and get top N\n",
        "top_n = 10\n",
        "top_models = evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=top_n)\n",
        "\n",
        "# Display Top N models\n",
        "print(f\"\\nTop {len(top_models)} models:\")\n",
        "for model_file, score in top_models:\n",
        "    print(f\"Model: {model_file}, Score: {score:.2%}\")\n"
      ],
      "metadata": {
        "id": "AYBo89UBL1Pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "import multiprocessing\n",
        "import glob\n",
        "import numpy as np\n",
        "from rich.console import Console\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from icecream import ic  # Ensure icecream is installed (`pip install icecream`)\n",
        "import traceback\n",
        "import warnings\n",
        "\n",
        "# Initialize Rich Console\n",
        "console = Console()\n",
        "\n",
        "# Define your CryptoTransformer class\n",
        "class CryptoTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_size, d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
        "                 dim_feedforward, dropout, activation, n_future, num_outputs, max_seq_length):\n",
        "        super(CryptoTransformer, self).__init__()\n",
        "        self.transformer = torch.nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "        )\n",
        "        self.input_fc = torch.nn.Linear(input_size, d_model)\n",
        "        self.output_fc = torch.nn.Linear(d_model, num_outputs)\n",
        "        self.n_future = n_future\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.input_fc(src)\n",
        "        tgt = self.input_fc(tgt)\n",
        "        output = self.transformer(src, tgt)\n",
        "        output = self.output_fc(output)\n",
        "        return output\n",
        "\n",
        "# Define your CryptoLSTM class with corrected LayerNorm naming\n",
        "class CryptoLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size, has_layer_norm=False):\n",
        "        super(CryptoLSTM, self).__init__()\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                                  dropout=dropout, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
        "        if has_layer_norm:\n",
        "            self.layer_norm = torch.nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        if hasattr(self, 'layer_norm'):\n",
        "            out = self.layer_norm(out)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Function to find a suitable number of attention heads\n",
        "def find_nhead(d_model, max_nhead=16, min_head_dim=8):\n",
        "    for nhead in range(max_nhead, 0, -1):\n",
        "        if d_model % nhead == 0:\n",
        "            head_dim = d_model // nhead\n",
        "            if head_dim >= min_head_dim:\n",
        "                return nhead\n",
        "    return 1  # Fallback to single head\n",
        "\n",
        "# Function to inverse transform data\n",
        "def get_original_values(df_columns, input_np, target_np, prediction_np, scalers):\n",
        "    inv_pred = pd.DataFrame()\n",
        "    inv_target = pd.DataFrame()\n",
        "    inv_input = pd.DataFrame()\n",
        "\n",
        "    num_features = len(df_columns)\n",
        "    for i, col in enumerate(df_columns):\n",
        "        scaler = scalers.get(col)\n",
        "        if scaler:\n",
        "            # For predictions and targets, flatten the sequences\n",
        "            pred_values = prediction_np[:, :, i].flatten()\n",
        "            target_values = target_np[:, :, i].flatten()\n",
        "            inv_pred[col] = np.exp(scaler.inverse_transform(pred_values.reshape(-1, 1)).flatten())\n",
        "            inv_target[col] = np.exp(scaler.inverse_transform(target_values.reshape(-1, 1)).flatten())\n",
        "            # For input, only take the last timestep\n",
        "            input_values = input_np[:, -1, i]\n",
        "            inv_input[col] = np.exp(scaler.inverse_transform(input_values.reshape(-1, 1)).flatten())\n",
        "\n",
        "    return inv_input, inv_target, inv_pred\n",
        "\n",
        "# Function to calculate the score\n",
        "def calculate_score(inv_target, inv_pred):\n",
        "    scores = {}\n",
        "    for col in inv_target.columns:\n",
        "        # Ensure lengths match\n",
        "        min_len = min(len(inv_target[col]), len(inv_pred[col]))\n",
        "        target_col = inv_target[col][:min_len]\n",
        "        pred_col = inv_pred[col][:min_len]\n",
        "        # Calculate the absolute percentage error\n",
        "        ape = np.abs((target_col - pred_col) / target_col)\n",
        "        # Handle division by zero\n",
        "        ape = ape.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "        # Calculate the mean absolute percentage error\n",
        "        mape = ape.mean()\n",
        "        scores[col] = mape\n",
        "    # Calculate the overall score (average of individual scores)\n",
        "    overall_score = np.mean(list(scores.values()))\n",
        "    print(f\"Overall Score: {overall_score:.2%}\")\n",
        "    return overall_score\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*does not have many workers.*\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*torch.load.*\")\n",
        "\n",
        "def load_model(model_file, cfg, device='cpu'):\n",
        "    try:\n",
        "        if not os.path.exists(model_file):\n",
        "            print(f\"File not found: {model_file}\")\n",
        "            return None\n",
        "\n",
        "        # Load the state dict\n",
        "        state_dict = torch.load(model_file, map_location=device)\n",
        "\n",
        "        # Check if it's a Lightning checkpoint\n",
        "        if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n",
        "            state_dict = state_dict['state_dict']\n",
        "\n",
        "        # Strip 'model.' prefix if present\n",
        "        if any(key.startswith('model.') for key in state_dict.keys()):\n",
        "            new_state_dict = {}\n",
        "            for k, v in state_dict.items():\n",
        "                if k.startswith('model.'):\n",
        "                    new_k = k[6:]  # Remove 'model.' prefix\n",
        "                else:\n",
        "                    new_k = k\n",
        "                new_state_dict[new_k] = v\n",
        "            state_dict = new_state_dict\n",
        "\n",
        "        # Determine the model type based on key prefixes\n",
        "        if any(key.startswith('lstm') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoLSTM\")\n",
        "\n",
        "            # Infer LSTM parameters\n",
        "            lstm_weight_ih_keys = [k for k in state_dict.keys() if k.startswith('lstm.weight_ih_l')]\n",
        "            num_layers = len(lstm_weight_ih_keys)\n",
        "            if num_layers == 0:\n",
        "                print(f\"No LSTM layers found in {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "                return None\n",
        "\n",
        "            sample_weight_ih = state_dict[lstm_weight_ih_keys[0]]\n",
        "            hidden_size = sample_weight_ih.shape[0] // 4  # LSTM gates\n",
        "            input_size = sample_weight_ih.shape[1]\n",
        "\n",
        "            if 'fc.weight' in state_dict:\n",
        "                output_size = state_dict['fc.weight'].shape[0]\n",
        "            elif 'fc.bias' in state_dict:\n",
        "                output_size = state_dict['fc.bias'].shape[0]\n",
        "            else:\n",
        "                print(f\"Could not infer output_size for LSTM in {model_file}. Using default: {cfg.NUM_FEATURES}\")\n",
        "                output_size = cfg.NUM_FEATURES\n",
        "\n",
        "            # Infer if LayerNorm is present\n",
        "            has_layer_norm = any('layer_norm' in key or 'ln' in key for key in state_dict.keys())\n",
        "            print(f\"Inferred LSTM parameters: hidden_size={hidden_size}, num_layers={num_layers}, \"\n",
        "                  f\"input_size={input_size}, output_size={output_size}, LayerNorm={has_layer_norm}\")\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoLSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hidden_size,\n",
        "                num_layers=num_layers,\n",
        "                dropout=cfg.DROPOUT,\n",
        "                output_size=output_size,\n",
        "                has_layer_norm=has_layer_norm\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {'input_size': input_size, 'output_size': output_size,\n",
        "                          'n_past': cfg.N_PAST, 'n_future': cfg.N_FUTURE, 'model_type': 'lstm'}\n",
        "\n",
        "        elif any(key.startswith('transformer') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoTransformer\")\n",
        "            # Attempt to infer Transformer parameters from state_dict\n",
        "\n",
        "            # Infer d_model from the first transformer's in_proj_weight\n",
        "            d_model = cfg.HIDDEN_SIZE  # Default value\n",
        "            for key in state_dict.keys():\n",
        "                if 'transformer_encoder.layers.0.self_attn.in_proj_weight' in key:\n",
        "                    weight = state_dict[key]\n",
        "                    d_model = weight.shape[1]  # Typically (3*d_model, d_model)\n",
        "                    break\n",
        "\n",
        "            # Find a suitable nhead\n",
        "            nhead = find_nhead(d_model)\n",
        "            if nhead == 1 and d_model < 8:\n",
        "                print(f\"Could not find a suitable nhead for d_model={d_model}. Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Infer number of encoder and decoder layers\n",
        "            transformer_encoder_keys = [k for k in state_dict.keys() if 'transformer_encoder.layers.' in k]\n",
        "            num_encoder_layers = len(set(k.split('.')[3] for k in transformer_encoder_keys))\n",
        "            transformer_decoder_keys = [k for k in state_dict.keys() if 'transformer_decoder.layers.' in k]\n",
        "            num_decoder_layers = len(set(k.split('.')[3] for k in transformer_decoder_keys))\n",
        "\n",
        "            # Infer dim_feedforward from the first linear layer\n",
        "            dim_feedforward = cfg.DIM_FEEDFORWARD if hasattr(cfg, 'DIM_FEEDFORWARD') else 2048\n",
        "            dropout = cfg.DROPOUT\n",
        "            activation = 'gelu'  # Defaulting to 'gelu'\n",
        "\n",
        "            print(f\"Inferred Transformer parameters: d_model={d_model}, nhead={nhead}, \"\n",
        "                  f\"num_encoder_layers={num_encoder_layers}, num_decoder_layers={num_decoder_layers}, \"\n",
        "                  f\"dim_feedforward={dim_feedforward}, dropout={dropout}, activation={activation}\")\n",
        "\n",
        "            if 'output_fc.weight' in state_dict:\n",
        "                num_outputs = state_dict['output_fc.weight'].shape[1]\n",
        "                output_size = state_dict['output_fc.weight'].shape[0]\n",
        "            else:\n",
        "                num_outputs = cfg.NUM_FEATURES\n",
        "                output_size = cfg.NUM_FEATURES\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoTransformer(\n",
        "                input_size=cfg.NUM_FEATURES,\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                num_encoder_layers=num_encoder_layers,\n",
        "                num_decoder_layers=num_decoder_layers,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                activation=activation,\n",
        "                n_future=cfg.N_FUTURE,\n",
        "                num_outputs=output_size,\n",
        "                max_seq_length=cfg.N_PAST + cfg.N_FUTURE\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {\n",
        "                'input_size': cfg.NUM_FEATURES,\n",
        "                'output_size': output_size,\n",
        "                'n_past': cfg.N_PAST,\n",
        "                'n_future': cfg.N_FUTURE,\n",
        "                'model_type': 'transformer'\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"Unrecognized model format for {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load model {model_file}: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# Function to prepare input data\n",
        "def prepare_input(input_data, device):\n",
        "    input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    return input_tensor\n",
        "\n",
        "# Function to get a random sample from the DataFrame\n",
        "def get_random_sample(df, n_past, n_future, input_cols, target_cols):\n",
        "    max_start = len(df) - n_past - n_future\n",
        "    if max_start <= 0:\n",
        "        raise ValueError(\"DataFrame is too short for the given n_past and n_future\")\n",
        "    start_idx = np.random.randint(0, max_start)\n",
        "    input_data = df[input_cols].iloc[start_idx:start_idx + n_past].values\n",
        "    target_data = df[target_cols].iloc[start_idx + n_past:start_idx + n_past + n_future].values\n",
        "    return input_data, target_data\n",
        "\n",
        "# Function to convert tensors to numpy arrays\n",
        "def convert_to_numpy(input_tensor, target, prediction):\n",
        "    input_np = input_tensor.cpu().numpy()\n",
        "    target_np = target.cpu().numpy()\n",
        "    prediction_np = prediction.cpu().numpy()\n",
        "    return input_np, target_np, prediction_np\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    VERSION_N: int = 1\n",
        "    RECORDS_TO_LOAD: int = 1205040\n",
        "    N_PAST: int = 3 * 12 * 3  # 1 week of 10-minute intervals (108)\n",
        "    N_FUTURE: int = 1 * 12 * 2  # 1 day of 10-minute intervals (24)\n",
        "    BATCH_SIZE: int = 5000\n",
        "    HIDDEN_SIZE: int = 512  # Adjusted to match inferred d_model=512\n",
        "    NUM_LAYERS: int = 2\n",
        "    DROPOUT: float = 0.2\n",
        "    NUM_EPOCHS: int = 150\n",
        "    HOT_RESTART: bool = True\n",
        "    TRAIN_FIRST: bool = True\n",
        "    EPOCH_TO_RESTART: int = 50\n",
        "    BATCH_FACTOR: int = 81\n",
        "    DEBUG_FREQ: int = 180\n",
        "    num_cpus = multiprocessing.cpu_count()\n",
        "    NUM_WORKERS = max((num_cpus // 4 - 4), 4) if num_cpus > 16 else 4\n",
        "    DEBUG_ON: bool = False\n",
        "    DATA_URL: str = 'https://sambo.us-iad-1.linodeobjects.com/fillnan_combined_df.csv'\n",
        "    DATA_FILE: str = './data/fill_nan_df.csv'\n",
        "    MODEL_PATH: str = \"\"\n",
        "    MODEL_SAVE_PATH: str = f'./yay'\n",
        "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    EPSILON: float = 1e-4\n",
        "    PATH_TO_SEARCH: str = \"/content/drive/MyDrive/Kraken\"\n",
        "    # Additional parameters\n",
        "    NUM_FEATURES: int = None  # To be set after loading data\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_and_preprocess_data(file_path: str, download_url: str = None):\n",
        "    ic(\"Starting data loading and preprocessing...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        ic(f\"File {file_path} does not exist.\")\n",
        "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "        if download_url:\n",
        "            ic(f\"Downloading file from {download_url}...\")\n",
        "            try:\n",
        "                response = requests.get(download_url, stream=True)\n",
        "                response.raise_for_status()\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    for chunk in response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "                ic(f\"File downloaded and saved to {file_path}\")\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                ic(f\"Failed to download the file: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            ic(\"Download URL not provided. Cannot download the file.\")\n",
        "            raise FileNotFoundError(f\"The file {file_path} does not exist and no download URL was provided.\")\n",
        "\n",
        "    # Load the DataFrame\n",
        "    df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "    df = df.tail(cfg.RECORDS_TO_LOAD)\n",
        "    scalers = {}\n",
        "    start_time_preprocess = time.time()\n",
        "\n",
        "    for col in df.columns:\n",
        "        # Ensure no non-positive values before log transform\n",
        "        if (df[col] <= 0).any():\n",
        "            raise ValueError(f\"Column {col} contains non-positive values, cannot apply log transform.\")\n",
        "\n",
        "        # Apply natural logarithm transformation\n",
        "        df[col] = np.log(df[col])\n",
        "\n",
        "        # Initialize and fit MinMaxScaler\n",
        "        scaler = MinMaxScaler()\n",
        "        df[col] = scaler.fit_transform(df[[col]])\n",
        "\n",
        "        # Save the scaler\n",
        "        scalers[col] = scaler\n",
        "\n",
        "    ic(f\"Data preprocessing completed in {time.time() - start_time_preprocess:.2f} seconds\")\n",
        "    ic(f\"DataFrame shape: {df.shape}\")\n",
        "\n",
        "    return df, scalers\n",
        "\n",
        "df, scalers = load_and_preprocess_data(cfg.DATA_FILE, cfg.DATA_URL)\n",
        "cfg.NUM_FEATURES = df.shape[1]\n",
        "\n",
        "def evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=10):\n",
        "    top_models = []\n",
        "    for model_file in model_files:\n",
        "        cfg.MODEL_PATH = model_file\n",
        "        print(f\"\\nLoading model from {cfg.MODEL_PATH}\")\n",
        "\n",
        "        result = load_model(cfg.MODEL_PATH, cfg, cfg.DEVICE)\n",
        "        if result is None:\n",
        "            print(f\"Skipping model {cfg.MODEL_PATH} due to loading error\")\n",
        "            continue\n",
        "\n",
        "        model, params = result\n",
        "        input_size = params['input_size']\n",
        "        output_size = params['output_size']\n",
        "        n_past = params['n_past']\n",
        "        n_future = params['n_future']\n",
        "        num_features = cfg.NUM_FEATURES\n",
        "        model_type = params.get('model_type', 'unknown')\n",
        "\n",
        "        # Get the input columns\n",
        "        input_cols = df.columns[:input_size]\n",
        "\n",
        "        try:\n",
        "            input_data, target_data = get_random_sample(df, n_past, n_future, input_cols, input_cols)\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting random sample: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Prepare the tensors\n",
        "        try:\n",
        "            input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "            target_tensor = torch.tensor(target_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing tensors: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if model_type == 'transformer':\n",
        "                    # For Transformer, prepare tgt_input with zeros\n",
        "                    tgt_input = torch.zeros((1, n_future, input_size), device=cfg.DEVICE)\n",
        "                    prediction = model(input_tensor, tgt_input)\n",
        "                elif model_type == 'lstm':\n",
        "                    prediction = model(input_tensor)\n",
        "                else:\n",
        "                    print(f\"Unknown model type for file: {model_file}\")\n",
        "                    continue\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to make predictions: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Convert tensors to numpy\n",
        "        input_np = input_tensor.cpu().numpy()  # (1, n_past, num_features)\n",
        "        target_np = target_tensor.cpu().numpy()  # (1, n_future, num_features)\n",
        "        prediction_np = prediction.cpu().numpy()  # Expected to be (1, n_future, num_features)\n",
        "\n",
        "        # Handle predictions\n",
        "        try:\n",
        "            if prediction_np.shape[1] != n_future:\n",
        "                print(f\"Prediction output has unexpected number of timesteps: {prediction_np.shape[1]}\")\n",
        "                continue\n",
        "            # Ensure shapes are correct\n",
        "            input_np = input_np.reshape(-1, n_past, num_features)\n",
        "            target_np = target_np.reshape(-1, n_future, num_features)\n",
        "            prediction_np = prediction_np.reshape(-1, n_future, num_features)\n",
        "        except ValueError as ve:\n",
        "            print(f\"ValueError during reshaping: {ve}. Skipping model.\")\n",
        "            continue\n",
        "\n",
        "        # Inverse transform\n",
        "        try:\n",
        "            inv_input, inv_target, inv_pred = get_original_values(\n",
        "                df.columns, input_np, target_np, prediction_np, scalers\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error during inverse transformation: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        print(\"Calculating scores...\")\n",
        "        try:\n",
        "            model_score = calculate_score(inv_target, inv_pred)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating score: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Append and maintain top N\n",
        "        top_models.append((model_file, model_score))\n",
        "        top_models = sorted(top_models, key=lambda x: x[1])\n",
        "        top_models = top_models[:top_n]\n",
        "\n",
        "        print(f\"Current top {len(top_models)} models:\")\n",
        "        for m, s in top_models:\n",
        "            print(f\"  Model: {m}, Score: {s:.2%}\")\n",
        "\n",
        "    return top_models\n",
        "\n",
        "# Create a list of model files\n",
        "model_files = glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.ckpt\"), recursive=True) + \\\n",
        "              glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.pth\"), recursive=True)\n",
        "print(f\"Total model files found: {len(model_files)}\")\n",
        "\n",
        "# Optionally, truncate the list for testing\n",
        "model_files = model_files[:20]  # Adjust as needed\n",
        "\n",
        "# Evaluate models and get top N\n",
        "top_n = 10\n",
        "top_models = evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=top_n)\n",
        "\n",
        "# Display Top N models\n",
        "print(f\"\\nTop {len(top_models)} models:\")\n",
        "for model_file, score in top_models:\n",
        "    print(f\"Model: {model_file}, Score: {score:.2%}\")\n"
      ],
      "metadata": {
        "id": "v4JBfGjVb588"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "import multiprocessing\n",
        "import glob\n",
        "import numpy as np\n",
        "from rich.console import Console\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from icecream import ic  # Ensure icecream is installed (`pip install icecream`)\n",
        "import traceback\n",
        "import warnings\n",
        "\n",
        "# Initialize Rich Console\n",
        "console = Console()\n",
        "\n",
        "# Define your CryptoTransformer class\n",
        "class CryptoTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_size, d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
        "                 dim_feedforward, dropout, activation, n_future, num_outputs, max_seq_length):\n",
        "        super(CryptoTransformer, self).__init__()\n",
        "        self.transformer = torch.nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "        )\n",
        "        self.input_fc = torch.nn.Linear(input_size, d_model)\n",
        "        self.output_fc = torch.nn.Linear(d_model, num_outputs)\n",
        "        self.n_future = n_future\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.input_fc(src)\n",
        "        tgt = self.input_fc(tgt)\n",
        "        output = self.transformer(src, tgt)\n",
        "        output = self.output_fc(output)\n",
        "        return output\n",
        "\n",
        "# Define your CryptoLSTM class with corrected LayerNorm naming\n",
        "class CryptoLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size, has_layer_norm=False):\n",
        "        super(CryptoLSTM, self).__init__()\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                                  dropout=dropout, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
        "        if has_layer_norm:\n",
        "            self.layer_norm = torch.nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        if hasattr(self, 'layer_norm'):\n",
        "            out = self.layer_norm(out)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Function to find a suitable number of attention heads\n",
        "def find_nhead(d_model, max_nhead=16, min_head_dim=8):\n",
        "    for nhead in range(max_nhead, 0, -1):\n",
        "        if d_model % nhead == 0:\n",
        "            head_dim = d_model // nhead\n",
        "            if head_dim >= min_head_dim:\n",
        "                return nhead\n",
        "    return 1  # Fallback to single head\n",
        "\n",
        "# Function to inverse transform data\n",
        "def get_original_values(df_columns, input_np, target_np, prediction_np, scalers):\n",
        "    inv_pred = pd.DataFrame()\n",
        "    inv_target = pd.DataFrame()\n",
        "    inv_input = pd.DataFrame()\n",
        "\n",
        "    num_features = len(df_columns)\n",
        "    for i, col in enumerate(df_columns):\n",
        "        scaler = scalers.get(col)\n",
        "        if scaler:\n",
        "            # For predictions and targets, flatten the sequences\n",
        "            pred_values = prediction_np[:, :, i].flatten()\n",
        "            target_values = target_np[:, :, i].flatten()\n",
        "            inv_pred[col] = np.exp(scaler.inverse_transform(pred_values.reshape(-1, 1)).flatten())\n",
        "            inv_target[col] = np.exp(scaler.inverse_transform(target_values.reshape(-1, 1)).flatten())\n",
        "            # For input, only take the last timestep\n",
        "            input_values = input_np[:, -1, i]\n",
        "            inv_input[col] = np.exp(scaler.inverse_transform(input_values.reshape(-1, 1)).flatten())\n",
        "\n",
        "    return inv_input, inv_target, inv_pred\n",
        "\n",
        "# Function to calculate the score\n",
        "def calculate_score(inv_target, inv_pred):\n",
        "    scores = {}\n",
        "    for col in inv_target.columns:\n",
        "        # Ensure lengths match\n",
        "        min_len = min(len(inv_target[col]), len(inv_pred[col]))\n",
        "        target_col = inv_target[col][:min_len]\n",
        "        pred_col = inv_pred[col][:min_len]\n",
        "        # Calculate the absolute percentage error\n",
        "        ape = np.abs((target_col - pred_col) / target_col)\n",
        "        # Handle division by zero\n",
        "        ape = ape.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "        # Calculate the mean absolute percentage error\n",
        "        mape = ape.mean()\n",
        "        scores[col] = mape\n",
        "    # Calculate the overall score (average of individual scores)\n",
        "    overall_score = np.mean(list(scores.values()))\n",
        "    print(f\"Overall Score: {overall_score:.2%}\")\n",
        "    return overall_score\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*does not have many workers.*\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*torch.load.*\")\n",
        "\n",
        "def load_model(model_file, cfg, device='cpu'):\n",
        "    try:\n",
        "        if not os.path.exists(model_file):\n",
        "            print(f\"File not found: {model_file}\")\n",
        "            return None\n",
        "\n",
        "        # Load the state dict\n",
        "        state_dict = torch.load(model_file, map_location=device)\n",
        "\n",
        "        # Check if it's a Lightning checkpoint\n",
        "        if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n",
        "            state_dict = state_dict['state_dict']\n",
        "\n",
        "        # Strip 'model.' prefix if present\n",
        "        if any(key.startswith('model.') for key in state_dict.keys()):\n",
        "            new_state_dict = {}\n",
        "            for k, v in state_dict.items():\n",
        "                if k.startswith('model.'):\n",
        "                    new_k = k[6:]  # Remove 'model.' prefix\n",
        "                else:\n",
        "                    new_k = k\n",
        "                new_state_dict[new_k] = v\n",
        "            state_dict = new_state_dict\n",
        "\n",
        "        # Determine the model type based on key prefixes\n",
        "        if any(key.startswith('lstm') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoLSTM\")\n",
        "\n",
        "            # Infer LSTM parameters\n",
        "            lstm_weight_ih_keys = [k for k in state_dict.keys() if k.startswith('lstm.weight_ih_l')]\n",
        "            num_layers = len(lstm_weight_ih_keys)\n",
        "            if num_layers == 0:\n",
        "                print(f\"No LSTM layers found in {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "                return None\n",
        "\n",
        "            sample_weight_ih = state_dict[lstm_weight_ih_keys[0]]\n",
        "            hidden_size = sample_weight_ih.shape[0] // 4  # LSTM gates\n",
        "            input_size = sample_weight_ih.shape[1]\n",
        "\n",
        "            if 'fc.weight' in state_dict:\n",
        "                output_size = state_dict['fc.weight'].shape[0]\n",
        "            elif 'fc.bias' in state_dict:\n",
        "                output_size = state_dict['fc.bias'].shape[0]\n",
        "            else:\n",
        "                print(f\"Could not infer output_size for LSTM in {model_file}. Using default: {cfg.NUM_FEATURES}\")\n",
        "                output_size = cfg.NUM_FEATURES\n",
        "\n",
        "            # Infer if LayerNorm is present\n",
        "            has_layer_norm = any('layer_norm' in key or 'ln' in key for key in state_dict.keys())\n",
        "            print(f\"Inferred LSTM parameters: hidden_size={hidden_size}, num_layers={num_layers}, \"\n",
        "                  f\"input_size={input_size}, output_size={output_size}, LayerNorm={has_layer_norm}\")\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoLSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hidden_size,\n",
        "                num_layers=num_layers,\n",
        "                dropout=cfg.DROPOUT,\n",
        "                output_size=output_size,\n",
        "                has_layer_norm=has_layer_norm\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {'input_size': input_size, 'output_size': output_size,\n",
        "                          'n_past': cfg.N_PAST, 'n_future': cfg.N_FUTURE, 'model_type': 'lstm'}\n",
        "\n",
        "        elif any(key.startswith('transformer') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoTransformer\")\n",
        "            # Attempt to infer Transformer parameters from state_dict\n",
        "\n",
        "            # Infer d_model from the first transformer's in_proj_weight\n",
        "            d_model = cfg.HIDDEN_SIZE  # Default value\n",
        "            for key in state_dict.keys():\n",
        "                if 'transformer_encoder.layers.0.self_attn.in_proj_weight' in key:\n",
        "                    weight = state_dict[key]\n",
        "                    d_model = weight.shape[1]  # Typically (3*d_model, d_model)\n",
        "                    break\n",
        "\n",
        "            # Find a suitable nhead\n",
        "            nhead = find_nhead(d_model)\n",
        "            if nhead == 1 and d_model < 8:\n",
        "                print(f\"Could not find a suitable nhead for d_model={d_model}. Skipping model.\")\n",
        "                return None\n",
        "\n",
        "            # Infer number of encoder and decoder layers\n",
        "            transformer_encoder_keys = [k for k in state_dict.keys() if 'transformer_encoder.layers.' in k]\n",
        "            num_encoder_layers = len(set(k.split('.')[3] for k in transformer_encoder_keys))\n",
        "            transformer_decoder_keys = [k for k in state_dict.keys() if 'transformer_decoder.layers.' in k]\n",
        "            num_decoder_layers = len(set(k.split('.')[3] for k in transformer_decoder_keys))\n",
        "\n",
        "            # Infer dim_feedforward from the first linear layer\n",
        "            dim_feedforward = cfg.DIM_FEEDFORWARD if hasattr(cfg, 'DIM_FEEDFORWARD') else 2048\n",
        "            dropout = cfg.DROPOUT\n",
        "            activation = 'gelu'  # Defaulting to 'gelu'\n",
        "\n",
        "            print(f\"Inferred Transformer parameters: d_model={d_model}, nhead={nhead}, \"\n",
        "                  f\"num_encoder_layers={num_encoder_layers}, num_decoder_layers={num_decoder_layers}, \"\n",
        "                  f\"dim_feedforward={dim_feedforward}, dropout={dropout}, activation={activation}\")\n",
        "\n",
        "            if 'output_fc.weight' in state_dict:\n",
        "                num_outputs = state_dict['output_fc.weight'].shape[1]\n",
        "                output_size = state_dict['output_fc.weight'].shape[0]\n",
        "            else:\n",
        "                num_outputs = cfg.NUM_FEATURES\n",
        "                output_size = cfg.NUM_FEATURES\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoTransformer(\n",
        "                input_size=cfg.NUM_FEATURES,\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                num_encoder_layers=num_encoder_layers,\n",
        "                num_decoder_layers=num_decoder_layers,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                activation=activation,\n",
        "                n_future=cfg.N_FUTURE,\n",
        "                num_outputs=output_size,\n",
        "                max_seq_length=cfg.N_PAST + cfg.N_FUTURE\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {\n",
        "                'input_size': cfg.NUM_FEATURES,\n",
        "                'output_size': output_size,\n",
        "                'n_past': cfg.N_PAST,\n",
        "                'n_future': cfg.N_FUTURE,\n",
        "                'model_type': 'transformer'\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"Unrecognized model format for {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load model {model_file}: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# Function to prepare input data\n",
        "def prepare_input(input_data, device):\n",
        "    input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    return input_tensor\n",
        "\n",
        "# Function to get a random sample from the DataFrame\n",
        "def get_random_sample(df, n_past, n_future, input_cols, target_cols):\n",
        "    max_start = len(df) - n_past - n_future\n",
        "    if max_start <= 0:\n",
        "        raise ValueError(\"DataFrame is too short for the given n_past and n_future\")\n",
        "    start_idx = np.random.randint(0, max_start)\n",
        "    input_data = df[input_cols].iloc[start_idx:start_idx + n_past].values\n",
        "    target_data = df[target_cols].iloc[start_idx + n_past:start_idx + n_past + n_future].values\n",
        "    return input_data, target_data\n",
        "\n",
        "# Function to convert tensors to numpy arrays\n",
        "def convert_to_numpy(input_tensor, target, prediction):\n",
        "    input_np = input_tensor.cpu().numpy()\n",
        "    target_np = target.cpu().numpy()\n",
        "    prediction_np = prediction.cpu().numpy()\n",
        "    return input_np, target_np, prediction_np\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    VERSION_N: int = 1\n",
        "    RECORDS_TO_LOAD: int = 1205040\n",
        "    N_PAST: int = 3 * 12 * 3  # 1 week of 10-minute intervals (108)\n",
        "    N_FUTURE: int = 1 * 12 * 2  # 1 day of 10-minute intervals (24)\n",
        "    BATCH_SIZE: int = 5000\n",
        "    HIDDEN_SIZE: int = 512  # Adjusted to match inferred d_model=512\n",
        "    NUM_LAYERS: int = 2\n",
        "    DROPOUT: float = 0.2\n",
        "    NUM_EPOCHS: int = 150\n",
        "    HOT_RESTART: bool = True\n",
        "    TRAIN_FIRST: bool = True\n",
        "    EPOCH_TO_RESTART: int = 50\n",
        "    BATCH_FACTOR: int = 81\n",
        "    DEBUG_FREQ: int = 180\n",
        "    num_cpus = multiprocessing.cpu_count()\n",
        "    NUM_WORKERS = max((num_cpus // 4 - 4), 4) if num_cpus > 16 else 4\n",
        "    DEBUG_ON: bool = False\n",
        "    DATA_URL: str = 'https://sambo.us-iad-1.linodeobjects.com/fillnan_combined_df.csv'\n",
        "    DATA_FILE: str = './data/fill_nan_df.csv'\n",
        "    MODEL_PATH: str = \"\"\n",
        "    MODEL_SAVE_PATH: str = f'./yay'\n",
        "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    EPSILON: float = 1e-4\n",
        "    PATH_TO_SEARCH: str = \"/content/drive/MyDrive/Kraken\"\n",
        "    # Additional parameters\n",
        "    NUM_FEATURES: int = None  # To be set after loading data\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_and_preprocess_data(file_path: str, download_url: str = None):\n",
        "    ic(\"Starting data loading and preprocessing...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        ic(f\"File {file_path} does not exist.\")\n",
        "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "        if download_url:\n",
        "            ic(f\"Downloading file from {download_url}...\")\n",
        "            try:\n",
        "                response = requests.get(download_url, stream=True)\n",
        "                response.raise_for_status()\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    for chunk in response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "                ic(f\"File downloaded and saved to {file_path}\")\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                ic(f\"Failed to download the file: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            ic(\"Download URL not provided. Cannot download the file.\")\n",
        "            raise FileNotFoundError(f\"The file {file_path} does not exist and no download URL was provided.\")\n",
        "\n",
        "    # Load the DataFrame\n",
        "    df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "    df = df.tail(cfg.RECORDS_TO_LOAD)\n",
        "    scalers = {}\n",
        "    start_time_preprocess = time.time()\n",
        "\n",
        "    for col in df.columns:\n",
        "        # Ensure no non-positive values before log transform\n",
        "        if (df[col] <= 0).any():\n",
        "            raise ValueError(f\"Column {col} contains non-positive values, cannot apply log transform.\")\n",
        "\n",
        "        # Apply natural logarithm transformation\n",
        "        df[col] = np.log(df[col])\n",
        "\n",
        "        # Initialize and fit MinMaxScaler\n",
        "        scaler = MinMaxScaler()\n",
        "        df[col] = scaler.fit_transform(df[[col]])\n",
        "\n",
        "        # Save the scaler\n",
        "        scalers[col] = scaler\n",
        "\n",
        "    ic(f\"Data preprocessing completed in {time.time() - start_time_preprocess:.2f} seconds\")\n",
        "    ic(f\"DataFrame shape: {df.shape}\")\n",
        "\n",
        "    return df, scalers\n",
        "\n",
        "df, scalers = load_and_preprocess_data(cfg.DATA_FILE, cfg.DATA_URL)\n",
        "cfg.NUM_FEATURES = df.shape[1]\n",
        "\n",
        "def evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=10):\n",
        "    top_models = []\n",
        "    for model_file in model_files:\n",
        "        cfg.MODEL_PATH = model_file\n",
        "        print(f\"\\nLoading model from {cfg.MODEL_PATH}\")\n",
        "\n",
        "        result = load_model(cfg.MODEL_PATH, cfg, cfg.DEVICE)\n",
        "        if result is None:\n",
        "            print(f\"Skipping model {cfg.MODEL_PATH} due to loading error\")\n",
        "            continue\n",
        "\n",
        "        model, params = result\n",
        "        input_size = params['input_size']\n",
        "        output_size = params['output_size']\n",
        "        n_past = params['n_past']\n",
        "        n_future = params['n_future']\n",
        "        num_features = cfg.NUM_FEATURES\n",
        "        model_type = params.get('model_type', 'unknown')\n",
        "\n",
        "        # Get the input columns\n",
        "        input_cols = df.columns[:input_size]\n",
        "\n",
        "        try:\n",
        "            input_data, target_data = get_random_sample(df, n_past, n_future, input_cols, input_cols)\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting random sample: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Prepare the tensors\n",
        "        try:\n",
        "            input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "            target_tensor = torch.tensor(target_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing tensors: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if model_type == 'transformer':\n",
        "                    # For Transformer, prepare tgt_input with zeros\n",
        "                    tgt_input = torch.zeros((1, n_future, input_size), device=cfg.DEVICE)\n",
        "                    prediction = model(input_tensor, tgt_input)\n",
        "                elif model_type == 'lstm':\n",
        "                    prediction = model(input_tensor)\n",
        "                else:\n",
        "                    print(f\"Unknown model type for file: {model_file}\")\n",
        "                    continue\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to make predictions: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Convert tensors to numpy\n",
        "        input_np = input_tensor.cpu().numpy()  # (1, n_past, num_features)\n",
        "        target_np = target_tensor.cpu().numpy()  # (1, n_future, num_features)\n",
        "        prediction_np = prediction.cpu().numpy()  # Expected to be (1, n_future, num_features)\n",
        "\n",
        "        # Handle predictions\n",
        "        try:\n",
        "            if prediction_np.shape[1] != n_future:\n",
        "                print(f\"Prediction output has unexpected number of timesteps: {prediction_np.shape[1]}\")\n",
        "                continue\n",
        "            # Ensure shapes are correct\n",
        "            input_np = input_np.reshape(-1, n_past, num_features)\n",
        "            target_np = target_np.reshape(-1, n_future, num_features)\n",
        "            prediction_np = prediction_np.reshape(-1, n_future, num_features)\n",
        "        except ValueError as ve:\n",
        "            print(f\"ValueError during reshaping: {ve}. Skipping model.\")\n",
        "            continue\n",
        "\n",
        "        # Inverse transform\n",
        "        try:\n",
        "            inv_input, inv_target, inv_pred = get_original_values(\n",
        "                df.columns, input_np, target_np, prediction_np, scalers\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error during inverse transformation: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        print(\"Calculating scores...\")\n",
        "        try:\n",
        "            model_score = calculate_score(inv_target, inv_pred)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating score: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Append and maintain top N\n",
        "        top_models.append((model_file, model_score))\n",
        "        top_models = sorted(top_models, key=lambda x: x[1])\n",
        "        top_models = top_models[:top_n]\n",
        "\n",
        "        print(f\"Current top {len(top_models)} models:\")\n",
        "        for m, s in top_models:\n",
        "            print(f\"  Model: {m}, Score: {s:.2%}\")\n",
        "\n",
        "    return top_models\n",
        "\n",
        "# Create a list of model files\n",
        "model_files = glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.ckpt\"), recursive=True) + \\\n",
        "              glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.pth\"), recursive=True)\n",
        "print(f\"Total model files found: {len(model_files)}\")\n",
        "\n",
        "# Optionally, truncate the list for testing\n",
        "model_files = model_files[:20]  # Adjust as needed\n",
        "\n",
        "# Evaluate models and get top N\n",
        "top_n = 10\n",
        "top_models = evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=top_n)\n",
        "\n",
        "# Display Top N models\n",
        "print(f\"\\nTop {len(top_models)} models:\")\n",
        "for model_file, score in top_models:\n",
        "    print(f\"Model: {model_file}, Score: {score:.2%}\")\n"
      ],
      "metadata": {
        "id": "Br4difB9O8D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "import multiprocessing\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from icecream import ic\n",
        "warnings.filterwarnings(\"ignore\", message=\".*enable_nested_tensor*\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*torch.load.*\")\n",
        "\n",
        "# Initialize Rich Console\n",
        "from rich.console import Console\n",
        "console = Console()\n",
        "\n",
        "# Define your CryptoTransformer class\n",
        "class CryptoTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_size, d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
        "                 dim_feedforward, dropout, activation, n_future, num_outputs, max_seq_length):\n",
        "        super(CryptoTransformer, self).__init__()\n",
        "        # Update attribute names to match state_dict keys\n",
        "        self.transformer_encoder = torch.nn.TransformerEncoder(\n",
        "            torch.nn.TransformerEncoderLayer(\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                activation=activation\n",
        "            ),\n",
        "            num_layers=num_encoder_layers\n",
        "        )\n",
        "        self.transformer_decoder = torch.nn.TransformerDecoder(\n",
        "            torch.nn.TransformerDecoderLayer(\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                activation=activation\n",
        "            ),\n",
        "            num_layers=num_decoder_layers\n",
        "        )\n",
        "        self.pos_encoder = torch.nn.Embedding(max_seq_length, d_model)\n",
        "        self.pos_decoder = torch.nn.Embedding(max_seq_length, d_model)\n",
        "        self.input_fc = torch.nn.Linear(input_size, d_model)\n",
        "        self.output_fc = torch.nn.Linear(d_model, num_outputs)\n",
        "        self.n_future = n_future\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # Adjust batch_first as per model's requirement\n",
        "        src_seq_len = src.size(1)\n",
        "        tgt_seq_len = tgt.size(1)\n",
        "        src_positions = torch.arange(0, src_seq_len, device=src.device).unsqueeze(0)\n",
        "        tgt_positions = torch.arange(0, tgt_seq_len, device=tgt.device).unsqueeze(0)\n",
        "        src = self.input_fc(src) + self.pos_encoder(src_positions)\n",
        "        tgt = self.input_fc(tgt) + self.pos_decoder(tgt_positions)\n",
        "        memory = self.transformer_encoder(src.transpose(0, 1))\n",
        "        output = self.transformer_decoder(tgt.transpose(0, 1), memory)\n",
        "        output = self.output_fc(output.transpose(0, 1))\n",
        "        return output\n",
        "\n",
        "# Define your CryptoLSTM class with corrected LayerNorm naming\n",
        "class CryptoLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size, has_layer_norm=False):\n",
        "        super(CryptoLSTM, self).__init__()\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                                  dropout=dropout, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
        "        if has_layer_norm:\n",
        "            self.layer_norm = torch.nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        if hasattr(self, 'layer_norm'):\n",
        "            out = self.layer_norm(out)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "def adjust_state_dict_keys(state_dict):\n",
        "    new_state_dict = {}\n",
        "    for k, v in state_dict.items():\n",
        "        # Remove the 'model.' prefix if present\n",
        "        new_key = k.replace('model.', '') if k.startswith('model.') else k\n",
        "        new_state_dict[new_key] = v\n",
        "    return new_state_dict\n",
        "def load_model(model_file, cfg, device='cpu'):\n",
        "    try:\n",
        "        if not os.path.exists(model_file):\n",
        "            print(f\"File not found: {model_file}\")\n",
        "            return None\n",
        "\n",
        "        # Load the state dict\n",
        "        try:\n",
        "            state_dict = torch.load(model_file, map_location=device)\n",
        "        except EOFError:\n",
        "            print(f\"Failed to load model {model_file}: Ran out of input\")\n",
        "            return None\n",
        "\n",
        "        # Check if it's a Lightning checkpoint\n",
        "        if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n",
        "            state_dict = state_dict['state_dict']\n",
        "\n",
        "        # Adjust state dict keys to remove 'model.' prefix\n",
        "        state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}\n",
        "\n",
        "        # Determine the model type based on key prefixes\n",
        "        if any(key.startswith('lstm') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoLSTM\")\n",
        "\n",
        "            # Infer LSTM parameters\n",
        "            lstm_weight_ih_keys = [k for k in state_dict.keys() if k.startswith('lstm.weight_ih_l')]\n",
        "            num_layers = len(lstm_weight_ih_keys)\n",
        "            if num_layers == 0:\n",
        "                print(f\"No LSTM layers found in {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "                return None\n",
        "\n",
        "            sample_weight_ih = state_dict[lstm_weight_ih_keys[0]]\n",
        "            hidden_size = sample_weight_ih.shape[0] // 4  # LSTM gates\n",
        "            input_size = sample_weight_ih.shape[1]  # Directly gives us the input feature size (`n_features`)\n",
        "\n",
        "            # Infer the output size from the state dict\n",
        "            if 'fc.weight' in state_dict:\n",
        "                output_size = state_dict['fc.weight'].shape[0]\n",
        "                # Infer the number of timesteps dynamically using output_size\n",
        "                if output_size % input_size != 0:\n",
        "                    print(f\"Output size {output_size} is not divisible by input size {input_size}. Skipping model.\")\n",
        "                    return None  # Skip models with incompatible output sizes\n",
        "\n",
        "                n_future = output_size // input_size  # Dynamically inferred number of timesteps\n",
        "            elif 'fc.bias' in state_dict:\n",
        "                output_size = state_dict['fc.bias'].shape[0]\n",
        "                n_future = output_size // input_size\n",
        "            else:\n",
        "                print(f\"Could not infer output_size for LSTM in {model_file}. Using default: {cfg.NUM_FEATURES}\")\n",
        "                output_size = cfg.NUM_FEATURES\n",
        "                n_future = cfg.N_FUTURE  # Fall back to default timesteps\n",
        "\n",
        "            # Now that `input_size` is the number of input features\n",
        "            n_features = input_size\n",
        "\n",
        "            # Infer if LayerNorm is present\n",
        "            has_layer_norm = any('layer_norm' in key or 'ln' in key for key in state_dict.keys())\n",
        "            print(f\"Inferred LSTM parameters: hidden_size={hidden_size}, num_layers={num_layers}, \"\n",
        "                  f\"n_features={n_features}, output_size={output_size}, LayerNorm={has_layer_norm}, n_future={n_future}\")\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoLSTM(\n",
        "                input_size=n_features,\n",
        "                hidden_size=hidden_size,\n",
        "                num_layers=num_layers,\n",
        "                dropout=cfg.DROPOUT,\n",
        "                output_size=output_size,\n",
        "                has_layer_norm=has_layer_norm\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {missing_keys}\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "            return model, {'input_size': n_features, 'output_size': output_size,\n",
        "                           'n_past': cfg.N_PAST, 'n_future': n_future, 'model_type': 'lstm'}\n",
        "        elif any(key.startswith('transformer') for key in state_dict.keys()):\n",
        "            print(f\"Loading {model_file} as CryptoTransformer\")\n",
        "\n",
        "            # Infer Transformer parameters\n",
        "            d_model = cfg.HIDDEN_SIZE\n",
        "            nhead = find_nhead(d_model)\n",
        "            num_encoder_layers = len(set(k.split('.')[2] for k in state_dict.keys() if k.startswith('transformer_encoder.layers.')))\n",
        "            num_decoder_layers = len(set(k.split('.')[2] for k in state_dict.keys() if k.startswith('transformer_decoder.layers.')))\n",
        "            dim_feedforward = cfg.DIM_FEEDFORWARD if hasattr(cfg, 'DIM_FEEDFORWARD') else 2048\n",
        "            dropout = cfg.DROPOUT\n",
        "            activation = 'gelu'\n",
        "\n",
        "            print(f\"Inferred Transformer parameters: d_model={d_model}, nhead={nhead}, \"\n",
        "                  f\"num_encoder_layers={num_encoder_layers}, num_decoder_layers={num_decoder_layers}, \"\n",
        "                  f\"dim_feedforward={dim_feedforward}, dropout={dropout}, activation={activation}\")\n",
        "\n",
        "            input_size = cfg.NUM_FEATURES\n",
        "            output_size = cfg.NUM_FEATURES\n",
        "\n",
        "            # Create the model\n",
        "            model = CryptoTransformer(\n",
        "                input_size=input_size,\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                num_encoder_layers=num_encoder_layers,\n",
        "                num_decoder_layers=num_decoder_layers,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                activation=activation,\n",
        "                n_future=cfg.N_FUTURE,\n",
        "                num_outputs=output_size,\n",
        "                max_seq_length=cfg.N_PAST + cfg.N_FUTURE\n",
        "            ).to(device)\n",
        "\n",
        "            # Load state dict\n",
        "            model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "            return model, {\n",
        "                'input_size': input_size,\n",
        "                'output_size': output_size,\n",
        "                'n_past': cfg.N_PAST,\n",
        "                'n_future': cfg.N_FUTURE,\n",
        "                'model_type': 'transformer'\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"Unrecognized model format for {model_file}. Keys: {list(state_dict.keys())}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load model {model_file}: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# The rest of the code remains largely the same, with adjustments to input preparation and model invocation.\n",
        "\n",
        "# Function to prepare input data\n",
        "def prepare_input(input_data, device):\n",
        "    input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    return input_tensor\n",
        "\n",
        "# Function to get a random sample from the DataFrame\n",
        "def get_random_sample(df, n_past, n_future, input_cols, target_cols):\n",
        "    max_start = len(df) - n_past - n_future\n",
        "    if max_start <= 0:\n",
        "        raise ValueError(\"DataFrame is too short for the given n_past and n_future\")\n",
        "    start_idx = np.random.randint(0, max_start)\n",
        "    input_data = df[input_cols].iloc[start_idx:start_idx + n_past].values\n",
        "    target_data = df[target_cols].iloc[start_idx + n_past:start_idx + n_past + n_future].values\n",
        "    return input_data, target_data\n",
        "\n",
        "# Function to inverse transform data\n",
        "def get_original_values(df_columns, input_np, target_np, prediction_np, scalers):\n",
        "    inv_pred = pd.DataFrame()\n",
        "    inv_target = pd.DataFrame()\n",
        "    inv_input = pd.DataFrame()\n",
        "\n",
        "    num_features = len(df_columns)\n",
        "    for i, col in enumerate(df_columns):\n",
        "        scaler = scalers.get(col)\n",
        "        if scaler:\n",
        "            # For predictions and targets, flatten the sequences\n",
        "            pred_values = prediction_np[:, :, i].flatten()\n",
        "            target_values = target_np[:, :, i].flatten()\n",
        "            inv_pred[col] = np.exp(scaler.inverse_transform(pred_values.reshape(-1, 1)).flatten())\n",
        "            inv_target[col] = np.exp(scaler.inverse_transform(target_values.reshape(-1, 1)).flatten())\n",
        "            # For input, only take the last timestep\n",
        "            input_values = input_np[:, :, i].flatten()\n",
        "            inv_input[col] = np.exp(scaler.inverse_transform(input_values.reshape(-1, 1)).flatten())\n",
        "\n",
        "    return inv_input, inv_target, inv_pred\n",
        "\n",
        "# Rest of the code remains the same\n",
        "# ...\n",
        "\n",
        "# Adjust the evaluation function to match the input expectations of your models\n",
        "def evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=10):\n",
        "    top_models = []\n",
        "    for model_file in model_files:\n",
        "        cfg.MODEL_PATH = model_file\n",
        "        print(f\"\\nLoading model from {cfg.MODEL_PATH}\")\n",
        "\n",
        "        result = load_model(cfg.MODEL_PATH, cfg, cfg.DEVICE)\n",
        "        if result is None:\n",
        "            print(f\"Skipping model {cfg.MODEL_PATH} due to loading error\")\n",
        "            continue\n",
        "\n",
        "        model, params = result\n",
        "        input_size = params['input_size']\n",
        "        output_size = params['output_size']\n",
        "        n_past = params['n_past']\n",
        "        n_future = params['n_future']\n",
        "        num_features = cfg.NUM_FEATURES\n",
        "        model_type = params.get('model_type', 'unknown')\n",
        "\n",
        "        # Get the input columns\n",
        "        input_cols = df.columns[:input_size]\n",
        "\n",
        "        try:\n",
        "            input_data, target_data = get_random_sample(df, n_past, n_future, input_cols, input_cols)\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting random sample: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Prepare the tensors\n",
        "        try:\n",
        "            input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "            target_tensor = torch.tensor(target_data, dtype=torch.float32).unsqueeze(0).to(cfg.DEVICE)\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing tensors: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if model_type == 'transformer':\n",
        "                    # Prepare tgt_input appropriately\n",
        "                    tgt_input = torch.zeros((1, n_future, input_size), device=cfg.DEVICE)\n",
        "                    prediction = model(input_tensor, tgt_input)\n",
        "                elif model_type == 'lstm':\n",
        "                    prediction = model(input_tensor)\n",
        "                else:\n",
        "                    print(f\"Unknown model type for file: {model_file}\")\n",
        "                    continue\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to make predictions: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Convert tensors to numpy\n",
        "        input_np = input_tensor.cpu().numpy()  # (1, n_past, num_features)\n",
        "        target_np = target_tensor.cpu().numpy()  # (1, n_future, num_features)\n",
        "        prediction_np = prediction.cpu().numpy()  # Expected to be (1, n_future, num_features)\n",
        "\n",
        "        # Handle predictions\n",
        "        try:\n",
        "            # if prediction_np.shape[1] != n_future:\n",
        "            #     print(f\"Prediction output has unexpected number of timesteps: {prediction_np.shape[1]}\")\n",
        "            #     continue\n",
        "            # Ensure shapes are correct\n",
        "            input_np = input_np.reshape(-1, n_past, num_features)\n",
        "            target_np = target_np.reshape(-1, n_future, num_features)\n",
        "            prediction_np = prediction_np.reshape(-1, n_future, num_features)\n",
        "        except ValueError as ve:\n",
        "            print(f\"ValueError during reshaping: {ve}. Skipping model.\")\n",
        "            continue\n",
        "\n",
        "        # Inverse transform\n",
        "        try:\n",
        "            inv_input, inv_target, inv_pred = get_original_values(\n",
        "                df.columns, input_np, target_np, prediction_np, scalers\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error during inverse transformation: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        print(\"Calculating scores...\")\n",
        "        try:\n",
        "            model_score = calculate_score(inv_target, inv_pred)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating score: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Append and maintain top N\n",
        "        top_models.append((model_file, model_score))\n",
        "        top_models = sorted(top_models, key=lambda x: x[1])\n",
        "        top_models = top_models[:top_n]\n",
        "\n",
        "        print(f\"Current top {len(top_models)} models:\")\n",
        "        for m, s in top_models:\n",
        "            print(f\"  Model: {m}, Score: {s:.2%}\")\n",
        "\n",
        "    return top_models\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    @dataclass\n",
        "    class Config:\n",
        "        VERSION_N: int = 1\n",
        "        RECORDS_TO_LOAD: int = 1205040\n",
        "        N_PAST: int = 3 * 12 * 3  # 1 week of 10-minute intervals (108)\n",
        "        N_FUTURE: int = 1 * 12 * 2  # 1 day of 10-minute intervals (24)\n",
        "        BATCH_SIZE: int = 5000\n",
        "        HIDDEN_SIZE: int = 512  # Adjusted to match inferred d_model=512\n",
        "        NUM_LAYERS: int = 2\n",
        "        DROPOUT: float = 0.2\n",
        "        NUM_EPOCHS: int = 150\n",
        "        HOT_RESTART: bool = True\n",
        "        TRAIN_FIRST: bool = True\n",
        "        EPOCH_TO_RESTART: int = 50\n",
        "        BATCH_FACTOR: int = 81\n",
        "        DEBUG_FREQ: int = 180\n",
        "        num_cpus = multiprocessing.cpu_count()\n",
        "        NUM_WORKERS = max((num_cpus // 4 - 4), 4) if num_cpus > 16 else 4\n",
        "        DEBUG_ON: bool = False\n",
        "        DATA_URL: str = 'https://sambo.us-iad-1.linodeobjects.com/fillnan_combined_df.csv'\n",
        "        DATA_FILE: str = './data/fill_nan_df.csv'\n",
        "        MODEL_PATH: str = \"\"\n",
        "        MODEL_SAVE_PATH: str = f'./yay'\n",
        "        DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        EPSILON: float = 1e-4\n",
        "        PATH_TO_SEARCH: str = \"/content/drive/MyDrive/Kraken\"\n",
        "        # Additional parameters\n",
        "        NUM_FEATURES: int = None  # To be set after loading data\n",
        "\n",
        "    cfg = Config()\n",
        "    # Load and preprocess data\n",
        "    df, scalers = load_and_preprocess_data(cfg.DATA_FILE, cfg.DATA_URL)\n",
        "    cfg.NUM_FEATURES = df.shape[1]\n",
        "\n",
        "    # Create a list of model files\n",
        "    model_files = glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.ckpt\"), recursive=True) + \\\n",
        "                  glob.glob(os.path.join(cfg.PATH_TO_SEARCH, \"**/*.pth\"), recursive=True)\n",
        "    print(f\"Total model files found: {len(model_files)}\")\n",
        "\n",
        "    # Evaluate models and get top N\n",
        "    top_n = 10\n",
        "    top_models = evaluate_and_get_top_models(model_files, cfg, df, scalers, top_n=top_n)\n",
        "\n",
        "    # Display Top N models\n",
        "    print(f\"\\nTop {len(top_models)} models:\")\n",
        "    for model_file, score in top_models:\n",
        "        print(f\"Model: {model_file}, Score: {score:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnGjER7aDp0f",
        "outputId": "efd17f46-6d73-4eda-a2cc-aa84f1af6fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| 'Starting data loading and preprocessing...'\n",
            "ic| f\"Data preprocessing completed in {time.time() - start_time_preprocess:.2f} seconds\": 'Data preprocessing completed in 0.49 seconds'\n",
            "ic| f\"DataFrame shape: {df.shape}\": 'DataFrame shape: (1102782, 13)'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total model files found: 308\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt\n",
            "Loading /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt as CryptoTransformer\n",
            "Inferred Transformer parameters: d_model=512, nhead=16, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.2, activation=gelu\n",
            "Calculating scores...\n",
            "Overall Score: 49.50%\n",
            "Current top 1 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt\n",
            "Loading /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt as CryptoTransformer\n",
            "Inferred Transformer parameters: d_model=512, nhead=16, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.2, activation=gelu\n",
            "Calculating scores...\n",
            "Overall Score: 63.68%\n",
            "Current top 2 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt\n",
            "Loading /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt as CryptoTransformer\n",
            "Inferred Transformer parameters: d_model=512, nhead=16, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.2, activation=gelu\n",
            "Calculating scores...\n",
            "Overall Score: 61.56%\n",
            "Current top 3 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/models/model-epoch=14-val_loss=0.02.ckpt\n",
            "Loading /content/drive/MyDrive/Kraken/models/model-epoch=14-val_loss=0.02.ckpt as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=2, n_features=13, output_size=312, LayerNorm=True, n_future=24\n",
            "Calculating scores...\n",
            "Overall Score: 216.60%\n",
            "Current top 4 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=14-val_loss=0.02.ckpt, Score: 216.60%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/models/model-epoch=68-val_loss=0.14.ckpt\n",
            "Loading /content/drive/MyDrive/Kraken/models/model-epoch=68-val_loss=0.14.ckpt as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=2, n_features=13, output_size=312, LayerNorm=True, n_future=24\n",
            "Calculating scores...\n",
            "Overall Score: 32102.84%\n",
            "Current top 5 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=14-val_loss=0.02.ckpt, Score: 216.60%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=68-val_loss=0.14.ckpt, Score: 32102.84%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/models/model-epoch=65-val_loss=0.13.ckpt\n",
            "Loading /content/drive/MyDrive/Kraken/models/model-epoch=65-val_loss=0.13.ckpt as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=2, n_features=13, output_size=312, LayerNorm=True, n_future=24\n",
            "Calculating scores...\n",
            "Overall Score: 7452.54%\n",
            "Current top 6 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=14-val_loss=0.02.ckpt, Score: 216.60%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=65-val_loss=0.13.ckpt, Score: 7452.54%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=68-val_loss=0.14.ckpt, Score: 32102.84%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/models/model-epoch=32-val_loss=0.00.ckpt\n",
            "Loading /content/drive/MyDrive/Kraken/models/model-epoch=32-val_loss=0.00.ckpt as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=2, n_features=13, output_size=312, LayerNorm=True, n_future=24\n",
            "Calculating scores...\n",
            "Overall Score: 423.46%\n",
            "Current top 7 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=14-val_loss=0.02.ckpt, Score: 216.60%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=32-val_loss=0.00.ckpt, Score: 423.46%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=65-val_loss=0.13.ckpt, Score: 7452.54%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=68-val_loss=0.14.ckpt, Score: 32102.84%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/models/model-epoch=35-val_final_loss=0.00.ckpt\n",
            "Loading /content/drive/MyDrive/Kraken/models/model-epoch=35-val_final_loss=0.00.ckpt as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=13, output_size=312, LayerNorm=True, n_future=24\n",
            "Calculating scores...\n",
            "Overall Score: 104.66%\n",
            "Current top 8 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=35-val_final_loss=0.00.ckpt, Score: 104.66%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=14-val_loss=0.02.ckpt, Score: 216.60%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=32-val_loss=0.00.ckpt, Score: 423.46%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=65-val_loss=0.13.ckpt, Score: 7452.54%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=68-val_loss=0.14.ckpt, Score: 32102.84%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/models/model-epoch=21-val_loss=2.05.ckpt\n",
            "Failed to load model /content/drive/MyDrive/Kraken/models/model-epoch=21-val_loss=2.05.ckpt: Ran out of input\n",
            "Skipping model /content/drive/MyDrive/Kraken/models/model-epoch=21-val_loss=2.05.ckpt due to loading error\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/models/model-69-epoch=41-val_loss=1.20.ckpt\n",
            "Loading /content/drive/MyDrive/Kraken/models/model-69-epoch=41-val_loss=1.20.ckpt as CryptoTransformer\n",
            "Inferred Transformer parameters: d_model=512, nhead=16, num_encoder_layers=3, num_decoder_layers=3, dim_feedforward=2048, dropout=0.2, activation=gelu\n",
            "Failed to load model /content/drive/MyDrive/Kraken/models/model-69-epoch=41-val_loss=1.20.ckpt: Error(s) in loading state_dict for CryptoTransformer:\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for input_fc.weight: copying a param with shape torch.Size([256, 13]) from checkpoint, the shape in current model is torch.Size([512, 13]).\n",
            "\tsize mismatch for input_fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for output_fc.weight: copying a param with shape torch.Size([13, 256]) from checkpoint, the shape in current model is torch.Size([13, 512]).\n",
            "Skipping model /content/drive/MyDrive/Kraken/models/model-69-epoch=41-val_loss=1.20.ckpt due to loading error\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/models/model-71-epoch=30-val_loss=0.56.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-64-38609d2c3af6>\", line 201, in load_model\n",
            "    model.load_state_dict(state_dict, strict=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2215, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for CryptoTransformer:\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for input_fc.weight: copying a param with shape torch.Size([256, 13]) from checkpoint, the shape in current model is torch.Size([512, 13]).\n",
            "\tsize mismatch for input_fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for output_fc.weight: copying a param with shape torch.Size([13, 256]) from checkpoint, the shape in current model is torch.Size([13, 512]).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading /content/drive/MyDrive/Kraken/models/model-71-epoch=30-val_loss=0.56.ckpt as CryptoTransformer\n",
            "Inferred Transformer parameters: d_model=512, nhead=16, num_encoder_layers=3, num_decoder_layers=3, dim_feedforward=2048, dropout=0.2, activation=gelu\n",
            "Failed to load model /content/drive/MyDrive/Kraken/models/model-71-epoch=30-val_loss=0.56.ckpt: Error(s) in loading state_dict for CryptoTransformer:\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for input_fc.weight: copying a param with shape torch.Size([256, 13]) from checkpoint, the shape in current model is torch.Size([512, 13]).\n",
            "\tsize mismatch for input_fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for output_fc.weight: copying a param with shape torch.Size([13, 256]) from checkpoint, the shape in current model is torch.Size([13, 512]).\n",
            "Skipping model /content/drive/MyDrive/Kraken/models/model-71-epoch=30-val_loss=0.56.ckpt due to loading error\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-64-38609d2c3af6>\", line 201, in load_model\n",
            "    model.load_state_dict(state_dict, strict=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2215, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for CryptoTransformer:\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.0.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.1.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_encoder.layers.2.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.0.norm3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.multihead_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.1.norm3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.self_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.in_proj_weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.in_proj_bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.out_proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.multihead_attn.out_proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.linear1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.linear2.weight: copying a param with shape torch.Size([256, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.linear2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for transformer_decoder.layers.2.norm3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for input_fc.weight: copying a param with shape torch.Size([256, 13]) from checkpoint, the shape in current model is torch.Size([512, 13]).\n",
            "\tsize mismatch for input_fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for output_fc.weight: copying a param with shape torch.Size([13, 256]) from checkpoint, the shape in current model is torch.Size([13, 512]).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=700, num_layers=2, n_features=13, output_size=13, LayerNorm=False, n_future=1\n",
            "Calculating scores...\n",
            "Overall Score: 70.78%\n",
            "Current top 9 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=35-val_final_loss=0.00.ckpt, Score: 104.66%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=14-val_loss=0.02.ckpt, Score: 216.60%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=32-val_loss=0.00.ckpt, Score: 423.46%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=65-val_loss=0.13.ckpt, Score: 7452.54%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=68-val_loss=0.14.ckpt, Score: 32102.84%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=700, num_layers=2, n_features=13, output_size=13, LayerNorm=False, n_future=1\n",
            "Calculating scores...\n",
            "Overall Score: 52.68%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=35-val_final_loss=0.00.ckpt, Score: 104.66%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=14-val_loss=0.02.ckpt, Score: 216.60%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=32-val_loss=0.00.ckpt, Score: 423.46%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=65-val_loss=0.13.ckpt, Score: 7452.54%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=68-val_loss=0.14.ckpt, Score: 32102.84%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=700, num_layers=2, n_features=13, output_size=13, LayerNorm=False, n_future=1\n",
            "Calculating scores...\n",
            "Overall Score: 69.62%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=35-val_final_loss=0.00.ckpt, Score: 104.66%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=14-val_loss=0.02.ckpt, Score: 216.60%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=32-val_loss=0.00.ckpt, Score: 423.46%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=65-val_loss=0.13.ckpt, Score: 7452.54%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=700, num_layers=2, n_features=13, output_size=13, LayerNorm=False, n_future=1\n",
            "Calculating scores...\n",
            "Overall Score: 55.91%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=35-val_final_loss=0.00.ckpt, Score: 104.66%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=14-val_loss=0.02.ckpt, Score: 216.60%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=32-val_loss=0.00.ckpt, Score: 423.46%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=700, num_layers=2, n_features=13, output_size=13, LayerNorm=False, n_future=1\n",
            "Calculating scores...\n",
            "Overall Score: 50.25%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=35-val_final_loss=0.00.ckpt, Score: 104.66%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=14-val_loss=0.02.ckpt, Score: 216.60%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth\n",
            "Loading /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=700, num_layers=2, n_features=13, output_size=13, LayerNorm=False, n_future=1\n",
            "Calculating scores...\n",
            "Overall Score: 56.52%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "  Model: /content/drive/MyDrive/Kraken/models/model-epoch=35-val_final_loss=0.00.ckpt, Score: 104.66%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_54.pth\n",
            "Loading /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_54.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=700, num_layers=2, n_features=13, output_size=13, LayerNorm=False, n_future=1\n",
            "Calculating scores...\n",
            "Overall Score: 75.19%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_54.pth, Score: 75.19%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_63.pth\n",
            "Loading /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_63.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=700, num_layers=2, n_features=13, output_size=13, LayerNorm=False, n_future=1\n",
            "Calculating scores...\n",
            "Overall Score: 78.21%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_54.pth, Score: 75.19%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth\n",
            "Loading /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=700, num_layers=2, n_features=13, output_size=13, LayerNorm=False, n_future=1\n",
            "Calculating scores...\n",
            "Overall Score: 40.76%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_16.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_16.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=700, num_layers=2, n_features=13, output_size=624, LayerNorm=False, n_future=48\n",
            "Calculating scores...\n",
            "Overall Score: nan%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_8.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_8.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=624, LayerNorm=False, n_future=48\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 82.66%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/9crypto_lstm_model.pth\n",
            "Loading /content/drive/MyDrive/Kraken/9crypto_lstm_model.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=624, LayerNorm=False, n_future=48\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 78.80%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_model.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_model.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=624, LayerNorm=False, n_future=48\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 81.39%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_35.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_35.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_42.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_42.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_49.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_49.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_56.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_56.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_63.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_63.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_70.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_70.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_77.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_77.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_84.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_84.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_91.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_91.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_98.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_98.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_105.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_105.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_112.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_112.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_119.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_119.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_28.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_28.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_14.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_14.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=209, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_21.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_21.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=209, num_layers=1, n_features=7, output_size=105, LayerNorm=False, n_future=15\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=175, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_7.pth\n",
            "Loading /content/drive/MyDrive/Kraken/8crypto_lstm_model_epoch_7.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=175, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/1_fixed_crypto_lstm_model_epoch_11.pth\n",
            "Loading /content/drive/MyDrive/Kraken/1_fixed_crypto_lstm_model_epoch_11.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=175, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/2_fixed_crypto_lstm_model_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/2_fixed_crypto_lstm_model_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=175, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/2_fixed_crypto_lstm_model_epoch_11.pth\n",
            "Loading /content/drive/MyDrive/Kraken/2_fixed_crypto_lstm_model_epoch_11.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=175, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/1_fixed_crypto_lstm_model_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/1_fixed_crypto_lstm_model_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=7, output_size=175, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_22.pth\n",
            "Loading /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_22.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 72.86%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_33.pth\n",
            "Loading /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_33.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 84.21%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_44.pth\n",
            "Loading /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_44.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 77.06%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_55.pth\n",
            "Loading /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_55.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 78.02%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_66.pth\n",
            "Loading /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_66.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 79.16%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_77.pth\n",
            "Loading /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_77.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 88.44%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_88.pth\n",
            "Loading /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_88.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 74.62%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_99.pth\n",
            "Loading /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_99.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 73.35%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_110.pth\n",
            "Loading /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_110.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 80.22%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 84.27%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_11.pth\n",
            "Loading /content/drive/MyDrive/Kraken/3_fixed_crypto_lstm_model_epoch_11.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 84.61%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 83.66%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_11.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_11.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 85.60%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_22.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_22.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 74.99%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_33.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_33.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 75.07%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_44.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_44.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 71.73%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_55.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_55.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 74.17%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_66.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_66.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 77.55%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_77.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_77.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 77.88%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_10.pth, Score: 70.78%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_88.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_88.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 69.67%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_88.pth, Score: 69.67%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_99.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_99.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 87.09%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_88.pth, Score: 69.67%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 62.97%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_121.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_121.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 73.96%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_132.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_132.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 72.40%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_143.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_143.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 86.04%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_154.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_154.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 76.77%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_165.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_165.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 78.21%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_30.pth, Score: 69.62%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_176.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_176.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 64.02%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_176.pth, Score: 64.02%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_187.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_187.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 75.81%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_176.pth, Score: 64.02%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_198.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_198.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 74.26%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_176.pth, Score: 64.02%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_209.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_209.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 77.63%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_176.pth, Score: 64.02%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_220.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_220.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 75.62%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_176.pth, Score: 64.02%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_231.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_231.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 65.42%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_176.pth, Score: 64.02%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_242.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_242.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 83.26%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_176.pth, Score: 64.02%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_253.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_253.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 70.47%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_176.pth, Score: 64.02%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_264.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_264.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 74.76%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_176.pth, Score: 64.02%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_275.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_275.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 73.09%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_176.pth, Score: 64.02%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_286.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_286.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 79.63%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_176.pth, Score: 64.02%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth\n",
            "Loading /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n",
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating scores...\n",
            "Overall Score: 58.56%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/1crypto_lstm_model.pth\n",
            "Loading /content/drive/MyDrive/Kraken/1crypto_lstm_model.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=2096, num_layers=1, n_features=13, output_size=325, LayerNorm=False, n_future=25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unexpected keys: ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 73.25%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_63.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_63.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 256.26%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_70.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_70.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 7802.47%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_77.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_77.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 11831.41%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_84.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_84.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 37846.75%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_91.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_91.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 12999.77%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_98.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_98.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 541.81%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_105.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_105.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 9448.60%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_112.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_112.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 801.69%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_119.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_119.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 1791.86%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_126.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_126.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 6287.71%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_133.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_133.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 2013.98%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_140.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_140.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 1958.13%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_147.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_147.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 411.89%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_154.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_154.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 10879.47%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_161.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_161.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 22354.87%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_168.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_168.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 483.37%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_175.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_175.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 2440.47%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_182.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_182.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 24414.52%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_189.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_189.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 4718.89%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_196.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_196.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 1056.85%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1024, num_layers=2, n_features=13, output_size=156, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "Calculating scores...\n",
            "Overall Score: 11100.73%\n",
            "Current top 10 models:\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "  Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "  Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "  Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "  Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_14.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_14.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=2, n_features=6, output_size=72, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_21.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_21.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=2, n_features=6, output_size=72, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_28.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_28.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=2, n_features=6, output_size=72, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_35.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_35.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=2, n_features=6, output_size=72, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_42.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_42.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=2, n_features=6, output_size=72, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_49.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_49.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=2, n_features=6, output_size=72, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_56.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_56.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=2, n_features=6, output_size=72, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_7.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_7.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=7, num_layers=60, n_features=7, output_size=252, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'bn.num_batches_tracked']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/bool_crypto_lstm_model_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=128, num_layers=3, n_features=7, output_size=252, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=128, num_layers=3, n_features=7, output_size=252, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_7.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_7.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=128, num_layers=3, n_features=7, output_size=252, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_14.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_14.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=128, num_layers=3, n_features=7, output_size=252, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_21.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_21.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=128, num_layers=3, n_features=7, output_size=252, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_28.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_28.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=128, num_layers=3, n_features=7, output_size=252, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_35.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_35.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=128, num_layers=3, n_features=7, output_size=252, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_42.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_42.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=128, num_layers=3, n_features=7, output_size=252, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_49.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_49.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=128, num_layers=3, n_features=7, output_size=252, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 756 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_Stan_Scale_model_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_Stan_Scale_model_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=128, num_layers=3, n_features=6, output_size=216, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_Stan_Scale_XBT_model_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_Stan_Scale_XBT_model_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=128, num_layers=3, n_features=6, output_size=216, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_Stan_Scale_XBT_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_Stan_Scale_XBT_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=128, num_layers=3, n_features=6, output_size=216, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_Stan_Scale_XBT_all_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_Stan_Scale_XBT_all_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=6, output_size=216, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_Stan_Scale_XBT_all_model_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_Stan_Scale_XBT_all_model_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=6, output_size=216, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_model_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_model_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=6, output_size=216, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=6, output_size=216, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_50.pth\n",
            "Loading /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_50.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_60.pth\n",
            "Loading /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_60.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_70.pth\n",
            "Loading /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_70.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_80.pth\n",
            "Loading /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_epoch_80.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/Crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_BALANCE_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MAXDIFF_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MAXDIFF_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MAXDIFF_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MAXDIFF_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MAXDIFF_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MAXDIFF_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MAXDIFF_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MAXDIFF_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MAXDIFF_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MAXDIFF_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MAXDIFF_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MAXDIFF_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_DIRLOSS_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_DIRLOSS_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_DIRLOSS_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_DIRLOSS_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_DIRLOSS_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_DIRLOSS_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_DIRLOSS_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_DIRLOSS_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_DIRLOSS_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_DIRLOSS_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_DIRLOSS_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_DIRLOSS_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MSE_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MSE_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MSE_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MSE_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MSE_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MSE_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MSE_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MSE_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MSE_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MSE_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MSE_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_MSE_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_50.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_50.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_60.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_60.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_70.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_70.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_80.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_80.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_90.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_epoch_90.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model_COMBO_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_50.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_50.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_60.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_60.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_70.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_70.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_80.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_80.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_90.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_epoch_90.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model2_COMBO_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model3_COMBO_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model3_COMBO_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model3_COMBO_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model3_COMBO_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model3_COMBO_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model3_COMBO_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model3_COMBO_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model3_COMBO_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model3_COMBO_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model3_COMBO_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model3_COMBO_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model3_COMBO_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_50.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_50.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_60.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_60.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_70.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_70.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_80.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_80.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_90.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_epoch_90.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model4_COMBO_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_50.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_50.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_60.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_60.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_70.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_70.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_80.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_80.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_90.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_epoch_90.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_model5_COMBO_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=3, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_100.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_100.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_110.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_110.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_120.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_120.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_130.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_130.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_140.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_140.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_150.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_150.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_160.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_160.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_170.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_170.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_180.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_180.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_190.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_190.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_200.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_200.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_210.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_210.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_220.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_220.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_230.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_230.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_240.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_240.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_250.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_250.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_260.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_260.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_270.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_270.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_280.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_280.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_290.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_290.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_50.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_50.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_60.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_60.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_70.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_70.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_80.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_80.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_90.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_epoch_90.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model5_COMBO_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_50.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_50.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_60.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_60.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_70.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_70.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_80.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_80.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_90.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_epoch_90.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model6_COMBO_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=4, n_features=3, output_size=36, LayerNorm=True, n_future=12\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_50.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_50.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_60.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_60.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_70.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_70.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_80.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_80.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_90.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_90.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good__COMBO_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_50.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_50.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_60.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_60.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_70.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_70.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_80.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_80.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_90.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_90.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_100.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_100.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_110.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_110.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_120.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_120.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_130.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_130.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_140.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_140.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_150.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_150.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_160.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_160.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_170.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_170.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_180.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_180.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_190.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_epoch_190.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_SM_model_2Good2_COMBO_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=4, n_features=3, output_size=108, LayerNorm=True, n_future=36\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 324 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_50.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_50.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_60.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_60.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_70.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_70.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_80.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_80.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_90.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_90.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_100.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_100.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_110.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_110.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_120.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_120.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_2Good2_COMBO_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=5, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_epoch_0.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_epoch_0.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=4, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_epoch_10.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_epoch_10.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=4, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_epoch_20.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_epoch_20.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=4, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_epoch_30.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_epoch_30.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=4, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_epoch_40.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_epoch_40.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=4, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_epoch_50.pth\n",
            "Loading /content/drive/MyDrive/Kraken/crypto_lstm_MinMax_Scale_XBT_all_CustomLoss_BG_model_3Good1_COMBO_epoch_50.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=1028, num_layers=4, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/models/AGoodOne3_COMBO_final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/models/AGoodOne3_COMBO_final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=3, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/models/final.pth\n",
            "Loading /content/drive/MyDrive/Kraken/models/final.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=2, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/models/final2.pth\n",
            "Loading /content/drive/MyDrive/Kraken/models/final2.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=2, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/models/final3.pth\n",
            "Loading /content/drive/MyDrive/Kraken/models/final3.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=256, num_layers=2, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Loading model from /content/drive/MyDrive/Kraken/models/final4.pth\n",
            "Loading /content/drive/MyDrive/Kraken/models/final4.pth as CryptoLSTM\n",
            "Inferred LSTM parameters: hidden_size=512, num_layers=2, n_features=6, output_size=144, LayerNorm=True, n_future=24\n",
            "Missing keys: ['layer_norm.weight', 'layer_norm.bias']\n",
            "Unexpected keys: ['ln.weight', 'ln.bias']\n",
            "ValueError during reshaping: cannot reshape array of size 648 into shape (108,13). Skipping model.\n",
            "\n",
            "Top 10 models:\n",
            "Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_72.pth, Score: 40.76%\n",
            "Model: /content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt, Score: 49.50%\n",
            "Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_0.pth, Score: 50.25%\n",
            "Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_20.pth, Score: 52.68%\n",
            "Model: /content/drive/MyDrive/Kraken/crypto_lstm_model_epoch_40.pth, Score: 55.91%\n",
            "Model: /content/drive/MyDrive/Kraken/9crypto_lstm_model_epoch_81.pth, Score: 56.52%\n",
            "Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_297.pth, Score: 58.56%\n",
            "Model: /content/drive/MyDrive/Kraken/model-68-epoch=42-val_loss=1.49.ckpt, Score: 61.56%\n",
            "Model: /content/drive/MyDrive/Kraken/4eva_fixed_crypto_lstm_model_epoch_110.pth, Score: 62.97%\n",
            "Model: /content/drive/MyDrive/Kraken/model-68-epoch=26-val_loss=1.70.ckpt, Score: 63.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_file = \"/content/drive/MyDrive/Kraken/model-68-epoch=11-val_loss=1.90.ckpt\"\n",
        "state_dict = torch.load(model_file, map_location=\"cpu\")\n",
        "\n"
      ],
      "metadata": {
        "id": "iPapH_7VDsqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict.items()"
      ],
      "metadata": {
        "id": "d8bAdEiTZlmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_file, cfg, cfg.DEVICE)"
      ],
      "metadata": {
        "id": "-32TcJdeXdHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OYPt4jQwdHb6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}